Directory structure:
└── cainam-core/
    ├── README.md
    ├── Cargo.toml
    ├── .env.example
    ├── agents/
    ├── docs/
    ├── memory-bank/
    │   ├── activeContext.md
    │   ├── codeReview.md
    │   ├── databaseStructure.md
    │   ├── developmentWorkflow.md
    │   ├── operationalContext.md
    │   ├── productContext.md
    │   ├── projectBoundaries.md
    │   └── techContext.md
    ├── migrations/
    ├── scripts/
    │   ├── capture_token_analytics.rs
    │   ├── capture_trending_tokens.rs
    │   └── setup_mongodb.rs
    ├── src/
    │   ├── error.rs
    │   ├── lib.rs
    │   ├── main.rs
    │   ├── memory.rs
    │   ├── actions/
    │   │   ├── helius/
    │   │   │   ├── create_webhook.rs
    │   │   │   ├── delete_webhook.rs
    │   │   │   ├── get_assets_by_owner.rs
    │   │   │   ├── get_webhook.rs
    │   │   │   ├── mod.rs
    │   │   │   └── transaction_parsing.rs
    │   │   └── solana/
    │   │       ├── close_empty_token_accounts.rs
    │   │       ├── get_balance.rs
    │   │       ├── get_tps.rs
    │   │       ├── mod.rs
    │   │       ├── request_faucet_funds.rs
    │   │       └── transfer.rs
    │   ├── agent/
    │   │   ├── analyst.rs
    │   │   ├── mod.rs
    │   │   ├── portfolio_optimizer.rs
    │   │   ├── risk_manager.rs
    │   │   └── trader.rs
    │   ├── birdeye/
    │   │   ├── api.rs
    │   │   └── mod.rs
    │   ├── character/
    │   │   └── mod.rs
    │   ├── characteristics/
    │   │   ├── adjectives.rs
    │   │   ├── bio.rs
    │   │   ├── lore.rs
    │   │   ├── mod.rs
    │   │   ├── post_examples.rs
    │   │   ├── previous_messages.rs
    │   │   ├── styles.rs
    │   │   └── topics.rs
    │   ├── clients/
    │   │   └── twitter.rs
    │   ├── config/
    │   │   ├── agent_config.rs
    │   │   ├── birdeye_config.rs
    │   │   ├── logging_config.rs
    │   │   ├── market_config.rs
    │   │   ├── mod.rs
    │   │   └── mongodb.rs
    │   ├── core/
    │   │   ├── agent.rs
    │   │   ├── characteristics.rs
    │   │   ├── instruction_builder.rs
    │   │   ├── mod.rs
    │   │   └── runtime.rs
    │   ├── database/
    │   │   ├── mod.rs
    │   │   └── sync.rs
    │   ├── logging/
    │   │   └── mod.rs
    │   ├── market_data/
    │   │   └── birdeye.rs
    │   ├── models/
    │   │   ├── market_signal.rs
    │   │   ├── mod.rs
    │   │   ├── token_analytics.rs
    │   │   ├── token_info.rs
    │   │   └── trending_token.rs
    │   ├── personality/
    │   │   └── mod.rs
    │   ├── prompts/
    │   │   └── system.txt
    │   ├── providers/
    │   │   ├── birdeye.rs
    │   │   ├── discord.rs
    │   │   ├── mod.rs
    │   │   └── twitter.rs
    │   ├── services/
    │   │   ├── mod.rs
    │   │   ├── token_analytics.rs
    │   │   ├── token_data.rs
    │   │   └── token_data_service.rs
    │   ├── strategy/
    │   │   ├── llm.rs
    │   │   └── mod.rs
    │   ├── trading/
    │   │   ├── mod.rs
    │   │   └── trading_engine.rs
    │   ├── twitter/
    │   │   └── mod.rs
    │   ├── utils/
    │   │   └── mod.rs
    │   └── vector_store/
    │       └── mod.rs
    ├── tests/
    ├── .cursor/
    └── .github/

================================================
File: README.md
================================================
# Cainam Core

Core functionality for the Cainam project - A decentralized network of autonomous AI trading agents for the $CAINAM token platform on Solana.

## Overview

Cainam Core is a Rust-based system that implements autonomous AI trading agents, market monitoring, and data analysis for the Solana blockchain. The system features real-time market data processing, automated trading execution, and advanced risk management capabilities.

### Key Features

- Real-time market monitoring via Birdeye API
- Blockchain transaction monitoring using Helius webhooks
- Autonomous trading agents with AI-driven decision making
- Advanced risk management and position sizing
- Time-series data storage with TimescaleDB
- Vector similarity search using Qdrant
- Discord and Twitter integration

## Prerequisites

- Rust 1.75+ (2021 edition)
- PostgreSQL 15+ with TimescaleDB extension
- Solana CLI tools
- Node.js and npm (for development tools)

## Installation

1. Clone the repository:

```bash
git clone https://github.com/cainamventures/cainam-core
cd cainam-core
```

2. Copy the environment template and configure your variables:

```bash
cp .env.example .env
# Edit .env with your configuration
```

3. Install development dependencies:

```bash
# Install pre-commit hooks
pre-commit install

# Install required database extensions
psql -c 'CREATE EXTENSION IF NOT EXISTS timescaledb;'
```

4. Build the project:

```bash
cargo build
```

## Configuration

The following environment variables are required:

```env
# Database
DATABASE_URL=postgresql://user:password@localhost/dbname

# Solana
SOLANA_RPC_URL=your_rpc_url
HELIUS_API_KEY=your_helius_key

# APIs
BIRDEYE_API_KEY=your_birdeye_key

# Optional integrations
DISCORD_TOKEN=your_discord_token
TWITTER_API_KEY=your_twitter_key
```

## Project Structure

```
src/
├── actions/      # External API interactions
├── agent/        # Agent implementations
├── trading/      # Trading logic
├── models/       # Data models
└── services/     # Business logic
```

## Development

### Running Tests

```bash
# Run all tests
cargo test

# Run specific test suite
cargo test --package cainam-core
```

### Database Migrations

```bash
# Apply migrations
sqlx migrate run

# Create new migration
sqlx migrate add <name>
```

### Code Style

The project uses rustfmt and clippy for code formatting and linting:

```bash
# Format code
cargo fmt

# Run clippy
cargo clippy
```

## Performance Requirements

- Trade execution: < 500ms end-to-end
- Market data updates: < 1s refresh rate
- Signal processing: < 200ms
- Database queries: < 100ms response time

## Dependencies

Core dependencies include:

- tokio (async runtime)
- solana-client & solana-sdk (blockchain interaction)
- serde (serialization)
- tokio-postgres (database)
- qdrant-client (vector store)
- rig-core (framework)

## Contributing

Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines on contributing to the project.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contact

- Author: Matt Gunnin
- Email: <matt@cainamventures.com>
- Repository: <https://github.com/cainamventures/cainam-core>


================================================
File: Cargo.toml
================================================
[package]
name = "cainam-core"
version = "0.1.0"
edition = "2021"
authors = ["Matt Gunnin <matt@cainamventures.com>"]
repository = "https://github.com/cainamventures/cainam-core"
readme = "README.md"
keywords = ["ai", "solana", "rust", "cainam", "cainam-ventures"]
description = "Core functionality for the Cainam project"

[[bin]]
name = "cainam-core"
path = "src/main.rs"

[[bin]]
name = "setup_mongodb"
path = "scripts/setup_mongodb.rs"

[[bin]]
name = "capture_trending_tokens"
path = "scripts/capture_trending_tokens.rs"

[[bin]]
name = "capture_token_analytics"
path = "scripts/capture_token_analytics.rs"

[workspace]
resolver = "2"
members = []
exclude = [
    "examples",
    "memory-bank",
    "phases_output",
]

[workspace.package]
version = "0.1.0"
edition = "2021"

[profile.dev]
opt-level = "z"

[profile.release]
codegen-units = 1
lto = "thin"
opt-level = "z"
strip = true

[dependencies]
anyhow = "1.0"
async-trait = "0.1"
bigdecimal = { version = "0.2", features = ["serde"] }
bson = "2.0"
chrono = "0.4"
futures = "0.3"
mockall = "0.11.0"
mongodb = "3.2.1"
reqwest = { version = "0.11", features = ["json"] }
rig-core = "0.8.0"
solagent-core = "0.1.5"
serde = { version = "1.0.217", features = ["derive"] }
serde_derive = "1.0.217"
thiserror = "2.0.11"
time = "0.3"
tokio = { version = "1", features = ["full", "macros"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["std", "env-filter"] }

# Blockchain dependencies
solana-account-decoder = "2.2.0"
solana-client = "2.2.0"
solana-sdk = "2.2.1"
solana-program = "2.2.1"
spl-associated-token-account = "6.0.0"
spl-token = "7.0"

# Additional utilities
dotenvy = "0.15.7"
serde_json = "1.0"
uuid = { version = "1.6", features = ["v4", "serde"] }


================================================
File: .env.example
================================================
####################################
#### Core Configurations ####
####################################
OPENAI_MODEL=gpt-4o
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=

####################################
#### Birdeye Configurations ####
####################################
BIRDEYE_API_KEY=your_birdeye_api_key
BIRDEYE_WALLET_ADDR=

####################################
#### Solana Configurations ####
####################################
SOLANA_PUBLIC_KEY= 
# Either set SOLANA_PRIVATE_KEY or use local keypair at ~/.config/solana/id.json
#SOLANA_PRIVATE_KEY=your_base58_private_key
SOLANA_RPC_URL=https://api.mainnet-beta.solana.com

####################################
#### Trading Configurations ####
####################################
MAX_POSITION_SIZE_SOL=1.0
MIN_POSITION_SIZE_SOL=0.1
MAX_TOKENS_PER_WALLET=5
MIN_CONFIDENCE_THRESHOLD=0.8
MIN_LIQUIDITY_USD=100000
MAX_SLIPPAGE=0.01  # 1%
INITIAL_PORTFOLIO_VALUE=10.0  # SOL
MAX_DRAWDOWN=0.2  # 20%

# Risk Management
STOP_LOSS_PERCENTAGE=0.05  # 5%
TAKE_PROFIT_PERCENTAGE=0.15  # 15%

####################################
#### Future ####
####################################

# Web Search API Configuration
# TAVILY_API_KEY=

# Postgres Database
# DATABASE_URL=

######################################
#### Crypto Analytics ####
######################################

# CoinMarketCap
COINMARKETCAP_API_KEY=
# CoinGecko
COINGECKO_API_KEY=

####################################
#### Twitter ####
####################################
TWITTER_USERNAME=
TWITTER_PASSWORD=
TWITTER_EMAIL=
TWITTER_2FA_SECRET=
TWITTER_TARGET_USERS=

####################################
#### Discord ####
####################################
DISCORD_APPLICATION_ID=
DISCORD_API_TOKEN=

####################################
#### Telegram ####
####################################
TELEGRAM_BOT_TOKEN=

####################################
#### Database Configuration ####
####################################
MONGODB_URI=mongodb://localhost:32769
MONGODB_DATABASE=cainam
MONGODB_APP_NAME=cainam-core

# Optional vector store settings
MONGODB_VECTOR_COLLECTION=vectors
MONGODB_VECTOR_INDEX_NAME=vector_index

# Connection pool settings
MONGODB_MIN_POOL_SIZE=5
MONGODB_MAX_POOL_SIZE=10
MONGODB_CONNECT_TIMEOUT_MS=20000

# Optional development settings
MONGODB_TEST_DATABASE=cainam_test

================================================
File: memory-bank/activeContext.md
================================================
# Active Context

## Current Focus
- Market data capture and analysis system for Solana tokens
- Two-phase data collection process:
  1. Trending token capture from Birdeye API
  2. Detailed token analytics collection for trending tokens

## Recent Changes
- Split market data capture into two separate scripts:
  1. `capture_trending_tokens.rs`: Fetches trending tokens and stores in MongoDB
  2. `capture_token_analytics.rs`: Processes trending tokens to get detailed analytics
- Fixed MongoDB integration issues:
  - Corrected database connection handling
  - Implemented proper index creation
  - Fixed query syntax for sorting and filtering
- Improved error handling and logging throughout the system
- Cleaned up scripts directory:
  - Removed redundant initialization scripts
  - Consolidated MongoDB setup into single script
  - Removed deprecated test scripts

## Active Decisions
- Using MongoDB for data storage with specific collections:
  - `trending_tokens`: Stores basic trending token data
  - `token_analytics`: Stores detailed token analytics and metrics
- Implementing rate limiting (500ms delay) between API calls to respect Birdeye's limits
- Using compound indexes for efficient querying by address and timestamp
- Maintaining three core scripts:
  1. `setup_mongodb.rs` for database initialization
  2. `capture_trending_tokens.rs` for trending token collection
  3. `capture_token_analytics.rs` for detailed analytics

## Next Steps
1. Implement automated scheduling for both capture scripts
2. Add data validation and cleanup processes
3. Develop analytics dashboard for monitoring token performance
4. Integrate with trading system for automated decision making
5. Add more technical indicators and market metrics
6. Clean up deprecated scripts from repository

## Current Considerations
- Need to handle API rate limits carefully
- Consider implementing data archival strategy
- Monitor MongoDB performance and indexing
- Plan for scaling as data volume grows
- Consider implementing data backup strategy
- Maintain clear separation of concerns in scripts

## Technical Context

- Project uses MongoDB Atlas for vector store capabilities
- Vector search implemented using MongoDB Atlas Search and the `rig-mongodb` crate.
- Token analytics data stored with embeddings
- Connection pooling configured for optimal performance

## Resolution Progress

Current implementation includes:

1. ✅ MongoDB connection pool configuration
2. ✅ Token analytics data structure
3. ✅ Vector index creation
4. ✅ Search parameters configuration (simplified)
5. ✅ Document insertion functionality
6. ✅ `rig-mongodb` integration for vector search

Current Issues:

- None identified.  Focus is on testing.

Next steps:

1. Thoroughly test vector search functionality.
2. Implement proper error handling (ongoing).
3. Add comprehensive logging (ongoing).
4. Document MongoDB integration details (ongoing).

Technical Notes:

- Using MongoDB Atlas vector search capabilities
- Embedding dimension: 1536 (OpenAI compatible)
- Cosine similarity for vector search
- Connection pooling configured with:
  - Min pool size: 5
  - Max pool size: 10
  - Connect timeout: 20 seconds
- Vector index using IVFFlat algorithm (default for `rig-mongodb`)
- Using `rig-mongodb` for simplified vector search implementation.


================================================
File: memory-bank/codeReview.md
================================================
# Code Review Guidelines

Last Updated: 2025-02-11

## Focus Areas

### 1. MongoDB Integration

- Connection pooling configuration
- Error handling and retry logic
- Proper use of MongoDB Atlas features
- Vector store implementation

### 2. Vector Search Implementation

- Proper embedding handling
- Search parameter configuration
- Index creation and management
- Query optimization

### 3. Error Handling

```rust
// Good: Proper error context and handling
pub async fn search_tokens(query: &str) -> Result<Vec<TokenAnalytics>> {
    let results = pool.top_n("token_analytics", model, query, 10)
        .await
        .context("Failed to perform vector search")?;
    
    process_results(results)
        .context("Failed to process search results")
}

// Bad: Missing error context
pub async fn search_tokens(query: &str) -> Result<Vec<TokenAnalytics>> {
    let results = pool.top_n("token_analytics", model, query, 10).await?;
    process_results(results)
}
```

### 4. Connection Management

```rust
// Good: Proper connection pool configuration
let pool_config = MongoPoolConfig {
    min_pool_size: 5,
    max_pool_size: 10,
    connect_timeout: Duration::from_secs(20),
};

// Bad: Hardcoded values without configuration
let client = Client::with_uri_str("mongodb://localhost").await?;
```

### 5. Vector Store Operations

```rust
// Good: Proper search parameters
let search_params = SearchParams::new()
    .exact(true)
    .num_candidates(100)
    .fields(vec!["embedding"]);

// Bad: Missing required parameters
let search_params = SearchParams::new()
    .exact(true)
    .num_candidates(100);
```

## Review Checklist

### MongoDB

- [ ] Proper connection pool configuration
- [ ] Error handling with context
- [ ] Retry logic for transient failures
- [ ] Proper use of MongoDB Atlas features
- [ ] Connection string security

### Vector Store Implementation

- [ ] Proper embedding field configuration
- [ ] Search parameter completeness
- [ ] Index creation and management
- [ ] Query optimization
- [ ] Error handling for vector operations

### Code Quality

- [ ] Error handling with proper context
- [ ] Logging for important operations
- [ ] Performance considerations
- [ ] Type safety and null handling
- [ ] Documentation completeness

### Testing

- [ ] Unit tests for vector operations
- [ ] Integration tests for MongoDB
- [ ] Error case coverage
- [ ] Performance benchmarks
- [ ] Connection pool tests

## Common Issues to Watch

1. MongoDB Operations
   - Missing error context
   - Improper connection handling
   - Missing retry logic
   - Hardcoded configuration

2. Vector Store
   - Missing search parameters
   - Improper embedding handling
   - Missing index configuration
   - Inefficient queries

3. Error Handling
   - Generic error types
   - Missing error context
   - Improper error propagation
   - Missing logging

4. Performance
   - Connection pool misconfiguration
   - Missing indexes
   - Inefficient queries
   - Resource leaks

## Best Practices

### MongoDB Integration

```rust
// Connection Pool
impl MongoDbPool {
    pub async fn create_pool(config: MongoConfig) -> Result<Arc<MongoDbPool>> {
        let mut client_options = ClientOptions::parse(&config.uri).await?;
        config.pool_config.apply_to_options(&mut client_options);
        
        let client = Client::with_options(client_options)?;
        Ok(Arc::new(MongoDbPool { client, config }))
    }
}

// Error Handling
pub async fn insert_documents(docs: Vec<Document>) -> Result<()> {
    let collection = self.get_collection()?;
    collection
        .insert_many(docs)
        .await
        .context("Failed to insert documents")?;
    Ok(())
}
```

### Vector Store Operations

```rust
// Search Implementation
pub async fn search_similar(query: &str, limit: usize) -> Result<Vec<Document>> {
    let search_params = SearchParams::new()
        .exact(true)
        .num_candidates(100)
        .fields(vec!["embedding"]);

    let index = MongoDbVectorIndex::new(
        collection,
        model,
        "vector_index",
        search_params
    ).await?;

    index.top_n(query, limit).await
}
```

## Documentation Requirements

1. Function Documentation

```rust
/// Performs a vector similarity search in the token analytics collection
/// 
/// # Arguments
/// * `query` - The search query string
/// * `limit` - Maximum number of results to return
/// 
/// # Returns
/// * `Result<Vec<TokenAnalytics>>` - Search results or error with context
pub async fn search_tokens(query: &str, limit: usize) -> Result<Vec<TokenAnalytics>>
```

2. Error Documentation

```rust
/// Possible errors during vector store operations
#[derive(Error, Debug)]
pub enum VectorStoreError {
    #[error("MongoDB operation failed: {0}")]
    MongoError(#[from] mongodb::error::Error),
    
    #[error("Vector search failed: {0}")]
    SearchError(String),
    
    #[error("Invalid configuration: {0}")]
    ConfigError(String),
}
```


================================================
File: memory-bank/databaseStructure.md
================================================
# MongoDB Database Structure for CAINAM (Revised)

## Database: `cainam`

This document outlines the collections within the `cainam` database, their purposes, schemas, indexes, and relationships. It also notes the relevant API endpoints for data ingestion.

### 1. Market Data Collections

#### 1.1. `trending_tokens`

* **Purpose:** Stores trending token data from the Birdeye API. This is the initial point of discovery for potentially interesting tokens.
* **API Endpoint:** `https://public-api.birdeye.so/defi/token_trending`
* **Update Frequency:** Every 5 minutes.
* **Schema:**

    ```json
    {
        "_id": objectId,
        "address": string,          // Token contract address
        "decimals": number,         // Token decimals
        "liquidity": number,        // Current liquidity in USD
        "logo_uri": string,         // Token logo URL
        "name": string,             // Token name
        "symbol": string,           // Token symbol
        "volume_24h_usd": number,   // 24h volume in USD
        "volume_24h_change_percent": number,  // 24h volume change %
        "fdv": number,              // Fully diluted valuation
        "marketcap": number,        // Current market cap
        "rank": number,             // Trending rank
        "price": number,            // Current price
        "price_24h_change_percent": number,   // 24h price change %
        "timestamp": date       // When this data was captured
    }
    ```

* **Indexes:**
  * Compound: `{ address: 1, timestamp: -1 }` (For querying historical data for a specific token)
  * Single: `{ timestamp: -1 }` (For querying the most recent trending tokens)
* **Relationship:** Feeds into `token_analytics`.

#### 1.2. `token_analytics`

* **Purpose:** Stores comprehensive token analytics, combining data from Birdeye with calculated metrics and AI-generated insights.
* **API Endpoints:**
  * `https://public-api.birdeye.so/defi/token_overview?address={token_address}` (Token Overview)
  * `https://public-api.birdeye.so/defi/v3/token/market-data?address={token_address}` (Market Data)
  * `https://public-api.birdeye.so/defi/v3/token/trade-data/multiple?list_address={address1},{address2},...` (Trade Data - for multiple tokens, batched)
* **Update Frequency:** Every 15 minutes for actively tracked tokens.
* **Schema:**

    ```json
    {
        "_id": objectId,
        "token_address": string,
        "symbol": string,
        "name": string,
        "decimals": number,
        "logo_uri": string,

        //-- Price Data (from Birdeye and calculated)
        "price": number,
        "price_change_24h": number,
        "price_change_7d": number,  // Calculated from historical data
        "price_high_24h": number,    // From OHLCV data or calculated
        "price_low_24h": number,     // From OHLCV data or calculated

        //-- Volume Data (from Birdeye)
        "volume_24h": number,
        "volume_change_24h": number,
        "volume_by_price_24h": document, // Could be a nested document with price ranges and volumes

        //-- Market Cap and Supply (from Birdeye)
        "market_cap": number,
        "fully_diluted_market_cap": number,
        "circulating_supply": number,
        "total_supply": number,

        //-- Liquidity (from Birdeye)
        "liquidity": number,
        "liquidity_change_24h": number, // Calculated

        //-- Trading Metrics (from Birdeye and calculated)
        "trades_24h": number,
        "average_trade_size": number, // Calculated (volume_24h / trades_24h)
        "buy_volume_24h": number,      // From Birdeye trade data
        "sell_volume_24h": number,     // From Birdeye trade data

        //-- Holder Metrics (from Birdeye, potentially supplemented by other sources)
        "holder_count": number,
        "active_wallets_24h": number, // Requires additional on-chain analysis
        "whale_transactions_24h": number, // Requires additional on-chain analysis, defining "whale" threshold

        //-- Technical Indicators (Calculated)
        "rsi_14": number,
        "sma_20": number,
        "ema_50": number,
        "bollinger_bands": document, // { upper: number, middle: number, lower: number }
        "macd": document,          // { macd: number, signal: number, histogram: number }

        //-- Sentiment Analysis (from Analyst Agent)
        "social_sentiment": document, // { overall_score: number, twitter_score: number, telegram_score: number, ... }
        "news_sentiment": number,

        //-- On-Chain Analysis (from Analyst Agent, potentially using Birdeye's wallet APIs)
        "whale_activity_index": number, // (0-1, based on whale transaction volume and count)
        "network_growth": number,      // New addresses interacting with the token
        "concentration_ratio": number,  // Percentage of supply held by top N addresses

        //-- Risk Metrics (from Risk Manager Agent)
        "volatility_30d": number,     // Annualized volatility
        "value_at_risk_95": number,  // 95% VaR
        "expected_shortfall_95": number, // 95% Expected Shortfall

        "timestamp": date
    }
    ```

* **Indexes:**
  * Compound: `{ token_address: 1, timestamp: -1 }`
  * Single: `{ timestamp: -1 }`
  * Single: `{ "social_sentiment.overall_score": 1 }`
  * Single: `{ "whale_activity_index": 1 }`
  * Single: `{ "rsi_14": 1 }`
* **Relationship:** Fed by `trending_tokens` and Birdeye API calls. Generates data for `market_signals`.

### 2. Trading and Strategy Collections

#### 2.1. `market_signals`

* **Purpose:** Stores trading signals generated by the Analyst Agent.
* **API Endpoint:** None (Internally generated).
* **Update Frequency:** Continuously.
* **Schema:**

    ```json
    {
        "_id": objectId,
        "asset_address": string,
        "signal_type": string, // "PriceSpike", "VolumeSurge", "SentimentChange", "WhaleActivity", "TechnicalIndicatorCrossover", "NewsEvent"
        "direction": string,   // "BUY", "SELL", "HOLD"
        "confidence": number,
        "risk_score": number,
        "price": number,
        "timestamp": date,
        "metadata": document  // e.g., { rsi_value: 75, moving_average_crossover: "20_50_bullish", news_headline: "...", news_url: "..." }
    }
    ```

* **Indexes:**
  * Compound: `{ asset_address: 1, timestamp: -1 }`
  * Single: `{ timestamp: -1 }`
  * Single: `{ signal_type: 1 }`
  * Single: `{ confidence: 1 }`
* **Relationship:** Fed by `token_analytics`. May trigger actions in `trading_positions`.

#### 2.2. `trading_positions`

* **Purpose:** Tracks active and historical trading positions.
* **API Endpoint:** None (Internally generated).
* **Update Frequency:**  Real-time.
* **Schema:**

    ```json
    {
        "_id": objectId,
        "token_address": string,
        "entry_price": number,
        "current_price": number,
        "position_size": number, // Quantity of tokens
        "position_type": string, // "LONG", "SHORT"
        "entry_time": date,
        "last_update": date,
        "pnl": number,
        "status": string, // "ACTIVE", "CLOSED"
        "exit_price": number,
        "exit_time": date,
        "stop_loss": number,      // Stop-loss price (if set)
        "take_profit": number,    // Take-profit price (if set)
        "leverage": number,       // Leverage used (if applicable)
        "liquidation_price": number // Liquidation price (if applicable)
    }
    ```

* **Indexes:**
  * Compound: `{ token_address: 1, entry_time: -1 }`
  * Single: `{ status: 1 }`
  * Single: `{ last_update: -1 }`
* **Relationship:** Triggered by `market_signals`.

#### 2.3. `trade_history`

* **Purpose:** Records *all* executed trades (audit trail).
* **API Endpoint:** None (Internally generated).
* **Update Frequency:** Real-time.
* **Schema:**

    ```json
    {
        "_id": objectId,
        "trader_address": string,
        "token_address": string,
        "trade_type": string,  // "BUY", "SELL"
        "quantity": number,
        "price": number,
        "timestamp": date,
        "status": string, // "FILLED", "PARTIALLY_FILLED", "CANCELLED", "REJECTED"
        "transaction_hash": string,
        "slippage": number,
        "fees": number,
        "order_type": string, // "MARKET", "LIMIT", "STOP_LOSS", "TAKE_PROFIT"
        "dex": string         // e.g., "Orca", "Raydium", "Jupiter"
    }
    ```

* **Indexes:**
  * Compound: `{ trader_address: 1, timestamp: -1 }`
  * Single: `{ token_address: 1, timestamp: -1 }`
  * Single: `{ status: 1 }`
* **Relationship:** Created by Trader Agent.

### 3. Risk Management and Portfolio Collections

#### 3.1. `risk_models`

* **Purpose:** Stores risk model parameters and outputs.
* **API Endpoint:** None (Internally generated).
* **Update Frequency:** Periodic.
* **Schema:**

    ```json
    {
        "_id": objectId,
        "model_type": string, // "VaR", "ExpectedShortfall", "Volatility", "CorrelationMatrix"
        "asset_address": string, // "ALL" for portfolio-level, or a specific token address
        "parameters": document, // { confidence_level: 0.95, lookback_period: 30, ... }
        "output": number,      // e.g., VaR value, volatility, correlation coefficient
        "timestamp": date
    }
    ```

* **Indexes:**
  * Compound: `{ model_type: 1, asset_address: 1, timestamp: -1 }`
  * Single: `{ timestamp: -1 }`

#### 3.2. `portfolio_allocations`

* **Purpose:** Stores target and actual portfolio allocations.
* **API Endpoint:** None (Internally generated).
* **Update Frequency:**  Whenever rebalancing occurs.
* **Schema:**

    ```json
    {
        "_id": objectId,
        "wallet_address": string,
        "token_address": string,
        "target_allocation": number, // Percentage
        "actual_allocation": number,
        "timestamp": date
    }
    ```

* **Indexes:**
  * Compound: `{ wallet_address: 1, token_address: 1, timestamp: -1 }`
  * Single: `{ timestamp: -1 }`

### 4. Vector Embeddings

#### 4.1. `vectors`

* **Purpose:** Stores vector embeddings for similarity search.
* **API Endpoint:** None (Internally generated).
* **Update Frequency:** As needed.
* **Schema:**

    ```json
    {
        "_id": objectId,
        "entity_type": string, // "token", "news_article", "tweet", "trading_strategy"
        "entity_id": string,   // Token address, URL, strategy ID, etc.
        "vector": [number],    // Array of numbers (embedding)
        "metadata": document,  // { timestamp: date, source: string, ... }
         "weights": {
              "vector": number,
              "metadata.timestamp": number
          },
          "name": string,
          "background": boolean
    }
    ```

* **Indexes:**
  * `{ "vector": "2dsphere", "metadata.timestamp": -1 }` (For geospatial and time-based similarity search)
  * `"weights": { "vector": 1, "metadata.timestamp": 1 }, "name": "vector_search_idx", "background": true`

### 5. Compliance Data (Optional)

#### 5.1. `compliance_records`

* **Purpose:** Stores compliance check records.
* **API Endpoint:** None (Internally generated).
* **Update Frequency:** Real-time.
* **Schema:**

    ```json
    {
        "_id": objectId,
        "transaction_hash": string,
        "check_type": string, // "KYC", "AML", "SanctionsList", "Jurisdiction"
        "result": string,    // "PASS", "FAIL", "PENDING"
        "timestamp": date,
        "details": document   // { reason: "...", flagged_address: "...", ... }
    }
    ```

* **Indexes:**
  * `{ transaction_hash: 1, timestamp: -1 }`
  * `{ check_type: 1, result: 1 }`


================================================
File: memory-bank/developmentWorkflow.md
================================================
# Development Workflow

Last Updated: 2025-02-11

## Implementation Plan

### Phase 1: Core Infrastructure (Current Phase)

#### Vector Store Implementation

- [x] MongoDB Atlas Setup
  - [x] Configure connection pooling
  - [x] Set up authentication
  - [x] Create collections

- [x] Vector Search Integration
  - [x] Create vector index
  - [x] Implement embedding storage
  - [x] Configure search parameters

- [ ] Token Analytics System
  - [x] Implement data models
  - [x] Add document insertion
  - [ ] Complete search functionality
  - [ ] Add comprehensive error handling

#### Next Steps: Agent System

- [ ] Complete trader agent implementation
  - [ ] Vector store integration
  - [ ] Market signal processing
  - [ ] Decision making logic

- [ ] Risk Management
  - [ ] Risk scoring system
  - [ ] Position monitoring
  - [ ] Portfolio analysis

### Current Focus

1. Vector Store Completion
   - Fix SearchParams configuration
   - Implement proper error handling
   - Add comprehensive logging
   - Complete testing suite

2. Agent Integration
   - Connect vector store to agent system
   - Implement market analysis
   - Add decision making logic

## Testing Strategy

### Unit Testing

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_vector_search() -> Result<()> {
        let pool = setup_test_pool().await?;
        let result = pool.top_n("test_collection", model, "query", 10).await?;
        assert!(!result.is_empty());
        Ok(())
    }
}
```

### Integration Testing

1. MongoDB Operations
   - Connection pool management
   - Document insertion
   - Vector search functionality
   - Error handling

2. Vector Store Integration
   - Embedding generation
   - Search accuracy
   - Performance metrics
   - Error scenarios

## Project Standards

### Code Organization

```
src/
├── config/       # Configuration (MongoDB, etc.)
├── models/       # Data models
├── services/     # Business logic
├── agent/        # Agent implementations
└── trading/      # Trading logic
```

### Error Handling

```rust
use anyhow::{Context, Result};

pub async fn search_tokens(query: &str) -> Result<Vec<TokenAnalytics>> {
    let results = pool.top_n("token_analytics", model, query, 10)
        .await
        .context("Failed to perform vector search")?;
    
    process_results(results)
        .context("Failed to process search results")?;
    
    Ok(results)
}
```

### MongoDB Integration

```rust
// Connection Pool Configuration
let pool_config = MongoPoolConfig {
    min_pool_size: 5,
    max_pool_size: 10,
    connect_timeout: Duration::from_secs(20),
};

// Vector Search Parameters
let search_params = SearchParams::new()
    .exact(true)
    .num_candidates(100)
    .fields(vec!["embedding"]);
```

## Monitoring and Maintenance

### Health Checks

- MongoDB connection status
- Vector search performance
- Error rates and types
- System resource usage

### Performance Metrics

- Search latency
- Connection pool utilization
- Document insertion rates
- Memory usage

### Error Handling

- Structured error logging
- MongoDB operation retries
- Connection error recovery
- Alert thresholds

### Maintenance Tasks

- Index optimization
- Connection pool monitoring
- Error log analysis
- Performance tuning


================================================
File: memory-bank/operationalContext.md
================================================
# Operational Context

Last Updated: 2025-01-30

## System Operation

### Core Services

1. **Market Data Service**

   ```rust
   pub struct MarketDataService {
       birdeye_client: BirdeyeClient,
       db_pool: PgPool,
       cache: Cache,
   }
   ```

   - Real-time price and volume monitoring
   - Historical data aggregation
   - Market trend analysis
   - Data validation and cleaning

2. **Trading Service**

   ```rust
   pub struct TradingService {
       engine: TradingEngine,
       risk_manager: RiskManager,
       solana_client: SolanaClient,
   }
   ```

   - Trade execution
   - Position management
   - Risk validation
   - Transaction signing

3. **Agent Coordination Service**

   ```rust
   pub struct AgentCoordinator {
       agents: Vec<Box<dyn Agent>>,
       message_bus: MessageBus,
       state_manager: StateManager,
   }
   ```

   - Agent lifecycle management
   - Inter-agent communication
   - State synchronization
   - Performance monitoring

### Error Handling Patterns

1. **Database Errors**

   ```rust
   #[derive(Error, Debug)]
   pub enum DatabaseError {
       #[error("Connection failed: {0}")]
       ConnectionError(String),
       #[error("Query failed: {0}")]
       QueryError(String),
       #[error("Data validation failed: {0}")]
       ValidationError(String),
   }
   ```

   - Connection retry logic
   - Query timeout handling
   - Data integrity checks

2. **API Errors**

   ```rust
   #[derive(Error, Debug)]
   pub enum ApiError {
       #[error("Rate limit exceeded")]
       RateLimitError,
       #[error("Authentication failed: {0}")]
       AuthError(String),
       #[error("Request failed: {0}")]
       RequestError(String),
   }
   ```

   - Rate limiting
   - Authentication handling
   - Request retries

3. **Trading Errors**

   ```rust
   #[derive(Error, Debug)]
   pub enum TradingError {
       #[error("Insufficient funds: {0}")]
       InsufficientFunds(String),
       #[error("Invalid trade: {0}")]
       InvalidTrade(String),
       #[error("Execution failed: {0}")]
       ExecutionError(String),
   }
   ```

   - Position validation
   - Balance checks
   - Transaction verification

### Infrastructure Requirements

1. **Database**
   - PostgreSQL 15+ with TimescaleDB
   - Minimum 16GB RAM
   - SSD storage
   - Regular backups
   - Connection pooling

2. **Network**
   - Low latency connection
   - Redundant connectivity
   - DDoS protection
   - SSL/TLS encryption

3. **Compute**
   - Multi-core CPU
   - Minimum 32GB RAM
   - Load balancing
   - Auto-scaling

### Performance Requirements

1. **Latency Targets**

   ```rust
   pub struct PerformanceMetrics {
       trade_execution_ms: u64,    // Target: < 500ms
       market_data_refresh_ms: u64, // Target: < 1000ms
       signal_processing_ms: u64,   // Target: < 200ms
       db_query_ms: u64,           // Target: < 100ms
   }
   ```

2. **Throughput Requirements**
   - 1000+ market signals/second
   - 100+ trades/minute
   - 10000+ database operations/second
   - 100+ concurrent agents

3. **Resource Utilization**
   - CPU: < 70% sustained
   - Memory: < 80% usage
   - Disk I/O: < 70% utilization
   - Network: < 50% capacity

## Monitoring and Alerting

### System Health Monitoring

```rust
pub struct HealthCheck {
    pub service: String,
    pub status: Status,
    pub last_check: DateTime<Utc>,
    pub metrics: HashMap<String, f64>,
}
```

1. **Service Health**
   - API availability
   - Database connectivity
   - Agent status
   - Memory usage

2. **Performance Metrics**
   - Trade execution latency
   - Market data freshness
   - Database query performance
   - Network latency

3. **Business Metrics**
   - Trade success rate
   - Agent performance
   - Portfolio returns
   - Risk exposure

### Alert Thresholds

1. **Critical Alerts**
   - Trade execution failures
   - Database connectivity issues
   - API authentication errors
   - Memory exhaustion

2. **Warning Alerts**
   - High latency
   - Elevated error rates
   - Resource utilization
   - Rate limit warnings

3. **Information Alerts**
   - Agent state changes
   - Database maintenance
   - Performance optimization
   - System updates

## Recovery Procedures

### 1. Database Recovery

```sql
-- Point-in-time recovery
SELECT * FROM market_signals
WHERE timestamp >= '2025-01-30 00:00:00'
  AND timestamp < '2025-01-30 01:00:00';

-- Reprocess failed trades
SELECT * FROM trade_executions
WHERE status = 'FAILED'
  AND execution_time > now() - interval '1 hour';
```

### 2. Service Recovery

```rust
impl RecoveryManager {
    async fn recover_service(&self) -> Result<()> {
        // 1. Stop affected service
        // 2. Verify dependencies
        // 3. Restore state
        // 4. Restart service
        // 5. Verify operation
    }
}
```

### 3. Data Integrity

```rust
impl DataValidator {
    async fn validate_market_data(&self) -> Result<()> {
        // 1. Check data consistency
        // 2. Verify calculations
        // 3. Compare with backup sources
        // 4. Report discrepancies
    }
}
```

## Maintenance Procedures

### 1. Database Maintenance

- Daily backup verification
- Weekly index optimization
- Monthly data archival
- Quarterly performance review

### 2. System Updates

- Security patches
- Dependency updates
- Performance optimizations
- Feature deployments

### 3. Monitoring Updates

- Alert threshold adjustments
- Metric collection tuning
- Dashboard updates
- Log rotation


================================================
File: memory-bank/productContext.md
================================================
# Project Brief

## Project Overview

Cainam Core is a Rust-based autonomous trading system for the Solana blockchain, focusing on market data collection, analysis, and automated trading execution.

## Core Requirements

### 1. Market Data Collection

- Capture trending tokens from Birdeye API
- Collect detailed token analytics
- Store historical market data
- Implement efficient data indexing

### 2. Market Analysis

- Calculate technical indicators
- Generate trading signals
- Assess market conditions
- Evaluate trading opportunities

### 3. Trading Automation

- Execute trades based on signals
- Manage portfolio positions
- Implement risk management
- Track trading performance

## Technical Goals

- Reliable data collection pipeline
- Efficient MongoDB integration
- Scalable architecture
- Robust error handling
- Comprehensive logging
- Performance optimization

## Project Scope

- Market data collection and storage
- Technical analysis implementation
- Trading signal generation
- Automated trade execution
- Performance monitoring
- Risk management system

## Success Criteria

- Accurate market data capture
- Reliable signal generation
- Efficient trade execution
- Scalable data storage
- Robust error handling
- Comprehensive monitoring


================================================
File: memory-bank/projectBoundaries.md
================================================
# Project Boundaries

Last Updated: 2025-01-30

## Technical Constraints

### 1. Performance Boundaries

#### Latency Requirements

- Trade execution: < 500ms end-to-end
- Market data updates: < 1s refresh rate
- Signal processing: < 200ms
- Database queries: < 100ms response time

#### Throughput Limits

- Maximum 100 concurrent agents
- Up to 1000 market signals per second
- Maximum 100 trades per minute
- Up to 10000 database operations per second

#### Resource Constraints

- Memory usage: < 32GB per instance
- CPU utilization: < 70% sustained
- Network bandwidth: < 1Gbps
- Storage: < 1TB active data

### 2. API Limitations

#### Birdeye API

- Rate limit: 10 requests/second
- Websocket connections: 5 max
- Data freshness: 1s minimum
- Historical data: 90 days

#### Helius API

- Webhook delivery: Best effort
- Transaction history: 30 days
- Rate limit: 100 requests/second
- Concurrent connections: 10 max

#### Solana RPC

- Transaction confirmation: 2-4s
- Rate limit: 40 requests/second
- Connection limit: 20 per IP
- Data size: 5MB max per request

### 3. Database Constraints

#### TimescaleDB

- Chunk interval: 1 day
- Retention period: 1 year
- Compression ratio: 10:1 target
- Query complexity: < 1000 rows scan

#### Qdrant

- Vector dimensions: 1536 max
- Index size: 1M vectors
- Query time: < 50ms
- Similarity threshold: 0.8

## Scale Requirements

### 1. Data Volume

```rust
pub struct DataVolume {
    market_signals_per_day: u64,    // 86_400_000
    trades_per_day: u64,            // 144_000
    token_analytics_per_day: u64,   // 2_160_000
    agent_metrics_per_day: u64,     // 144_000
}
```

### 2. System Scale

```rust
pub struct SystemScale {
    concurrent_agents: u32,         // 100
    active_markets: u32,            // 1000
    monitored_tokens: u32,          // 10000
    trading_pairs: u32,             // 100
}
```

### 3. Storage Requirements

```rust
pub struct StorageRequirements {
    market_data_per_day: u64,      // 10GB
    trade_data_per_day: u64,       // 1GB
    analytics_per_day: u64,        // 5GB
    log_data_per_day: u64,         // 2GB
}
```

## Hard Limitations

### 1. Trading Restrictions

```rust
pub struct TradingLimits {
    max_position_size: f64,        // 5% of portfolio
    min_trade_size: f64,           // $10 equivalent
    max_trades_per_minute: u32,    // 100
    max_slippage: f64,             // 1%
}
```

### 2. Risk Management

```rust
pub struct RiskLimits {
    max_portfolio_exposure: f64,    // 20%
    max_correlation: f64,           // 0.7
    min_confidence: f64,           // 0.8
    max_drawdown: f64,             // 10%
}
```

### 3. Technical Limits

```rust
pub struct TechnicalLimits {
    max_concurrent_requests: u32,   // 1000
    max_websocket_connections: u32, // 100
    max_database_connections: u32,  // 500
    max_memory_usage: u64,         // 32GB
}
```

## Non-Negotiables

### 1. Security Requirements

- All private keys must be securely stored
- All API communications must be encrypted
- Rate limiting must be enforced
- Access control for all operations

### 2. Data Integrity

- All trades must be verified
- Market data must be validated
- Database consistency must be maintained
- Audit trail for all operations

### 3. Reliability

- No single point of failure
- Automatic failover required
- Data backup mandatory
- Error recovery procedures required

## Future Considerations

### 1. Scalability

- Horizontal scaling of agents
- Distributed database deployment
- Load balancing implementation
- Cache layer addition

### 2. Feature Expansion

- Cross-chain integration
- Advanced analytics
- Machine learning models
- Social sentiment analysis

### 3. Performance Optimization

- Query optimization
- Caching strategies
- Network optimization
- Resource allocation

## Compliance Requirements

### 1. Data Retention

- Trade records: 7 years
- Market data: 1 year
- System logs: 90 days
- Error reports: 1 year

### 2. Audit Requirements

- All trades must be traceable
- Risk checks must be documented
- System changes must be logged
- Performance metrics must be stored

### 3. Reporting Requirements

- Daily performance reports
- Risk exposure analysis
- System health metrics
- Compliance verification


================================================
File: memory-bank/techContext.md
================================================
# Technical Context

## Core Technologies

### Backend
- Rust (2021 edition)
- Tokio async runtime
- MongoDB for data storage
- Birdeye API integration

### Database
- MongoDB Atlas
- Collections:
  - `trending_tokens`
  - `token_analytics`
  - Vector store support for embeddings
- Compound indexing for efficient queries

### APIs and Integration
- Birdeye API
  - Token trending data
  - Token analytics and market data
  - Rate limited with 500ms delay between requests

### Development Tools
- Cargo for build and dependency management
- Environment configuration via `.env`
- Tracing for logging and debugging

## Key Dependencies

### Core
```toml
anyhow = "1.0"
async-trait = "0.1"
bigdecimal = { version = "0.2", features = ["serde"] }
bson = "2.0"
mongodb = "3.2.1"
tokio = { version = "1", features = ["full"] }
```

### Blockchain
```toml
solana-sdk = "2.2.1"
solana-program = "2.2.1"
spl-token = "7.0"
```

### Utilities
```toml
tracing = "0.1"
serde = { version = "1.0", features = ["derive"] }
dotenvy = "0.15.7"
```

## Architecture Components

### Data Collection
1. Trending Token Capture
   - Fetches trending tokens from Birdeye
   - Stores in MongoDB with timestamps
   - Uses compound indexing for efficient queries

2. Token Analytics Processing
   - Processes trending tokens for detailed analytics
   - Calculates technical indicators
   - Stores comprehensive market data

### Services
- TokenAnalyticsService
- TokenDataService
- BirdeyeClient

## Development Setup
1. MongoDB Atlas cluster configuration
2. Environment variables in `.env`
3. Rust toolchain setup
4. Birdeye API key configuration

## Technical Constraints
- Birdeye API rate limits
- MongoDB Atlas connection limits
- Memory usage for vector operations
- Network latency considerations

## Vector Store Implementation

### MongoDB Atlas Setup

- Enabled Atlas Search for vector similarity search capabilities
- Created token_analytics collection with document structure for embeddings
- Implemented vector search index for efficient similarity search using cosine distance
- Added vector store integration with proper connection pooling

### Database Schema

The vector store implementation uses the following document structure:

```json
{
    "_id": ObjectId,
    "token_address": String,
    "token_name": String,
    "token_symbol": String,
    "embedding": Array<float>,
    "created_at": ISODate
}
```

### Search Configuration

Implemented MongoDB vector search with:

- Vector search index on embedding field
- Cosine similarity for distance calculation
- Configurable search parameters:
  - Exact matching option
  - Number of candidates
  - Field specification for embedding search

### Integration Notes

- Using OpenAI's text-embedding-3-small model (1536 dimensions)
- Configured with MongoDB Atlas Search for vector similarity
- Supports batch document insertion
- Includes proper connection pooling
- Implements retry logic for operations

### Current Implementation

1. MongoDB Connection Pool
   - Configurable min/max pool size
   - Connection timeout settings
   - Error handling for connection issues

2. Vector Store Operations
   - Document insertion with embeddings
   - Vector similarity search
   - Top-N query support
   - Proper error handling

3. Data Models
   - TokenAnalyticsData structure
   - Proper serialization/deserialization
   - ObjectId handling
   - Embedding field management

### Error Handling

- Comprehensive error types for MongoDB operations
- Connection error handling
- Vector store operation error handling
- Proper error propagation
- Logging integration with tracing

### Pending Improvements

1. SearchParams configuration refinement
2. Enhanced error context for vector operations
3. Additional logging for debugging
4. Performance optimization for batch operations
5. Connection pool monitoring


================================================
File: scripts/capture_token_analytics.rs
================================================
use anyhow::{Context, Result};
use cainam_core::{
    birdeye::api::{BirdeyeApi, BirdeyeClient},
    config::mongodb::{MongoConfig, MongoDbPool, MongoPoolConfig},
    models::trending_token::TrendingToken,
    services::token_analytics::TokenAnalyticsService,
};
use dotenvy::dotenv;
use futures::TryStreamExt;
use mongodb::bson::doc;
use std::sync::Arc;
use tokio;
use tracing::{error, info, Level};

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt()
        .with_max_level(Level::INFO)
        .with_target(false)
        .with_thread_ids(true)
        .with_file(true)
        .with_line_number(true)
        .init();

    info!("Starting token analytics capture...");

    // Load environment variables
    dotenv().ok();

    // Get MongoDB connection details
    let mongodb_uri = dotenvy::var("MONGODB_URI").context("MONGODB_URI must be set")?;
    let mongodb_database = dotenvy::var("MONGODB_DATABASE").context("MONGODB_DATABASE must be set")?;

    info!("Connecting to MongoDB at: {}", mongodb_uri);

    // Initialize MongoDB connection
    let config = MongoConfig {
        uri: mongodb_uri,
        database: mongodb_database.clone(),
        app_name: Some("token-analytics-capture".to_string()),
        pool_config: MongoPoolConfig::default(),
    };

    let db_pool = MongoDbPool::create_pool(config).await?;
    info!("Successfully connected to MongoDB");

    // Initialize Birdeye client
    let birdeye_api_key = dotenvy::var("BIRDEYE_API_KEY").context("BIRDEYE_API_KEY must be set")?;
    let birdeye_client = Arc::new(BirdeyeClient::new(birdeye_api_key.clone()));
    info!("Initialized Birdeye client");

    // Initialize TokenAnalyticsService
    let analytics_service =
        TokenAnalyticsService::new(db_pool.clone(), birdeye_client.clone(), None).await?;
    info!("Initialized TokenAnalyticsService");

    // Get database and collections
    let db = db_pool.database(&mongodb_database);
    let trending_collection = db.collection::<TrendingToken>("trending_tokens");

    // Get tokens from the trending_tokens collection
    info!("Fetching tokens from trending_tokens collection...");
    let filter = doc! {};
    let mut cursor = trending_collection.find(filter).await?;
    let mut processed = 0;
    let mut errors = 0;

    // Process each token
    while let Some(token) = cursor.try_next().await? {
        info!("Processing analytics for token: {} ({})", token.symbol, token.address);

        // First get basic token overview
        match birdeye_client.get_token_overview(&token.address).await {
            Ok(overview) => {
                info!(
                    "Got token overview for {}: price=${:.4}, mcap=${:.2}",
                    token.symbol,
                    overview.price,
                    overview.market_cap.unwrap_or_default()
                );

                // If overview looks good, fetch and store detailed analytics
                match analytics_service
                    .fetch_and_store_token_info(&token.symbol, &token.address)
                    .await
                {
                    Ok(_) => {
                        processed += 1;
                        info!("Successfully stored analytics for {}", token.symbol);
                    }
                    Err(e) => {
                        errors += 1;
                        error!("Failed to store analytics for {}: {}", token.symbol, e);
                    }
                }
            }
            Err(e) => {
                errors += 1;
                error!("Failed to get overview for {}: {}", token.symbol, e);
            }
        }

        // Add a small delay to respect rate limits
        tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
    }

    info!("Token analytics capture completed:");
    info!("Successfully processed: {}", processed);
    info!("Errors: {}", errors);

    Ok(())
}


================================================
File: scripts/capture_trending_tokens.rs
================================================
use anyhow::{Context, Result};
use cainam_core::{
    birdeye::api::{BirdeyeApi, BirdeyeClient},
    config::mongodb::{MongoConfig, MongoDbPool, MongoPoolConfig},
    models::trending_token::TrendingToken,
};
use dotenvy::dotenv;
use mongodb::bson::{doc, oid::ObjectId, DateTime};
use mongodb::IndexModel;
use std::sync::Arc;
use tokio;
use tracing::{info, Level};

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt()
        .with_max_level(Level::INFO)
        .with_target(false)
        .with_thread_ids(true)
        .with_file(true)
        .with_line_number(true)
        .init();

    info!("Starting trending tokens capture...");

    // Load environment variables
    dotenv().ok();

    // Get MongoDB connection details
    let mongodb_uri = dotenvy::var("MONGODB_URI").context("MONGODB_URI must be set")?;
    let mongodb_database = dotenvy::var("MONGODB_DATABASE").context("MONGODB_DATABASE must be set")?;

    info!("Connecting to MongoDB at: {}", mongodb_uri);

    // Initialize MongoDB connection
    let config = MongoConfig {
        uri: mongodb_uri,
        database: mongodb_database.clone(),
        app_name: Some("trending-tokens-capture".to_string()),
        pool_config: MongoPoolConfig::default(),
    };

    let db_pool = MongoDbPool::create_pool(config).await?;
        info!("Successfully connected to MongoDB");
    let db = db_pool.database(&mongodb_database);
        info!("Database: {}", db.name());

    // Initialize Birdeye client
    let birdeye_api_key = dotenvy::var("BIRDEYE_API_KEY").context("BIRDEYE_API_KEY must be set")?;

    let birdeye_client: Arc<dyn BirdeyeApi> = Arc::new(BirdeyeClient::new(birdeye_api_key));
    info!("Initialized Birdeye client");
    
    // Get trending tokens collection
    let trending_collection = db.collection::<TrendingToken>("trending_tokens");

    // Create compound index on address and timestamp
    let index = IndexModel::builder()
        .keys(doc! {
            "address": 1,
            "timestamp": -1
        })
        .build();

    trending_collection.create_index(index).await?;

    info!("Fetching trending tokens from Birdeye...");
    let trending_tokens = birdeye_client.get_trending_tokens().await?;
    let current_timestamp = DateTime::now();

    let mut tokens_stored = 0;
    for token in trending_tokens {
        // Add timestamp and id to token before storing
        let token_with_meta = TrendingToken {
            id: Some(ObjectId::new()),
            timestamp: Some(current_timestamp),
            address: token.address,
            decimals: token.decimals,
            liquidity: token.liquidity,
            logo_uri: token.logo_uri,
            name: token.name,
            symbol: token.symbol,
            volume_24h_usd: token.volume_24h_usd,
            rank: token.rank,
            price: token.price,
            volume_24h_change_percent: None,
            fdv: None,
            marketcap: None,
            price_24h_change_percent: None,
        };

        match trending_collection.insert_one(token_with_meta).await {
            Ok(_) => tokens_stored += 1,
            Err(e) => info!("Error inserting token: {}", e),
        }
    }

    info!("Successfully captured {} trending tokens", tokens_stored);
    Ok(())
}


================================================
File: scripts/setup_mongodb.rs
================================================
#![recursion_limit = "256"]

use anyhow::{Context, Result};
use cainam_core::config::mongodb::{MongoConfig, MongoDbPool, MongoPoolConfig};
use dotenvy::dotenv;
use mongodb::bson::doc;
use tracing::{info, Level};

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize tracing
    tracing_subscriber::fmt()
        .with_max_level(Level::INFO)
        .with_target(false)
        .with_thread_ids(true)
        .with_file(true)
        .with_line_number(true)
        .init();

    info!("Starting MongoDB setup...");

    // Load environment variables
    dotenv().ok();

    // Get MongoDB connection details
    let mongodb_uri = dotenvy::var("MONGODB_URI")
        .context("MONGODB_URI must be set")?;
    let mongodb_database = dotenvy::var("MONGODB_DATABASE")
        .context("MONGODB_DATABASE must be set")?;

    info!("Connecting to MongoDB at: {}", mongodb_uri);

    // Initialize MongoDB connection
    let config = MongoConfig {
        uri: mongodb_uri,
        database: mongodb_database.clone(),
        app_name: Some("mongodb-setup".to_string()),
        pool_config: MongoPoolConfig::default(),
    };

    let db_pool = MongoDbPool::create_pool(config).await?;
    let db = db_pool.database(&mongodb_database);
    info!("Successfully connected to MongoDB");

    // Drop existing time series collections
    info!("Dropping existing time series collections...");
    match db.run_command(doc! { "drop": "trending_tokens" }).await {
        Ok(_) => info!("Dropped trending_tokens collection"),
        Err(e) => info!("Error dropping trending_tokens: {}", e),
    }
    match db.run_command(doc! { "drop": "token_analytics" }).await {
        Ok(_) => info!("Dropped token_analytics collection"),
        Err(e) => info!("Error dropping token_analytics: {}", e),
    }

    // Setup trending_tokens collection
    info!("Setting up trending_tokens collection...");
    match db
        .run_command(doc! {
            "create": "trending_tokens"
        })
        .await
    {
        Ok(_) => info!("Created trending_tokens collection"),
        Err(e) => info!("trending_tokens collection may already exist: {}", e),
    }

    // Create compound index for time-based queries
    match db
        .run_command(doc! {
            "createIndexes": "trending_tokens",
            "indexes": [{
                "key": { "timestamp": -1 },
                "name": "timestamp_desc"
            }]
        })
        .await
    {
        Ok(_) => info!("Created timestamp index for trending_tokens"),
        Err(e) => info!("Index may already exist: {}", e),
    }

    // Create search index for trending_tokens
    info!("Setting up search index for trending_tokens...");
    match db
        .run_command(doc! {
            "createSearchIndexes": "trending_tokens",
            "indexes": [{
                "name": "trending_tokens_index",
                "definition": {
                    "mappings": {
                        "dynamic": true,
                        "fields": {
                            "address": { "type": "string" },
                            "decimals": { "type": "number" },
                            "liquidity": { "type": "number" },
                            "logo_uri": { "type": "string" },
                            "name": { "type": "string" },
                            "symbol": { "type": "string" },
                            "volume_24h_usd": { "type": "number" },
                            "volume_24h_change_percent": { "type": "number" },
                            "fdv": { "type": "number" },
                            "marketcap": { "type": "number" },
                            "rank": { "type": "number" },
                            "price": { "type": "number" },
                            "price_24h_change_percent": { "type": "number" },
                            "timestamp": { "type": "date" }
                        }
                    }
                }
            }]
        })
        .await
    {
        Ok(_) => info!("Created search index for trending_tokens"),
        Err(e) => info!("Search index may already exist: {}", e),
    }

    // Setup token_analytics collection
    info!("Setting up token_analytics collection...");
    match db
        .run_command(doc! {
            "create": "token_analytics"
        })
        .await
    {
        Ok(_) => info!("Created token_analytics collection"),
        Err(e) => info!("token_analytics collection may already exist: {}", e),
    }

    // Create compound index for time-based queries
    match db
        .run_command(doc! {
            "createIndexes": "token_analytics",
            "indexes": [{
                "key": { "token_address": 1, "timestamp": -1 },
                "name": "token_time_desc"
            }]
        })
        .await
    {
        Ok(_) => info!("Created token_time index for token_analytics"),
        Err(e) => info!("Index may already exist: {}", e),
    }

    // Create search index for token_analytics
    info!("Setting up search index for token_analytics...");
    match db
        .run_command(doc! {
            "createSearchIndexes": "token_analytics",
            "indexes": [{
                "name": "token_analytics_index",
                "definition": {
                    "mappings": {
                        "dynamic": true,
                        "fields": {
                            "token_address": { "type": "string"},
                            "token_name": { "type": "string"},
                            "token_symbol": { "type": "string"},
                            "timestamp": { "type": "date" },
                            "liquidity": { "type": "number" },
                            "volume_24h": { "type": "number" },
                            "volume_change_24h": { "type": "number" },
                            "market_cap": { "type": "number" },
                            "fully_diluted_market_cap": { "type": "number" },
                            "price": { "type": "number" },
                            "price_change_24h": { "type": "number" },
                            "rsi_14": { "type": "number" },
                            "macd": { "type": "number" },
                            "macd_signal": { "type": "number" },
                            "bollinger_upper": { "type": "number" },
                            "bollinger_lower": { "type": "number" }
                        }
                    }
                }
            }]
        })
        .await
    {
        Ok(_) => info!("Created search index for token_analytics"),
        Err(e) => info!("Search index may already exist: {}", e),
    }

    // Setup market_signals collection
    info!("Setting up market_signals collection...");
    match db
        .run_command(doc! {
            "create": "market_signals"
        })
        .await
    {
        Ok(_) => info!("Created market_signals collection"),
        Err(e) => info!("market_signals collection may already exist: {}", e),
    }

    // Create search index for market_signals
    info!("Setting up search index for market_signals...");
    match db
        .run_command(doc! {
            "createSearchIndexes": "market_signals",
            "indexes": [{
                "name": "market_signals_index",
                "definition": {
                    "mappings": {
                        "dynamic": true,
                        "fields": {
                            "token_address": { "type": "string"},
                            "signal_type": { "type": "string"},
                            "timestamp": { "type": "date" },
                            "price": { "type": "number" },
                            "price_change_24h": { "type": "number" },
                            "volume_change_24h": { "type": "number" },
                            "confidence": { "type": "number" },
                            "risk_score": { "type": "number" }
                        }
                    }
                }
            }]
        })
        .await
    {
        Ok(_) => info!("Created search index for market_signals"),
        Err(e) => info!("Search index may already exist: {}", e),
    }

    // Setup trading_positions collection
    info!("Setting up trading_positions collection...");
    match db
        .run_command(doc! {
            "create": "trading_positions"
        })
        .await
    {
        Ok(_) => info!("Created trading_positions collection"),
        Err(e) => info!("trading_positions collection may already exist: {}", e),
    }

    // Create search index for trading_positions
    info!("Setting up search index for trading_positions...");
    match db
        .run_command(doc! {
            "createSearchIndexes": "trading_positions",
            "indexes": [{
                "name": "trading_positions_index",
                "definition": {
                    "mappings": {
                        "dynamic": true,
                        "fields": {
                            "token_address": { "type": "string"},
                            "position_type": { "type": "string"},
                            "status": { "type": "string"},
                            "timestamp": { "type": "date" },
                            "entry_price": { "type": "number" },
                            "current_price": { "type": "number" },
                            "size": { "type": "number" },
                            "pnl": { "type": "number" }
                        }
                    }
                }
            }]
        })
        .await
    {
        Ok(_) => info!("Created search index for trading_positions"),
        Err(e) => info!("Search index may already exist: {}", e),
    }

    info!("MongoDB setup completed successfully!");
    Ok(())
}


================================================
File: src/error.rs
================================================
use mongodb::error::Error as MongoError;
use std::error::Error as StdError;
use std::fmt;
use std::num::ParseFloatError;
use thiserror::Error;
#[derive(Error, Debug)]
pub enum Error {
    #[error("MongoDB error: {0}")]
    Mongo(#[from] MongoError),
    #[error("ParseFloat error: {0}")]
    ParseFloat(#[from] ParseFloatError),
    #[error("Other error: {0}")]
    Other(String),
}

#[derive(Debug)]
pub enum AgentError {
    Config(String),
    MissingEnvVar(String),
    InvalidConfig(String, String),
    TwitterApi(String),
    Trading(String),
    Database(MongoError),
    MarketAnalysis(String),
    VectorStore(String),
    BirdeyeApi(String),
    Transaction(String),
    Validation(String),
    Parse(String),
    RateLimit(String),
    Authentication(String),
    Network(String),
    Timeout(String),
    Conversion(String),
    Other(anyhow::Error),
    Mongo(mongodb::error::Error),
    InvalidInput(String),
    ApiError(String),
}

impl fmt::Display for AgentError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            AgentError::Config(msg) => write!(f, "Configuration error: {}", msg),
            AgentError::MissingEnvVar(var) => write!(f, "Environment variable '{}' not found", var),
            AgentError::InvalidConfig(field, msg) => {
                write!(f, "Invalid value for {}: {}", field, msg)
            }
            AgentError::TwitterApi(msg) => write!(f, "Twitter API error: {}", msg),
            AgentError::Trading(msg) => write!(f, "Trading error: {}", msg),
            AgentError::Database(err) => write!(f, "Database error: {}", err),
            AgentError::MarketAnalysis(msg) => write!(f, "Market analysis error: {}", msg),
            AgentError::VectorStore(msg) => write!(f, "Vector store error: {}", msg),
            AgentError::BirdeyeApi(msg) => write!(f, "Birdeye API error: {}", msg),
            AgentError::Transaction(msg) => write!(f, "Transaction error: {}", msg),
            AgentError::Validation(msg) => write!(f, "Validation error: {}", msg),
            AgentError::Parse(msg) => write!(f, "Parse error: {}", msg),
            AgentError::RateLimit(service) => write!(f, "Rate limit exceeded for {}", service),
            AgentError::Authentication(msg) => write!(f, "Authentication error: {}", msg),
            AgentError::Network(msg) => write!(f, "Network error: {}", msg),
            AgentError::Timeout(msg) => write!(f, "Timeout error: {}", msg),
            AgentError::Conversion(msg) => write!(f, "Conversion error: {}", msg),
            AgentError::Other(err) => write!(f, "Other error: {}", err),
            AgentError::Mongo(err) => write!(f, "MongoDB error: {}", err),
            AgentError::InvalidInput(err) => write!(f, "Input error: {}", err),
            AgentError::ApiError(err) => write!(f, "Api error: {}", err),
        }
    }
}

impl StdError for AgentError {
    fn source(&self) -> Option<&(dyn StdError + 'static)> {
        match self {
            AgentError::Database(err) => Some(err),
            AgentError::Mongo(err) => Some(err),
            _ => None,
        }
    }
}

impl From<MongoError> for AgentError {
    fn from(err: MongoError) -> Self {
        AgentError::Mongo(err)
    }
}

impl From<ParseFloatError> for AgentError {
    fn from(err: ParseFloatError) -> Self {
        AgentError::Parse(err.to_string())
    }
}

impl From<tracing_subscriber::filter::ParseError> for AgentError {
    fn from(err: tracing_subscriber::filter::ParseError) -> Self {
        AgentError::Parse(err.to_string())
    }
}

impl From<reqwest::Error> for AgentError {
    fn from(err: reqwest::Error) -> Self {
        if err.is_timeout() {
            AgentError::Timeout(err.to_string())
        } else if err.is_connect() {
            AgentError::Network(err.to_string())
        } else {
            AgentError::Other(err.into())
        }
    }
}

pub type AgentResult<T> = Result<T, AgentError>;

// Helper functions for common error cases
impl AgentError {
    pub fn missing_env(var: &str) -> Self {
        AgentError::MissingEnvVar(var.to_string())
    }

    pub fn invalid_config<T: std::fmt::Display>(field: &str, message: T) -> Self {
        AgentError::InvalidConfig(field.to_string(), message.to_string())
    }

    pub fn validation<T: std::fmt::Display>(message: T) -> Self {
        AgentError::Validation(message.to_string())
    }

    pub fn transaction<T: std::fmt::Display>(message: T) -> Self {
        AgentError::Transaction(message.to_string())
    }

    pub fn rate_limit<T: std::fmt::Display>(service: T) -> Self {
        AgentError::RateLimit(service.to_string())
    }

    pub fn auth<T: std::fmt::Display>(message: T) -> Self {
        AgentError::Authentication(message.to_string())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_error_conversions() {
        // Test ParseFloatError conversion
        let parse_err: AgentError = "invalid float".parse::<f64>().unwrap_err().into();
        assert!(matches!(parse_err, AgentError::Parse(_)));

        // Test helper functions
        let missing_env = AgentError::missing_env("TEST_VAR");
        assert!(matches!(missing_env, AgentError::MissingEnvVar(_)));

        let invalid_config = AgentError::invalid_config("threshold", "must be positive");
        assert!(matches!(invalid_config, AgentError::InvalidConfig(_, _)));

        let validation = AgentError::validation("invalid input");
        assert!(matches!(validation, AgentError::Validation(_)));

        let transaction = AgentError::transaction("commit failed");
        assert!(matches!(transaction, AgentError::Transaction(_)));

        let rate_limit = AgentError::rate_limit("Birdeye API");
        assert!(matches!(rate_limit, AgentError::RateLimit(_)));

        let auth = AgentError::auth("invalid credentials");
        assert!(matches!(auth, AgentError::Authentication(_)));
    }

    #[test]
    fn test_error_display() {
        let err = AgentError::missing_env("TEST_VAR");
        assert_eq!(err.to_string(), "Environment variable 'TEST_VAR' not found");

        let err = AgentError::invalid_config("threshold", "must be positive");
        assert_eq!(
            err.to_string(),
            "Invalid value for threshold: must be positive"
        );

        let err = AgentError::validation("invalid input");
        assert_eq!(err.to_string(), "Validation error: invalid input");
    }
}


================================================
File: src/lib.rs
================================================
pub mod agent;
pub mod birdeye;
pub mod config;
pub mod error;
pub mod logging;
pub mod models;
pub mod services;
pub mod trading;
pub mod twitter;
pub mod utils;

// Re-export commonly used types
pub use crate::config::{
    AgentConfig,
    BirdeyeConfig,
    MarketConfig,
    get_log_level,
    get_openai_model,
    mongodb::{MongoConfig, MongoDbPool, MongoPoolConfig},
};


================================================
File: src/main.rs
================================================
use crate::{
    agent::trader::TradingAgent,
    config::AgentConfig,
    models::market_signal::{MarketSignal, SignalType},
    trading::SolanaAgentKit,
    utils::f64_to_decimal,
};
use anyhow::Result;
use bson::DateTime;
use config::mongodb::{MongoConfig, MongoDbPool, MongoPoolConfig};
use solana_sdk::signature::Keypair;
use std::io::{self, Write};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use tracing::{error, info};

mod agent;
mod birdeye;
mod config;
mod error;
mod logging;
mod models;
mod services;
mod trading;
mod twitter;
mod utils;

async fn handle_user_input(
    trader: Arc<TradingAgent>,
    config: AgentConfig,
    running: Arc<AtomicBool>,
) {
    println!("\n=== Cainam Trading Agent ===");
    println!("The agent is running autonomously in the background.");
    println!("\nAvailable commands:");
    println!("  analyze <symbol> <address>    - Analyze market for a token");
    println!("  trade <symbol> <buy|sell> <amount>  - Execute a trade");
    println!("  status                        - Get current trading status");
    println!("  exit                          - Exit the program");
    println!("\nType a command and press Enter.\n");

    loop {
        if !running.load(Ordering::SeqCst) {
            break;
        }

        print!("> ");
        io::stdout().flush().expect("Failed to flush stdout");

        let mut input = String::new();
        match io::stdin().read_line(&mut input) {
            Ok(_) => {
                let parts: Vec<String> = input.split_whitespace().map(String::from).collect();

                if parts.is_empty() {
                    continue;
                }

                match parts[0].as_str() {
                    "analyze" => {
                        if parts.len() != 3 {
                            println!("Usage: analyze <symbol> <address>");
                            continue;
                        }
                        println!("Analyzing market for {}...", parts[1]);
                        tokio::spawn({
                            let trader = trader.clone();
                            let symbol = parts[1].clone();
                            let address = parts[2].clone();
                            async move {
                                match trader.analyze_market(&symbol, &address).await {
                                    Ok(Some(signal)) => {
                                        println!("\nMarket Analysis Result:");
                                        println!("  Signal: {:?}", signal.signal_type);
                                        println!("  Confidence: {:.2}", signal.confidence);
                                        println!("  Risk Score: {:.2}", signal.risk_score);
                                    }
                                    Ok(None) => println!("\nNo trading signals generated"),
                                    Err(e) => println!("\nAnalysis failed: {}", e),
                                }
                            }
                        });
                    }
                    "trade" => {
                        if parts.len() != 4 {
                            println!("Usage: trade <symbol> <buy|sell> <amount>");
                            continue;
                        }
                        let amount = match parts[3].parse::<f64>() {
                            Ok(val) => val,
                            Err(_) => {
                                println!("Invalid amount. Please provide a valid number.");
                                continue;
                            }
                        };

                        let signal_type = match parts[2].to_uppercase().as_str() {
                            "BUY" => SignalType::StrongBuy,
                            "SELL" => SignalType::StrongSell,
                            _ => {
                                println!("Invalid trade type. Use 'buy' or 'sell'");
                                continue;
                            }
                        };

                        println!("Executing {} trade for {}...", parts[2], parts[1]);
                        tokio::spawn({
                            let trader = trader.clone();
                            let symbol = parts[1].clone();
                            async move {
                                let signal = MarketSignal {
                                    id: None,
                                    asset_address: symbol.clone(),
                                    signal_type: signal_type.clone(),
                                    confidence: f64_to_decimal(0.8),
                                    risk_score: f64_to_decimal(0.2),
                                    sentiment_score: Some(f64_to_decimal(0.6)),
                                    volume_change_24h: Some(f64_to_decimal(0.15)),
                                    price_change_24h: Some(f64_to_decimal(
                                        if signal_type == SignalType::StrongBuy {
                                            0.05
                                        } else {
                                            -0.05
                                        },
                                    )),
                                    price: f64_to_decimal(10.0),
                                    volume_change: f64_to_decimal(0.2),
                                    timestamp: DateTime::now(),
                                    metadata: None,
                                    created_at: None,
                                };

                                let min_confidence = f64_to_decimal(config.trade_min_confidence);
                                if signal.confidence >= min_confidence {
                                    match trader.execute_trade(&symbol, &signal).await {
                                        Ok(signature) => {
                                            println!("\nTrade executed successfully!");
                                            println!("Transaction: {}", signature);
                                            if let Err(e) = trader
                                                .post_trade_update(
                                                    &symbol,
                                                    &parts[2],
                                                    amount,
                                                    &signal_type,
                                                )
                                                .await
                                            {
                                                println!("Failed to post trade update: {}", e);
                                            }
                                        }
                                        Err(e) => println!("\nTrade execution failed: {}", e),
                                    }
                                }
                            }
                        });
                    }
                    "status" => {
                        println!("\nTrading Agent Status:");
                        println!("  State: Active");
                        println!("  Analysis Interval: {:?}", config.analysis_interval);
                        println!("  Min Confidence: {:.2}", config.trade_min_confidence);
                        println!("  Max Trade Amount: {:.2}", config.trade_max_amount);
                    }
                    "exit" => {
                        println!("\nShutting down trading agent...");
                        running.store(false, Ordering::SeqCst);
                        break;
                    }
                    _ => println!("Unknown command. Type 'help' for available commands."),
                }
            }
            Err(e) => {
                error!("Error reading input: {}", e);
                break;
            }
        }
    }
}

async fn init_mongodb() -> Result<Arc<MongoDbPool>> {
    info!("Initializing MongoDB connection...");
    let config = MongoConfig {
        uri: std::env::var("MONGODB_URI")
            .unwrap_or_else(|_| "mongodb://localhost:32770".to_string()),
        database: std::env::var("MONGODB_DATABASE").unwrap_or_else(|_| "cainam".to_string()),
        app_name: std::env::var("MONGODB_APP_NAME").ok(),
        pool_config: MongoPoolConfig::from_env(),
    };

    info!("Connecting to MongoDB at {}", config.uri);
    let pool = MongoDbPool::create_pool(config).await?;
    info!("Successfully connected to MongoDB");
    Ok(pool)
}

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize logging
    // logging::init_logging()?;

    println!("Starting Cainam Core...");

    // Load environment variables from .env file
    dotenvy::dotenv().ok();
    println!("Loading env file...");

    // Initialize MongoDB connection pool using rig-mongodb
    let db_pool = init_mongodb().await?;
    println!("Initialized MongoDB connection pool");

    // TODO: zTgx hardcoded
    // Initialize Solana agent
    let rpc_url = std::env::var("SOLANA_RPC_URL").unwrap_or_else(|_| "https://api.devnet.solana.com".to_string());
    let private_key = std::env::var("SOLANA_PRIVATE_KEY").expect("SOLANA_PRIVATE_KEY not found in environment");
    let keypair = Keypair::from_base58_string(&private_key);
    let solana_agent = SolanaAgentKit::new(&rpc_url, keypair);

    // Load configuration from environment
    let config = AgentConfig::new_from_env()?;

    // Initialize trading agent
    let trader = Arc::new(TradingAgent::new(config.clone(), db_pool, solana_agent).await?);
    let running = Arc::new(AtomicBool::new(true));

    // Initialize services with MongoDB pool
    // let token_analytics_service = TokenAnalyticsService::new(
    //     db_pool.clone(),
    //     birdeye.clone(),
    //     birdeye_extended.clone(),
    //     Some(market_config.clone()),
    // ).await?;

    // let portfolio_optimizer = PortfolioOptimizer::new(db_pool.clone());

    // // Initialize vector store
    // let vector_store = VectorStore::new().await?;

    // // Spawn the autonomous trading agent
    // let trader_clone = trader.clone();
    // let running_clone = running.clone();
    // let trading_handle = tokio::spawn(async move {
    //     info!("Starting autonomous trading...");
    //     if let Err(e) = trader_clone.run().await {
    //         error!("Trading agent error: {}", e);
    //         running_clone.store(false, Ordering::SeqCst);
    //     }
    // });

    // Handle user input in a separate task
    let input_handle = tokio::spawn(handle_user_input(trader.clone(), config, running.clone()));

    // Wait for either task to complete
    tokio::select! {
        // _ = trading_handle => {
        //     info!("Trading task completed");
        // }
        _ = input_handle => {
            info!("User input task completed");
        }
    }

    // Wait for clean shutdown
    info!("Shutting down trading agent...");
    running.store(false, Ordering::SeqCst);
    trader.stop();

    Ok(())
}


================================================
File: src/memory.rs
================================================
use serde_json;
use std::fs;
use std::io::{self, Write};
use std::path::Path;

pub struct MemoryStore;

impl MemoryStore {
    const FILE_PATH: &'static str = "./storage/memory.json";

    // Load memory from file
    pub fn load_memory() -> io::Result<Vec<String>> {
        if Path::new(Self::FILE_PATH).exists() {
            let data = fs::read_to_string(Self::FILE_PATH)?;
            let memory: Vec<String> = serde_json::from_str(&data)?;
            Ok(memory)
        } else {
            Ok(Vec::new()) // Return an empty vector if file doesn't exist
        }
    }

    // Add to memory
    pub fn add_to_memory(memory: &mut Vec<String>, item: &str) -> Result<(), String> {
        if !memory.contains(&item.to_string()) {
            memory.push(item.to_string());
            let _ = Self::save_memory(memory);
            Ok(())
        } else {
            Err("Memory Exists!".to_string())
        }
    }

    // Wipe memory
    pub fn wipe_memory(memory: &mut Vec<String>) -> io::Result<()> {
        memory.clear();
        Self::save_memory(memory)
    }

    // Count memories
    pub fn count_memories(memory: &Vec<String>) -> usize {
        memory.len()
    }

    // Save memory to file
    pub fn save_memory(memory: &Vec<String>) -> io::Result<()> {
        let data = serde_json::to_string(memory)?;
        let mut file = fs::File::create(Self::FILE_PATH)?;
        file.write_all(data.as_bytes())?;
        Ok(())
    }

    // Get current memory
    pub fn get_memory() -> io::Result<Vec<String>> {
        Self::load_memory()
    }
}


================================================
File: src/actions/helius/create_webhook.rs
================================================
use crate::SolanaAgentKit;
use serde::{Deserialize, Serialize};

#[derive(Deserialize, Serialize)]
pub struct HeliusWebhookResponse {
    pub webhook_url: String,
    pub webhook_id: String,
}

pub async fn create_webhook(
    agent: &SolanaAgentKit,
    account_addresses: Vec<String>,
    webhook_url: String,
) -> Result<HeliusWebhookResponse, Box<dyn std::error::Error>> {
    // Get the Helius API key from the agent's configuration
    let api_key = match agent.config.helius_api_key.as_ref() {
        Some(key) => key,
        None => return Err("Missing Helius API key in agent.config.HELIUS_API_KEY".into()),
    };

    let url = format!("https://api.helius.xyz/v0/webhooks?api-key={}", api_key);

    let body = serde_json::json!({
        "webhookURL": webhook_url,
        "transactionTypes": ["Any"],
        "accountAddresses": account_addresses,
        "webhookType": "enhanced",
        "txnStatus": "all",
    });

    let client = reqwest::Client::new();
    let response = client.post(url).header("Content-Type", "application/json").json(&body).send().await?;

    let data = response.json::<serde_json::Value>().await?;
    let webhook_url = data.get("webhookURL").expect("webhookURL field").as_str().expect("webhookURL text");
    let webhook_id = data.get("webhookID").expect("webhookID field").as_str().expect("webhookID text");

    Ok(HeliusWebhookResponse { webhook_url: webhook_url.to_string(), webhook_id: webhook_id.to_string() })
}


================================================
File: src/actions/helius/delete_webhook.rs
================================================
use crate::SolanaAgentKit;

/// Deletes a Helius Webhook by its ID.
///
/// # Arguments
/// * `agent` - An instance of SolanaAgentKit (with .config.HELIUS_API_KEY)
/// * `webhook_id` - The unique ID of the webhook to delete
///
/// # Returns
/// The response body from the Helius API (which may contain status or other info)
pub async fn delete_webhook(
    agent: &SolanaAgentKit,
    webhook_id: &str,
) -> Result<serde_json::Value, Box<dyn std::error::Error>> {
    // Get the Helius API key from the agent's configuration
    let api_key = match agent.config.helius_api_key.as_ref() {
        Some(key) => key,
        None => return Err("Missing Helius API key in agent.config.HELIUS_API_KEY".into()),
    };

    // Construct the URL for the DELETE request
    let url = format!("https://api.helius.xyz/v0/webhooks/{}?api-key={}", webhook_id, api_key);

    // Create an HTTP client
    let client = reqwest::Client::new();

    // Send the DELETE request
    let response = client.delete(&url).header("Content-Type", "application/json").send().await?;

    // Check if the request was successful
    if !response.status().is_success() {
        return Err(format!(
            "Failed to delete webhook: {} {}",
            response.status(),
            response.status().canonical_reason().unwrap_or("Unknown")
        )
        .into());
    }

    // Handle different response status codes
    if response.status().as_u16() == 204 {
        return Ok(serde_json::json!({"message": "Webhook deleted successfully (no content returned)"}));
    }

    // Check if the response body is empty
    let content_length = response.headers().get("Content-Length");
    if content_length.is_none() || content_length.expect("HeaderValue").to_str()? == "0" {
        return Ok(serde_json::json!({"message": "Webhook deleted successfully (empty body)"}));
    }

    // Parse the response body as JSON
    let data: serde_json::Value = response.json().await?;
    Ok(data)
}


================================================
File: src/actions/helius/get_assets_by_owner.rs
================================================
use crate::SolanaAgentKit;
use serde_json::json;

pub async fn get_assets_by_owner(
    agent: &SolanaAgentKit,
    owner_public_key: &str,
    limit: u32,
) -> Result<serde_json::Value, Box<dyn std::error::Error>> {
    // Get the Helius API key from the agent's configuration
    let api_key = match agent.config.helius_api_key.as_ref() {
        Some(key) => key,
        None => return Err("Missing Helius API key in agent.config.HELIUS_API_KEY".into()),
    };

    let url = format!("https://mainnet.helius-rpc.com/?api-key={}", api_key);

    let client = reqwest::Client::new();

    let request_body = json!({
        "jsonrpc": "2.0",
        "id": "get-assets",
        "method": "getAssetsByOwner",
        "params": json!({
            "ownerAddress": owner_public_key,
            "page": 3,
            "limit": limit,
            "displayOptions": { "showFungible": true },
        }),
    });

    let response = client.post(&url).header("Content-Type", "application/json").json(&request_body).send().await?;

    if !response.status().is_success() {
        return Err(format!(
            "Failed to fetch: {} - {}",
            response.status(),
            response.status().canonical_reason().unwrap_or("Unknown")
        )
        .into());
    }

    let data: serde_json::Value = response.json().await?;

    Ok(data)
}


================================================
File: src/actions/helius/get_webhook.rs
================================================
use crate::SolanaAgentKit;
use serde::{Deserialize, Serialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct HeliusWebhookIdResponse {
    pub wallet: String,
    pub webhook_url: String,
    pub transaction_types: Vec<String>,
    pub account_addresses: Vec<String>,
    pub webhook_type: String,
}

/// Retrieves a Helius Webhook by ID, returning only the specified fields.
///
/// # Arguments
/// * `agent` - An instance of SolanaAgentKit (with .config.HELIUS_API_KEY)
/// * `webhook_id` - The unique ID of the webhook to delete
///
/// # Returns
/// A HeliusWebhook object containing { wallet, webhookURL, transactionTypes, accountAddresses, webhookType }
pub async fn get_webhook(
    agent: &SolanaAgentKit,
    webhook_id: &str,
) -> Result<HeliusWebhookIdResponse, Box<dyn std::error::Error>> {
    // Get the Helius API key from the agent's configuration
    let api_key = match agent.config.helius_api_key.as_ref() {
        Some(key) => key,
        None => return Err("Missing Helius API key in agent.config.HELIUS_API_KEY".into()),
    };

    let client = reqwest::Client::new();
    let url = format!("https://api.helius.xyz/v0/webhooks/{}?api-key={}", webhook_id, api_key);

    let response = client.get(url).header("Content-Type", "application/json").send().await?;

    let data = response.json::<HeliusWebhookIdResponse>().await?;
    Ok(data)
}


================================================
File: src/actions/helius/mod.rs
================================================
mod create_webhook;
pub use create_webhook::{create_webhook, HeliusWebhookResponse};

mod delete_webhook;
pub use delete_webhook::delete_webhook;

mod get_webhook;
pub use get_webhook::{get_webhook, HeliusWebhookIdResponse};

mod transaction_parsing;
pub use transaction_parsing::transaction_parse;

mod get_assets_by_owner;
pub use get_assets_by_owner::get_assets_by_owner;


================================================
File: src/actions/helius/transaction_parsing.rs
================================================
use crate::SolanaAgentKit;
use serde::{Deserialize, Serialize};
use serde_json::json;

#[derive(Debug, Serialize, Deserialize)]
pub struct HeliusWebhookIdResponse {
    pub wallet: String,
    pub webhook_url: String,
    pub transaction_types: Vec<String>,
    pub account_addresses: Vec<String>,
    pub webhook_type: String,
}

/// Parse a Solana transaction using the Helius Enhanced Transactions API
///
/// # Arguments
/// * `agent` - An instance of SolanaAgentKit (with .config.HELIUS_API_KEY)
/// * `transaction_id` - The transaction ID to parse
///
/// # Returns
/// Parsed transaction data
pub async fn transaction_parse(
    agent: &SolanaAgentKit,
    transaction_id: &str,
) -> Result<serde_json::Value, Box<dyn std::error::Error>> {
    // Get the Helius API key from the agent's configuration
    let api_key = match agent.config.helius_api_key.as_ref() {
        Some(key) => key,
        None => return Err("Missing Helius API key in agent.config.HELIUS_API_KEY".into()),
    };

    let client = reqwest::Client::new();
    let url = format!("https://api.helius.xyz/v0/transactions/?api-key={}", api_key);

    let body = json!( {
        "transactions": vec![transaction_id.to_string()],
    });

    let response = client.post(url).header("Content-Type", "application/json").json(&body).send().await?;

    let data = response.json().await?;
    Ok(data)
}


================================================
File: src/actions/solana/close_empty_token_accounts.rs
================================================
use crate::{primitives::USDC, SolanaAgentKit};
use anyhow::{anyhow, Context, Result};
use solana_client::rpc_request::TokenAccountsFilter;
use solana_sdk::{instruction::Instruction, pubkey::Pubkey, transaction::Transaction};
use spl_token::instruction::close_account;
use std::str::FromStr;

use serde::{Deserialize, Serialize};

#[derive(serde::Deserialize)]
pub struct Parsed {
    pub info: SplToken,
}

#[derive(serde::Deserialize)]
pub struct SplToken {
    pub mint: String,
    #[serde(rename(deserialize = "tokenAmount"))]
    pub token_amount: Amount,
}

#[allow(dead_code)]
#[derive(serde::Deserialize)]
pub struct Amount {
    pub amount: String,
    #[serde(rename(deserialize = "uiAmountString"))]
    ui_amount_string: String,
    #[serde(rename(deserialize = "uiAmount"))]
    pub ui_amount: f64,
    pub decimals: u8,
}

#[derive(Serialize, Deserialize, Debug, Default)]
pub struct CloseEmptyTokenAccountsData {
    pub signature: String,
    pub closed_size: usize,
}

impl CloseEmptyTokenAccountsData {
    pub fn new(signature: String, closed_size: usize) -> Self {
        CloseEmptyTokenAccountsData {
            signature,
            closed_size,
        }
    }
}

/// Close Empty SPL Token accounts of the agent.
///
/// # Parameters
///
/// - `agent`: An instance of `SolanaAgentKit`.
///
/// # Returns
///
/// Transaction signature and total number of accounts closed or an error if the account doesn't exist.
pub async fn close_empty_token_accounts(
    agent: &SolanaAgentKit,
) -> Result<CloseEmptyTokenAccountsData> {
    let max_instructions = 40_u32;
    let mut transaction: Vec<Instruction> = vec![];
    let mut closed_size = 0;
    let token_programs = vec![spl_token::ID, spl_token_2022::ID];

    for token_program in token_programs {
        let accounts = agent
            .connection
            .get_token_accounts_by_owner(
                &agent.wallet.address,
                TokenAccountsFilter::ProgramId(token_program.to_owned()),
            )
            .context("Failed to get token accounts by owner")?;

        closed_size += accounts.len();

        for account in accounts {
            if transaction.len() >= max_instructions as usize {
                break;
            }

            if let solana_account_decoder::UiAccountData::Json(d) = &account.account.data {
                let parsed = serde_json::from_value::<Parsed>(d.parsed.clone())
                    .context("Failed to parse token account data")?;

                if parsed.info.token_amount.amount.parse::<u32>().unwrap_or(0) == 0_u32
                    && parsed.info.mint != USDC
                {
                    let account_pubkey = Pubkey::from_str(&account.pubkey)
                        .context("Failed to parse account pubkey")?;

                    let instruct = close_account(
                        &token_program,
                        &account_pubkey,
                        &agent.wallet.address,
                        &agent.wallet.address,
                        &[&agent.wallet.address],
                    )
                    .context("Failed to create close_account instruction")?;
                    transaction.push(instruct);
                }
            }
        }
    }

    if transaction.is_empty() {
        return Ok(CloseEmptyTokenAccountsData::default());
    }

    let recent_blockhash = agent
        .connection
        .get_latest_blockhash()
        .context("Failed to get latest blockhash")?;
    let transaction = Transaction::new_signed_with_payer(
        &transaction,
        Some(&agent.wallet.address),
        &[&agent.wallet.wallet],
        recent_blockhash,
    );

    let signature = agent
        .connection
        .send_and_confirm_transaction(&transaction)
        .context("Failed to send and confirm transaction")?;
    let data = CloseEmptyTokenAccountsData::new(signature.to_string(), closed_size);
    Ok(data)
}


================================================
File: src/actions/solana/get_balance.rs
================================================
use crate::SolanaAgentKit;
use anyhow::{Context, Result};
use solana_client::client_error::ClientError;
use solana_sdk::{native_token::LAMPORTS_PER_SOL, pubkey::Pubkey};
use std::str::FromStr;

/// Gets the balance of SOL or an SPL token for the agent's wallet.
///
/// # Parameters
///
/// - `agent`: An instance of `SolanaAgentKit`.
/// - `token_address`: An optional SPL token mint address. If not provided, returns the SOL balance.
///
/// # Returns
///
/// A `Result` that resolves to the balance as a number (in UI units) or an error if the account doesn't exist.
pub async fn get_balance(agent: &SolanaAgentKit, token_address: Option<String>) -> Result<f64, ClientError> {
    if let Some(token_address) = token_address {
        // Get SPL token account balance
        let pubkey = Pubkey::from_str(&token_address).map_err(|e| {
            ClientError::from(std::io::Error::new(
                std::io::ErrorKind::InvalidInput,
                format!("Invalid token address: {}: {}", token_address, e),
            ))
        })?;

        let token_account = agent.connection.get_token_account_balance(&pubkey)?;
        let ui_amount = token_account.ui_amount.unwrap_or(0.0);
        return Ok(ui_amount);
    }

    // Get SOL balance
    let balance = agent.connection.get_balance(&agent.wallet.address)?;
    Ok(balance as f64 / LAMPORTS_PER_SOL as f64)
}


// Integration Tests:
#[cfg(test)]
mod tests {
    use super::*;
    use solana_sdk::signature::Keypair;

    #[tokio::test]
    async fn test_get_sol_balance() -> Result<()> {
        // Replace with a testnet/devnet RPC URL and a wallet with known balance
        let rpc_url = "https://api.devnet.solana.com";
        let wallet = Keypair::new(); // Create a new keypair for testing
        let wallet_address = wallet.pubkey().to_string();
        Ok(())
    }

    #[tokio::test]
    async fn test_get_spl_token_balance() -> Result<()> {
        // Replace with a testnet/devnet RPC URL and a token with known balance
        let rpc_url = "https://api.devnet.solana.com";
        let wallet_address = "A5GecEJ";
        let token_address = "So11111111111111111111111111111111111111112";
        Ok(())
    }
}


================================================
File: src/actions/solana/get_tps.rs
================================================
use crate::SolanaAgentKit;
use solana_client::client_error::ClientError;

/// Gets the transactions per second (TPS) from the Solana network.
///
/// # Parameters
///
/// - `agent`: An instance of `SolanaAgentKit` that connects to the Solana cluster.
///
/// # Returns
///
/// A `Result` containing the TPS as a `f64`, or an error if fetching performance samples fails.
pub async fn get_tps(agent: &SolanaAgentKit) -> Result<f64, ClientError> {
    // Fetch recent performance samples
    let limit = 1;
    let perf_samples = agent.connection.get_recent_performance_samples(Some(limit))?;

    // Check if there are any samples available
    if !perf_samples.is_empty() {
        // Calculate TPS
        let num_transactions = perf_samples[0].num_transactions;
        let sample_period_secs = perf_samples[0].sample_period_secs;

        let tps = num_transactions as f64 / sample_period_secs as f64;

        return Ok(tps);
    }

    Ok(0.0)
}


================================================
File: src/actions/solana/mod.rs
================================================
mod close_empty_token_accounts;
pub use close_empty_token_accounts::{close_empty_token_accounts, CloseEmptyTokenAccountsData};

mod get_balance;
pub use get_balance::get_balance;

mod request_faucet_funds;
pub use request_faucet_funds::request_faucet_funds;

mod get_tps;
pub use get_tps::get_tps;

mod transfer;
pub use transfer::transfer;


================================================
File: src/actions/solana/request_faucet_funds.rs
================================================
use crate::SolanaAgentKit;
use solana_client::client_error::ClientError;
use solana_sdk::native_token::LAMPORTS_PER_SOL;

/// Requests SOL from the Solana faucet (devnet/testnet only).
///
/// # Parameters
///
/// - `agent`: An instance of `SolanaAgentKit`.
///
/// # Returns
///
/// A transaction signature as a `String`.
///
/// # Errors
///
/// Returns an error if the request fails or times out.
pub async fn request_faucet_funds(agent: &SolanaAgentKit) -> Result<String, ClientError> {
    // Request airdrop of 5 SOL (5 * LAMPORTS_PER_SOL)
    let tx = agent.connection.request_airdrop(&agent.wallet.address, 5 * LAMPORTS_PER_SOL)?;

    // Confirm the transaction
    agent.connection.confirm_transaction(&tx)?;

    Ok(tx.to_string())
}


================================================
File: src/actions/solana/transfer.rs
================================================
use crate::SolanaAgentKit;
use anyhow::{Context, Result};
use solana_client::client_error::ClientError;
use solana_sdk::{program_pack::Pack, pubkey::Pubkey, system_instruction, transaction::Transaction};
use spl_associated_token_account::get_associated_token_address;
use spl_token::{instruction::transfer as transfer_instruct, state::Mint};
use std::str::FromStr;

/// Transfer SOL or SPL tokens to a recipient
///
/// `agent` - SolanaAgentKit instance
/// `to` - Recipient's public key
/// `amount` - Amount to transfer
/// `mint` - Optional mint address for SPL tokens
///
/// Returns the transaction signature.
pub async fn transfer(
    agent: &SolanaAgentKit,
    to: &str,
    amount: u64,
    mint: Option<String>,
) -> Result<String, ClientError> {
    match mint {
        Some(mint) => {
            // Transfer SPL Token
            let mint_pubkey = Pubkey::from_str(&mint).map_err(|e| {
                ClientError::from(std::io::Error::new(
                    std::io::ErrorKind::InvalidInput,
                    format!("Invalid mint address: {}: {}", mint, e),
                ))
            })?;
            let to_pubkey = Pubkey::from_str(to).map_err(|e| {
                ClientError::from(std::io::Error::new(
                    std::io::ErrorKind::InvalidInput,
                    format!("Invalid recipient address: {}: {}", to, e),
                ))
            })?;

            let from_ata = get_associated_token_address(&agent.wallet.address, &mint_pubkey);
            let to_ata = get_associated_token_address(&to_pubkey, &mint_pubkey);

            let account_info = agent.connection.get_account(&mint_pubkey).map_err(|e| {
                ClientError::from(std::io::Error::new(
                    std::io::ErrorKind::Other,
                    format!("Failed to get account info for mint {}: {}", mint, e),
                ))
            })?;
            let mint_info = Mint::unpack_from_slice(&account_info.data).map_err(|e| {
                ClientError::from(std::io::Error::new(
                    std::io::ErrorKind::Other,
                    format!("Failed to unpack mint info for {}: {}", mint, e),
                ))
            })?;

            let adjusted_amount = amount * 10u64.pow(mint_info.decimals as u32);

            let transfer_instruction = transfer_instruct(
                &spl_token::id(),
                &from_ata,
                &to_ata,
                &agent.wallet.address,
                &[&agent.wallet.address],
                adjusted_amount,
            )
            .map_err(|e| {
                ClientError::from(std::io::Error::new(
                    std::io::ErrorKind::Other,
                    format!("Failed to create transfer instruction: {}", e),
                ))
            })?;

            let recent_blockhash = agent
                .connection
                .get_latest_blockhash()
                .map_err(|e| ClientError::from(e))?;

            let transaction = Transaction::new_signed_with_payer(
                &[transfer_instruction],
                Some(&agent.wallet.address),
                &[&agent.wallet.wallet],
                recent_blockhash,
            );

            let signature = agent
                .connection
                .send_and_confirm_transaction(&transaction)
                .map_err(|e| ClientError::from(e))?;
            Ok(signature.to_string())
        }
        None => {
            // Transfer SOL
            let to_pubkey = Pubkey::from_str(to).map_err(|e| {
                ClientError::from(std::io::Error::new(
                    std::io::ErrorKind::InvalidInput,
                    format!("Invalid recipient address: {}: {}", to, e),
                ))
            })?;
            let transfer_instruction =
                system_instruction::transfer(&agent.wallet.address, &to_pubkey, amount);

            let recent_blockhash = agent
                .connection
                .get_latest_blockhash()
                .map_err(|e| ClientError::from(e))?;

            let transaction = Transaction::new_signed_with_payer(
                &[transfer_instruction],
                Some(&agent.wallet.address),
                &[&agent.wallet.wallet],
                recent_blockhash,
            );

            let signature = agent
                .connection
                .send_and_confirm_transaction(&transaction)
                .map_err(|e| ClientError::from(e))?;
            Ok(signature.to_string())
        }
    }
}


================================================
File: src/agent/analyst.rs
================================================
use crate::birdeye::api::{BirdeyeApi, BirdeyeClient};
use crate::config::mongodb::MongoDbPool;
use crate::config::birdeye_config::BirdeyeConfig;
use crate::models::market_signal::MarketSignal;
use crate::services::token_analytics::TokenAnalyticsService;
use anyhow::Result;
use bson::DateTime;
use chrono::{Duration, TimeZone, Utc};
use std::sync::Arc;
use thiserror::Error;
use tracing::info;

#[derive(Error, Debug)]
pub enum Error {
    #[error("MongoDB error: {0}")]
    Mongo(#[from] mongodb::error::Error),
    #[error("Token analysis error: {0}")]
    Analysis(String),
    #[error("Data error: {0}")]
    Data(String),
    #[error("Anyhow error: {0}")]
    Anyhow(#[from] anyhow::Error),
}

pub struct AnalystAgent {
    analytics_service: Arc<TokenAnalyticsService>,
    db: Arc<MongoDbPool>,
}

impl AnalystAgent {
    pub async fn new(db_pool: Arc<MongoDbPool>, birdeye_api_key: String) -> Result<Self> {
        let birdeye_client: Arc<dyn BirdeyeApi> = Arc::new(BirdeyeClient::new(birdeye_api_key));
        let analytics_service =
            Arc::new(TokenAnalyticsService::new(db_pool.clone(), birdeye_client, None).await?);

        Ok(Self {
            analytics_service,
            db: db_pool,
        })
    }

    pub async fn analyze_token(&self, symbol: &str, address: &str) -> Result<Option<MarketSignal>> {
        info!("Starting analysis for token: {} ({})", symbol, address);

        // First fetch and store current token info
        let analytics = self
            .analytics_service
            .fetch_and_store_token_info(symbol, address)
            .await?;

        // Get historical data for analysis
        let now = DateTime::now();
        let timestamp_millis = now.timestamp_millis();
        let chrono_now = Utc.timestamp_millis_opt(timestamp_millis).unwrap();
        let start_time_chrono = chrono_now - Duration::days(7);
        let new_timestamp_millis = start_time_chrono.timestamp_millis();
        let start_time = DateTime::from_millis(new_timestamp_millis);
        let end_time = now;

        let history = self
            .analytics_service
            .get_token_history(address, start_time, end_time)
            .await?;

        info!(
            "Retrieved {} historical data points for analysis",
            history.len()
        );

        // Get previous analytics for comparison
        if self
            .analytics_service
            .get_previous_analytics(address)
            .await?
            .is_some()
        {
            info!("Generating market signals based on analysis");

            // Generate market signals based on the analysis
            return self
                .analytics_service
                .generate_market_signals(&analytics)
                .await
                .map_err(|e| Error::Analysis(e.to_string()).into());
        }

        info!("No previous analytics found for comparison");
        Ok(None)
    }
}

================================================
File: src/agent/mod.rs
================================================
pub mod trader;
// pub mod risk_manager;
// pub mod portfolio_optimizer;
pub mod analyst;

use serde::{Deserialize, Serialize};
use std::time::Duration;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AgentConfig {
    pub openai_api_key: String,
    pub birdeye_api_key: String,
    pub twitter_email: String,
    pub twitter_username: String,
    pub twitter_password: String,
    pub analysis_interval: Duration,
    pub trade_min_confidence: f64,
    pub trade_max_amount: f64,
}

impl Default for AgentConfig {
    fn default() -> Self {
        Self {
            openai_api_key: String::new(),
            birdeye_api_key: String::new(),
            twitter_email: String::new(),
            twitter_username: String::new(),
            twitter_password: String::new(),
            analysis_interval: Duration::from_secs(300), // 5 minutes
            trade_min_confidence: 0.7,
            trade_max_amount: 1000.0,
        }
    }
}

// Re-export common types


================================================
File: src/agent/portfolio_optimizer.rs
================================================
use anyhow::Result;
use bigdecimal::{BigDecimal, ToPrimitive};
use crate::models::market_signal::MarketSignal;
use crate::models::token_analytics::TokenAnalytics;
use crate::utils::f64_to_decimal;
use std::sync::Arc;
use rig_mongodb::{MongoDbPool, bson::doc};
use crate::error::Error;
use crate::models::allocation::Allocation;

pub struct PortfolioOptimizer {
    db: Arc<MongoDbPool>,
}

impl PortfolioOptimizer {
    pub fn new(db: Arc<MongoDbPool>) -> Self {
        Self { db }
    }

    pub async fn get_allocation(&self, _token: &TokenAnalytics, _signal: &MarketSignal) -> Result<BigDecimal> {
        // For now, return a default allocation
        Ok(f64_to_decimal(0.1)) // 10% allocation
    }

    pub async fn get_position_allocation(&self, address: &str) -> Result<BigDecimal> {
        let collection = self.db.collection("allocations");
        
        let filter = doc! {
            "token_address": address,
        };
        
        let doc = collection.find_one(filter, None)
            .await?;
            
        let allocation = doc
            .and_then(|d| d.get_f64("allocation"))
            .unwrap_or(0.0);

        Ok(f64_to_decimal(allocation))
    }

    async fn get_allocation(&self, token_address: &str) -> Result<Option<Allocation>, Error> {
        let collection = self.db.database("cainam").collection("allocations");
        
        let filter = doc! {
            "token_address": token_address,
        };
        
        collection.find_one(filter, None)
            .await
            .map_err(|e| Error::Database(e.to_string()))
    }
}


================================================
File: src/agent/risk_manager.rs
================================================
use anyhow::Result;
use crate::models::market_signal::MarketSignal;
use crate::utils::{decimal_to_f64, f64_to_decimal};
use std::sync::Arc;
use rig_mongodb::MongoDbPool;

pub struct RiskManagerAgent {
    db: Arc<MongoDbPool>,
    max_position_size: f64,
    max_drawdown: f64,
}

impl RiskManagerAgent {
    pub fn new(db: Arc<MongoDbPool>, max_position_size: f64, max_drawdown: f64) -> Self {
        Self {
            db,
            max_position_size,
            max_drawdown,
        }
    }

    pub async fn validate_trade(&self, signal: &MarketSignal) -> Result<bool> {
        // TODO: Implement risk validation logic
        // - Check current exposure
        // - Validate against max drawdown
        // - Check correlation with existing positions
        // - Verify position sizing
        
        let min_confidence = f64_to_decimal(0.5);
        let max_risk = f64_to_decimal(0.7);
        if signal.confidence < min_confidence || signal.risk_score > max_risk {
            return Ok(false);
        }

        Ok(true)
    }

    pub async fn calculate_position_size(&self, signal: &MarketSignal) -> Result<f64> {
        // Calculate optimal position size based on:
        // - Current portfolio value
        // - Risk metrics
        // - Signal confidence
        let max_size = f64_to_decimal(self.max_position_size);
        let base_size = max_size.clone() * signal.confidence.clone();
        let one = f64_to_decimal(1.0);
        let risk_factor = one - signal.risk_score.clone();
        let risk_adjusted_size = base_size * risk_factor;
        
        Ok(decimal_to_f64(&risk_adjusted_size.min(max_size)))
    }
}

================================================
File: src/agent/trader.rs
================================================
// use crate::models::trade::Trade;
use crate::{
    birdeye::api::BirdeyeClient,
    config::mongodb::MongoDbPool,
    config::{AgentConfig, MarketConfig},
    error::{AgentError, AgentResult},
    models::market_signal::{MarketSignal, SignalType},
    services::TokenAnalyticsService,
    trading::trading_engine::TradingEngine,
    trading::SolanaAgentKit,
    utils::f64_to_decimal,
};
use bigdecimal::BigDecimal;
use rig::{
    agent::Agent,
    providers::openai::{Client as OpenAIClient, CompletionModel},
};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use tokio::time::sleep;
use tracing::{error, info};

const MAX_RETRIES: u32 = 3;
const RETRY_DELAY: u64 = 1000; // 1 second

pub struct TradingAgent {
    agent: Agent<CompletionModel>,
    trading_engine: TradingEngine,
    analytics_service: Arc<TokenAnalyticsService>,
    config: AgentConfig,
    running: Arc<AtomicBool>,
    db: Arc<MongoDbPool>,
    birdeye: Arc<BirdeyeClient>,
    birdeye_extended: Arc<BirdeyeClient>,
}

impl TradingAgent {
    pub async fn new(
        config: AgentConfig,
        db: Arc<MongoDbPool>,
        solana_agent: SolanaAgentKit,
    ) -> AgentResult<Self> {
        info!("Initializing TradingAgent...");

        // Initialize OpenAI client
        let openai_client = OpenAIClient::new(&config.openai_api_key);

        info!("Creating GPT-4 agent...");
        let agent = openai_client
            .agent(crate::config::get_openai_model())
            .preamble(include_str!("../prompts/system.txt"))
            .build();

        // Initialize components
        let trading_engine = TradingEngine::new(
            config.trade_min_confidence,
            config.trade_max_amount,
            solana_agent,
        );

        // info!("Initializing Twitter client...");
        // let mut twitter_client = TwitterClient::new(
        //     config.twitter_email.clone(),
        //     config.twitter_username.clone(),
        //     config.twitter_password.clone(),
        // );

        // // Retry Twitter login with exponential backoff
        // let mut retry_count = 0;
        // loop {
        //     match twitter_client.login().await {
        //         Ok(_) => {
        //             info!("Successfully logged in to Twitter");
        //             break;
        //         }
        //         Err(e) => {
        //             retry_count += 1;
        //             if retry_count >= MAX_RETRIES {
        //                 error!("Failed to login to Twitter after {} attempts", MAX_RETRIES);
        //                 return Err(AgentError::TwitterApi(format!("Login failed: {}", e)));
        //             }
        //             warn!(
        //                 "Failed to login to Twitter (attempt {}), retrying...",
        //                 retry_count
        //             );
        //             sleep(Duration::from_millis(RETRY_DELAY * 2u64.pow(retry_count))).await;
        //         }
        //     }
        // }

        info!("Initializing Birdeye clients...");
        let birdeye = Arc::new(BirdeyeClient::new(config.birdeye_api_key.clone()));
        let birdeye_extended = Arc::new(BirdeyeClient::new(config.birdeye_api_key.clone()));

        // Initialize market config
        let market_config = MarketConfig::new_from_env()?;

        // Initialize analytics service
        let analytics_service = Arc::new(
            TokenAnalyticsService::new(db.clone(), birdeye.clone(), Some(market_config)).await?,
        );

        Ok(Self {
            agent,
            trading_engine,
            analytics_service,
            config,
            running: Arc::new(AtomicBool::new(false)),
            db,
            birdeye,
            birdeye_extended,
        })
    }

    // async fn store_trade(&self, trade: &Trade) -> Result<(), Error> {
    //     let collection = self.db.database("cainam").collection("trades");
    //     collection
    //         .insert_one(trade)
    //         .await
    //         .map_err(|e| Error::Mongo(e))?;
    //     Ok(())
    // }

    pub async fn analyze_market(
        &self,
        symbol: &str,
        address: &str,
    ) -> AgentResult<Option<MarketSignal>> {
        info!("Starting market analysis for {}", symbol);

        // Fetch and store token analytics
        let analytics = self
            .analytics_service
            .fetch_and_store_token_info(symbol, address)
            .await
            .map_err(|e| {
                AgentError::MarketAnalysis(format!("Failed to fetch token info: {}", e))
            })?;

        info!("Market Analysis for {}:", symbol);
        info!("Current Price: ${:.4}", analytics.price);
        if let Some(ref volume) = analytics.volume_24h {
            info!("24h Volume: ${:.2}", volume);
        }

        // Generate market signals
        let signal = self
            .analytics_service
            .generate_market_signals(&analytics)
            .await
            .map_err(|e| {
                AgentError::MarketAnalysis(format!("Failed to generate signals: {}", e))
            })?;

        if let Some(signal) = &signal {
            info!(
                "Market signal generated: {:?} (confidence: {:.2})",
                signal.signal_type, signal.confidence
            );
        }

        Ok(signal)
    }

    pub async fn process_signal(&self, signal: &MarketSignal) -> AgentResult<Option<String>> {
        let zero = BigDecimal::from(0);
        let action = match signal.signal_type {
            SignalType::PriceSpike if signal.price > zero => "BUY",
            SignalType::StrongBuy => "BUY",
            SignalType::Buy => "BUY",
            SignalType::VolumeSurge if signal.volume_change > zero => "BUY",
            SignalType::PriceDrop => "SELL",
            SignalType::StrongSell => "SELL",
            SignalType::Sell => "SELL",
            SignalType::Hold => "HOLD",
            _ => return Ok(None),
        };

        // Convert f64 config values to BigDecimal
        let threshold = f64_to_decimal(self.config.trade_min_confidence);
        let max_amount = f64_to_decimal(self.config.trade_max_amount);

        if signal.confidence >= threshold {
            let amount = (max_amount.clone() * signal.confidence.clone()).min(max_amount.clone());

            match action {
                "BUY" | "SELL" => {
                    info!(
                        "Executing {} trade for {} with amount {}",
                        action, signal.asset_address, amount
                    );
                    self.trading_engine
                        .execute_trade(signal)
                        .await
                        .map_err(|e| {
                            AgentError::Trading(format!("Trade execution failed: {}", e))
                        })?;
                }
                _ => {}
            }
        }

        Ok(Some(action.to_string()))
    }

    pub async fn execute_trade(&self, _symbol: &str, signal: &MarketSignal) -> AgentResult<String> {
        self.trading_engine
            .execute_trade(signal)
            .await
            .map_err(|e| AgentError::Trading(format!("Trade execution failed: {}", e)))
    }

    pub async fn post_trade_update(
        &self,
        _symbol: &str,
        _action: &str,
        _amount: f64,
        _signal_type: &SignalType,
    ) -> AgentResult<()> {
        // TODO: Implement post-trade updates
        // - Update portfolio state
        // - Log trade details
        // - Send notifications
        Ok(())
    }

    pub async fn run(&self) -> AgentResult<()> {
        info!("Starting trading agent...");
        self.running.store(true, Ordering::SeqCst);

        let tokens = [
            ("SOL", "So11111111111111111111111111111111111111112"),
            ("BONK", "DezXAZ8z7PnrnRJjz3wXBoRgixCa6xjnB7YaB1pPB263"),
        ];

        while self.running.load(Ordering::SeqCst) {
            for (symbol, address) in tokens.iter() {
                match self.analyze_market(symbol, address).await {
                    Ok(Some(signal)) => {
                        let min_confidence = f64_to_decimal(self.config.trade_min_confidence);
                        if signal.confidence >= min_confidence {
                            if let Err(e) = self.process_signal(&signal).await {
                                error!("Error processing signal: {}", e);
                            }
                        } else {
                            info!("Signal confidence too low for trading");
                        }
                    }
                    Ok(None) => {
                        info!("No trading signals generated");
                    }
                    Err(e) => {
                        error!("Market analysis failed for {}: {}", symbol, e);
                    }
                }
            }

            info!(
                "Waiting for next analysis interval ({:?})...",
                self.config.analysis_interval
            );
            sleep(self.config.analysis_interval).await;
            info!("Starting next analysis cycle");
        }

        info!("Trading agent stopped");
        Ok(())
    }

    pub fn stop(&self) {
        info!("Stopping trading agent...");
        self.running.store(false, Ordering::SeqCst);
    }
}

// #[cfg(test)]
// mod tests {
//     use super::*;
//     use crate::birdeye::MockBirdeyeApi;
//     use crate::twitter::MockTwitterApi;

//     async fn setup_test_db() -> Arc<MongoDbPool> {
//         MongoDbPool::new_from_uri("mongodb://localhost:32770", "cainam_test")
//             .await
//             .expect("Failed to create test database pool")
//             .into()
//     }

//     async fn setup_mocks() -> (Box<MockTwitterApi>, Box<MockBirdeyeApi>) {
//         let mut twitter_mock = Box::new(MockTwitterApi::new());
//         twitter_mock
//             .expect_login()
//             .times(1)
//             .returning(|| Box::pin(async { Ok(()) }));

//         let mut birdeye_mock = Box::new(MockBirdeyeApi::new());
//         birdeye_mock.expect_get_token_info().returning(|_| {
//             Box::pin(async {
//                 Ok(crate::birdeye::TokenInfo {
//                     price: 100.0,
//                     volume_24h: 1000000.0,
//                     price_change_24h: 5.0,
//                     liquidity: 500000.0,
//                     trade_24h: 1000,
//                 })
//             })
//         });

//         (twitter_mock, birdeye_mock)
//     }

//     #[tokio::test]
//     async fn test_market_analysis() -> AgentResult<()> {
//         let db = setup_test_db().await;
//         let solana_agent = SolanaAgentKit::new_from_env()?;

//         let config = AgentConfig::new_from_env()?;
//         let agent = TradingAgent::new(config, db, solana_agent).await?;

//         let signal = agent
//             .analyze_market("SOL", "So11111111111111111111111111111111111111112")
//             .await?;

//         assert!(signal.is_some());
//         Ok(())
//     }
// }


================================================
File: src/birdeye/api.rs
================================================
use super::BIRDEYE_API_URL;
use crate::config::BirdeyeConfig;
use crate::models::token_info::TokenExtensions;
use crate::models::trending_token::{TrendingToken, TrendingTokenData};
use anyhow::{anyhow, Context, Result};
use async_trait::async_trait;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use tracing::{debug, error};

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ApiResponse<T> {
    pub success: bool,
    pub data: T,
    pub message: Option<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct TokenPrice {
    pub value: f64,
    pub decimals: u8,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct TokenData {
    pub address: String,
    pub symbol: String,
    pub name: String,
    #[serde(rename = "logoURI")]
    pub image: Option<String>,
    pub decimals: u8,
    #[serde(rename = "marketCap")]
    pub market_cap: Option<f64>,
    pub fdv: Option<f64>,
    pub liquidity: Option<f64>,
    pub price: f64,
    #[serde(rename = "priceChange24hPercent")]
    pub price_change_24h: Option<f64>,
    #[serde(rename = "v24h")]
    pub volume_24h: Option<f64>,
    #[serde(rename = "v24hChangePercent")]
    pub volume_change_24h: Option<f64>,
    #[serde(rename = "trade24h")]
    pub trade_24h: Option<i64>,
    pub holder: Option<i64>,
    pub extensions: Option<TokenExtensions>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct MultiTokenData {
    #[serde(flatten)]
    pub tokens: HashMap<String, TokenData>,
}

#[derive(Debug, Deserialize, Serialize, Clone)]
pub struct TokenMarketResponse {
    pub address: String,
    pub decimals: i32,
    pub symbol: String,
    pub name: String,
    #[serde(rename = "marketCap")]
    pub market_cap: f64,
    pub fdv: f64,
    pub extensions: TokenExtensions,
    #[serde(rename = "logoURI")]
    pub logo_uri: String,
    pub liquidity: f64,
    #[serde(rename = "lastTradeUnixTime")]
    pub last_trade_unix_time: i64,
    #[serde(rename = "lastTradeHumanTime")]
    pub last_trade_human_time: String,
    pub price: f64,
    #[serde(rename = "history30mPrice")]
    pub history30m_price: f64,
    #[serde(rename = "priceChange30mPercent")]
    pub price_change_30m_percent: f64,
    #[serde(rename = "history1hPrice")]
    pub history1h_price: f64,
    #[serde(rename = "priceChange1hPercent")]
    pub price_change_1h_percent: f64,
    #[serde(rename = "history2hPrice")]
    pub history2h_price: f64,
    #[serde(rename = "priceChange2hPercent")]
    pub price_change_2h_percent: f64,
    #[serde(rename = "history4hPrice")]
    pub history4h_price: f64,
    #[serde(rename = "priceChange4hPercent")]
    pub price_change_4h_percent: f64,
    #[serde(rename = "history6hPrice")]
    pub history6h_price: f64,
    #[serde(rename = "priceChange6hPercent")]
    pub price_change_6h_percent: f64,
    #[serde(rename = "history8hPrice")]
    pub history8h_price: f64,
    #[serde(rename = "priceChange8hPercent")]
    pub price_change_8h_percent: f64,
    #[serde(rename = "history12hPrice")]
    pub history12h_price: f64,
    #[serde(rename = "priceChange12hPercent")]
    pub price_change_12h_percent: f64,
    #[serde(rename = "history24hPrice")]
    pub history24h_price: f64,
    #[serde(rename = "priceChange24hPercent")]
    pub price_change_24h_percent: f64,
    #[serde(rename = "uniqueWallet30m")]
    pub unique_wallet30m: i64,
    #[serde(rename = "uniqueWalletHistory30m")]
    pub unique_wallet_history30m: i64,
    #[serde(rename = "uniqueWallet30mChangePercent")]
    pub unique_wallet30m_change_percent: f64,
    #[serde(rename = "uniqueWallet1h")]
    pub unique_wallet1h: i64,
    #[serde(rename = "uniqueWalletHistory1h")]
    pub unique_wallet_history1h: i64,
    #[serde(rename = "uniqueWallet1hChangePercent")]
    pub unique_wallet1h_change_percent: f64,
    #[serde(rename = "uniqueWallet2h")]
    pub unique_wallet2h: i64,
    #[serde(rename = "uniqueWalletHistory2h")]
    pub unique_wallet_history2h: i64,
    #[serde(rename = "uniqueWallet2hChangePercent")]
    pub unique_wallet2h_change_percent: f64,
    #[serde(rename = "uniqueWallet4h")]
    pub unique_wallet4h: i64,
    #[serde(rename = "uniqueWalletHistory4h")]
    pub unique_wallet_history4h: i64,
    #[serde(rename = "uniqueWallet4hChangePercent")]
    pub unique_wallet4h_change_percent: f64,
    #[serde(rename = "uniqueWallet8h")]
    pub unique_wallet8h: i64,
    #[serde(rename = "uniqueWalletHistory8h")]
    pub unique_wallet_history8h: i64,
    #[serde(rename = "uniqueWallet8hChangePercent")]
    pub unique_wallet8h_change_percent: f64,
    #[serde(rename = "uniqueWallet24h")]
    pub unique_wallet24h: i64,
    #[serde(rename = "uniqueWalletHistory24h")]
    pub unique_wallet_history24h: i64,
    #[serde(rename = "uniqueWallet24hChangePercent")]
    pub unique_wallet24h_change_percent: f64,
    pub supply: f64,
    #[serde(rename = "totalSupply")]
    pub total_supply: f64,
    pub mc: f64,
    #[serde(rename = "circulatingSupply")]
    pub circulating_supply: f64,
    #[serde(rename = "realMc")]
    pub real_mc: f64,
    pub holder: i64,
    pub trade30m: i64,
    #[serde(rename = "tradeHistory30m")]
    pub trade_history30m: i64,
    #[serde(rename = "trade30mChangePercent")]
    pub trade30m_change_percent: f64,
    pub sell30m: i64,
    #[serde(rename = "sellHistory30m")]
    pub sell_history30m: i64,
    #[serde(rename = "sell30mChangePercent")]
    pub sell30m_change_percent: f64,
    pub buy30m: i64,
    #[serde(rename = "buyHistory30m")]
    pub buy_history30m: i64,
    #[serde(rename = "buy30mChangePercent")]
    pub buy30m_change_percent: f64,
    pub v30m: f64,
    #[serde(rename = "v30mUSD")]
    pub v30m_usd: f64,
    #[serde(rename = "vHistory30m")]
    pub v_history30m: f64,
    #[serde(rename = "vHistory30mUSD")]
    pub v_history30m_usd: f64,
    #[serde(rename = "v30mChangePercent")]
    pub v30m_change_percent: f64,
    #[serde(rename = "vBuy30m")]
    pub v_buy30m: f64,
    #[serde(rename = "vBuy30mUSD")]
    pub v_buy30m_usd: f64,
    #[serde(rename = "vBuyHistory30m")]
    pub v_buy_history30m: f64,
    #[serde(rename = "vBuyHistory30mUSD")]
    pub v_buy_history30m_usd: f64,
    #[serde(rename = "vBuy30mChangePercent")]
    pub v_buy30m_change_percent: f64,
    #[serde(rename = "vSell30m")]
    pub v_sell30m: f64,
    #[serde(rename = "vSell30mUSD")]
    pub v_sell30m_usd: f64,
    #[serde(rename = "vSellHistory30m")]
    pub v_sell_history30m: f64,
    #[serde(rename = "vSellHistory30mUSD")]
    pub v_sell_history30m_usd: f64,
    #[serde(rename = "vSell30mChangePercent")]
    pub v_sell30m_change_percent: f64,
    pub trade24h: i64,
    #[serde(rename = "tradeHistory24h")]
    pub trade_history24h: i64,
    #[serde(rename = "trade24hChangePercent")]
    pub trade24h_change_percent: f64,
    pub sell24h: i64,
    #[serde(rename = "sellHistory24h")]
    pub sell_history24h: i64,
    #[serde(rename = "sell24hChangePercent")]
    pub sell24h_change_percent: f64,
    pub buy24h: i64,
    #[serde(rename = "buyHistory24h")]
    pub buy_history24h: i64,
    #[serde(rename = "buy24hChangePercent")]
    pub buy24h_change_percent: f64,
    pub v24h: f64,
    #[serde(rename = "v24hUSD")]
    pub v24h_usd: f64,
    #[serde(rename = "vHistory24h")]
    pub v_history24h: f64,
    #[serde(rename = "vHistory24hUSD")]
    pub v_history24h_usd: f64,
    #[serde(rename = "v24hChangePercent")]
    pub v24h_change_percent: f64,
    #[serde(rename = "vBuy24h")]
    pub v_buy24h: f64,
    #[serde(rename = "vBuy24hUSD")]
    pub v_buy24h_usd: f64,
    #[serde(rename = "vBuyHistory24h")]
    pub v_buy_history24h: f64,
    #[serde(rename = "vBuyHistory24hUSD")]
    pub v_buy_history24h_usd: f64,
    #[serde(rename = "vBuy24hChangePercent")]
    pub v_buy24h_change_percent: f64,
    #[serde(rename = "vSell24h")]
    pub v_sell24h: f64,
    #[serde(rename = "vSell24hUSD")]
    pub v_sell24h_usd: f64,
    #[serde(rename = "vSellHistory24h")]
    pub v_sell_history24h: f64,
    #[serde(rename = "vSellHistory24hUSD")]
    pub v_sell_history24h_usd: f64,
    #[serde(rename = "vSell24hChangePercent")]
    pub v_sell24h_change_percent: f64,
    #[serde(rename = "numberMarkets")]
    pub number_markets: i64,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
#[serde(rename_all = "camelCase")]
pub struct OnchainMetrics {
    pub unique_holders: u32,
    pub active_wallets_24h: u32,
    pub transactions_24h: u32,
    pub average_transaction_size: f64,
    pub whale_transactions_24h: u32,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct TokenOverviewResponse {
    pub address: String,
    pub symbol: String,
    pub name: String,
    #[serde(rename = "logoURI")]
    pub logo_uri: Option<String>,
    pub decimals: u8,
    pub price: f64,
    #[serde(rename = "marketCap")]
    pub market_cap: Option<f64>,
    pub liquidity: Option<f64>,
    #[serde(rename = "volume24h")]
    pub volume_24h: Option<f64>,
    #[serde(rename = "priceChange24h")]
    pub price_change_24h: Option<f64>,
    pub holder_count: Option<i32>,
}

#[async_trait]
pub trait BirdeyeApi: Send + Sync {
    /// Get detailed market data for a token by address
    async fn get_market_data(&self, address: &str) -> Result<TokenMarketResponse>;
    
    /// Get basic token overview information
    async fn get_token_overview(&self, address: &str) -> Result<TokenOverviewResponse>;
    
    /// Get trending tokens data
    async fn get_trending_tokens(&self) -> Result<Vec<TrendingToken>>;
}

pub struct BirdeyeClient {
    client: Client,
    api_key: String,
}

impl BirdeyeClient {
    pub fn new(api_key: String) -> Self {
        let client = Client::builder()
            .build()
            .expect("Failed to create reqwest client");
        BirdeyeClient { client, api_key }
    }

    async fn get(&self, endpoint: &str) -> Result<reqwest::Response> {
        let url = format!("{}{}", BIRDEYE_API_URL, endpoint);
        debug!("Making GET request to: {}", url);
        
        let response = self
            .client
            .get(&url)
            .header("X-API-KEY", &self.api_key)
            .send()
            .await
            .context(format!("Failed to send GET request to {}", url))?;

        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await.unwrap_or_else(|_| "No error text".to_string());
            error!("HTTP error {}: {}", status, error_text);
            return Err(anyhow!("HTTP {} error: {}", status, error_text));
        }

        debug!("Received successful response from {}", url);
        Ok(response)
    }
}

#[async_trait]
impl BirdeyeApi for BirdeyeClient {
    async fn get_market_data(&self, address: &str) -> Result<TokenMarketResponse> {
        debug!("Fetching market data for address: {}", address);
        let endpoint = format!("/defi/v3/token/market-data?address={}", address);
        let response: ApiResponse<TokenMarketResponse> = self
            .get(&endpoint)
            .await?
            .json()
            .await
            .context("Failed to deserialize market data response")?;

        if response.success {
            debug!("Successfully retrieved market data for {}", address);
            Ok(response.data)
        } else {
            let error_msg = response.message.unwrap_or_else(|| "Unknown error".to_string());
            error!("Failed to get market data: {}", error_msg);
            Err(anyhow!("Failed to get market data: {}", error_msg))
        }
    }

    async fn get_token_overview(&self, address: &str) -> Result<TokenOverviewResponse> {
        debug!("Fetching token overview for address: {}", address);
        let endpoint = format!("/defi/token_overview?address={}", address);
        let response: ApiResponse<TokenOverviewResponse> = self
            .get(&endpoint)
            .await?
            .json()
            .await
            .context("Failed to deserialize token overview response")?;

        if response.success {
            debug!("Successfully retrieved token overview for {}", address);
            Ok(response.data)
        } else {
            let error_msg = response.message.unwrap_or_else(|| "Unknown error".to_string());
            error!("Failed to get token overview: {}", error_msg);
            Err(anyhow!("Failed to get token overview: {}", error_msg))
        }
    }

    async fn get_trending_tokens(&self) -> Result<Vec<TrendingToken>> {
        debug!("Fetching trending tokens");
        let endpoint = "/defi/token_trending?sort_by=rank&sort_type=asc&limit=20";
        let response: ApiResponse<TrendingTokenData> = self
            .get(&endpoint)
            .await?
            .json()
            .await
            .context("Failed to deserialize trending tokens response")?;

        if response.success {
            debug!("Successfully retrieved {} trending tokens", response.data.tokens.len());
            Ok(response.data.tokens)
        } else {
            let error_msg = response.message.unwrap_or_else(|| "Unknown error".to_string());
            error!("Failed to get trending tokens: {}", error_msg);
            Err(anyhow!("Failed to get trending tokens: {}", error_msg))
        }
    }
}

// Mock BirdeyeApi for testing
#[cfg(test)]
pub struct MockBirdeyeApi {
    pub market_data: Option<TokenMarketResponse>,
    pub token_overview: Option<TokenOverviewResponse>,
    pub trending_tokens: Option<Vec<TrendingToken>>,
}

#[cfg(test)]
impl MockBirdeyeApi {
    pub fn new() -> Self {
        MockBirdeyeApi {
            market_data: None,
            token_overview: None,
            trending_tokens: None,
        }
    }
}

#[cfg(test)]
#[async_trait]
impl BirdeyeApi for MockBirdeyeApi {
    async fn get_market_data(&self, _address: &str) -> Result<TokenMarketResponse> {
        self.market_data.clone().ok_or(anyhow!("Mock not set"))
    }

    async fn get_token_overview(&self, _address: &str) -> Result<TokenOverviewResponse> {
        self.token_overview.clone().ok_or(anyhow!("Mock not set"))
    }

    async fn get_trending_tokens(&self) -> Result<Vec<TrendingToken>> {
        self.trending_tokens.clone().ok_or(anyhow!("Mock not set"))
    }
}


================================================
File: src/birdeye/mod.rs
================================================
pub mod api;
use crate::models::token_info::TokenInfo;
pub use api::{BirdeyeApi, TokenMarketResponse};
use async_trait::async_trait;
pub use crate::models::trending_token::TrendingToken;

pub const BIRDEYE_API_URL: &str = "https://public-api.birdeye.so";
const RATE_LIMIT_DELAY: u64 = 500; // 500ms between requests

pub const TOKEN_ADDRESSES: &[(&str, &str)] = &[
    ("SOL", "So11111111111111111111111111111111111111112"),
    ("USDC", "EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v"),
    ("USDT", "Es9vMFrzaCERmJfrF4H2FYD4KCoNkY11McCe8BenwNYB"),
    ("PYUSD", "HZ1JovNiVvGrGNiiYvEozEVgZ58xaU3RKwX8eACQBCt3"),
];

#[async_trait]
pub trait BirdeyeClient: Send + Sync {
    async fn get_token_info(&self, symbol: &str) -> Result<TokenInfo, anyhow::Error>;
    async fn get_token_info_by_address(&self, address: &str) -> Result<TokenInfo, anyhow::Error>;
    async fn get_market_data(&self, address: &str) -> Result<TokenMarketResponse, anyhow::Error>;
    async fn get_trending_tokens(&self, limit: usize) -> Result<Vec<TrendingToken>, anyhow::Error>;
}


================================================
File: src/character/mod.rs
================================================
use serde::{Deserialize, Serialize};
use std::collections::HashMap;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Character {
    pub name: String,
    pub username: String,
    pub clients: Vec<String>,
    pub model_provider: String,
    pub image_model_provider: String,
    pub plugins: Vec<String>,
    pub settings: Settings,
    pub system: String,
    pub bio: Vec<String>,
    pub lore: Vec<String>,
    pub knowledge: Vec<String>,
    pub message_examples: Vec<Vec<MessageExample>>,
    pub post_examples: Vec<String>,
    pub topics: Vec<String>,
    pub style: Style,
    pub adjectives: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Settings {
    pub secrets: HashMap<String, String>,
    pub voice: VoiceSettings,
    pub rag_knowledge: bool,
    pub model_config: ModelConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VoiceSettings {
    pub model: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelConfig {
    pub temperature: f32,
    pub max_tokens: u32,
    pub frequency_penalty: f32,
    pub presence_penalty: f32,
    pub top_p: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MessageExample {
    pub user: String,
    pub content: MessageContent,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MessageContent {
    pub text: String,
    pub action: Option<String>,
    pub content: Option<serde_json::Value>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Style {
    pub tone: String,
    pub writing: String,
    pub personality: String,
    pub quirks: Vec<String>,
    pub all: Vec<String>,
    pub chat: Vec<String>,
    pub post: Vec<String>,
}

impl Character {
    pub fn load(path: &str) -> anyhow::Result<Self> {
        let content = std::fs::read_to_string(path)?;
        let character = serde_json::from_str(&content)?;
        Ok(character)
    }

    pub fn get_system_prompt(&self) -> String {
        let mut prompt = String::new();
        
        // Add system description
        prompt.push_str(&self.system);
        prompt.push_str("\n\n");

        // Add style guidelines
        prompt.push_str("Style Guidelines:\n");
        for guideline in &self.style.all {
            prompt.push_str(&format!("- {}\n", guideline));
        }
        prompt.push_str("\n");

        // Add knowledge base summary
        prompt.push_str("Knowledge Base:\n");
        for knowledge in &self.knowledge {
            prompt.push_str(&format!("- {}\n", knowledge));
        }

        prompt
    }

    pub fn get_post_style(&self) -> Vec<String> {
        self.style.post.clone()
    }

    pub fn get_chat_style(&self) -> Vec<String> {
        self.style.chat.clone()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_character_deserialization() {
        let json = r#"{
            "name": "Vergen",
            "username": "vergen",
            "clients": ["direct", "discord", "telegram", "twitter"],
            "modelProvider": "anthropic",
            "imageModelProvider": "openai",
            "plugins": [],
            "settings": {
                "secrets": {},
                "voice": {
                    "model": "en_US-hfc_male-medium"
                },
                "ragKnowledge": true,
                "modelConfig": {
                    "temperature": 0.7,
                    "maxTokens": 2048,
                    "frequencyPenalty": 0.0,
                    "presencePenalty": 0.0,
                    "topP": 0.95
                }
            },
            "system": "Test system prompt",
            "bio": ["Test bio"],
            "lore": ["Test lore"],
            "knowledge": ["Test knowledge"],
            "messageExamples": [],
            "postExamples": [],
            "topics": ["Test topic"],
            "style": {
                "tone": "professional",
                "writing": "clear",
                "personality": "confident",
                "quirks": ["test quirk"],
                "all": ["test guideline"],
                "chat": ["test chat style"],
                "post": ["test post style"]
            },
            "adjectives": ["analytical"]
        }"#;

        let character: Character = serde_json::from_str(json).unwrap();
        assert_eq!(character.name, "Vergen");
        assert_eq!(character.username, "vergen");
    }
} 

================================================
File: src/characteristics/adjectives.rs
================================================
use std::fs;
use std::io;

use crate::core::characteristics::Characteristic;

pub struct Adjectives;

impl Characteristic for Adjectives {
    fn get_header(&self) -> String {
        "These are the adjectives.".to_string()
    }

    fn get_traits(&self, character_name: &str) -> io::Result<String> {
        let path = format!("./characters/{}/adjectives.txt", character_name);
        fs::read_to_string(&path)
    }
}


================================================
File: src/characteristics/bio.rs
================================================
use std::fs;
use std::io;

use crate::core::characteristics::Characteristic;

pub struct Bio;

impl Characteristic for Bio {
    fn get_header(&self) -> String {
        "This is your background.".to_string()
    }

    fn get_traits(&self, character_name: &str) -> io::Result<String> {
        let path = format!("./characters/{}/bio.txt", character_name);
        fs::read_to_string(&path)
    }
}


================================================
File: src/characteristics/lore.rs
================================================
use std::fs;
use std::io;

use crate::core::characteristics::Characteristic;

pub struct Lore;

impl Characteristic for Lore {
    fn get_header(&self) -> String {
        "This is your lore.".to_string()
    }

    fn get_traits(&self, character_name: &str) -> io::Result<String> {
        let path = format!("./characters/{}/lore.txt", character_name);
        fs::read_to_string(&path)
    }
}


================================================
File: src/characteristics/mod.rs
================================================
pub mod adjectives;
pub mod bio;
pub mod lore;
pub mod post_examples;
pub mod previous_messages;
pub mod topics;
pub mod styles;


================================================
File: src/characteristics/post_examples.rs
================================================
use std::fs;
use std::io;

use crate::core::characteristics::Characteristic;

pub struct PostExamples;

impl Characteristic for PostExamples {
    fn get_header(&self) -> String {
        "These are previous post examples.".to_string()
    }

    fn get_traits(&self, character_name: &str) -> io::Result<String> {
        let path = format!("./characters/{}/post_examples.txt", character_name);
        fs::read_to_string(&path)
    }
}


================================================
File: src/characteristics/previous_messages.rs
================================================
use std::fs;
use std::io;

use crate::core::characteristics::Characteristic;

pub struct PreviousMessages;

impl Characteristic for PreviousMessages {
    fn get_header(&self) -> String {
        "These are examples of your previous messages.".to_string()
    }

    fn get_traits(&self, character_name: &str) -> io::Result<String> {
        let path = format!("./characters/{}/previous_messages.txt", character_name);
        fs::read_to_string(&path)
    }
}


================================================
File: src/characteristics/styles.rs
================================================
use std::fs;
use std::io;

use crate::core::characteristics::Characteristic;

pub struct Styles;

impl Characteristic for Styles {
    fn get_header(&self) -> String {
        "This is the style you use to talk in".to_string()
    }

    fn get_traits(&self, character_name: &str) -> io::Result<String> {
        let path = format!("./characters/{}/styles.txt", character_name);
        fs::read_to_string(&path)
    }
}


================================================
File: src/characteristics/topics.rs
================================================
use std::fs;
use std::io;

use crate::core::characteristics::Characteristic;

pub struct Topics;

impl Characteristic for Topics {
    fn get_header(&self) -> String {
        "These are the topics you should talk about.".to_string()
    }

    fn get_traits(&self, character_name: &str) -> io::Result<String> {
        let path = format!("./characters/{}/topics.txt", character_name);
        fs::read_to_string(&path)
    }
}


================================================
File: src/clients/twitter.rs
================================================
use anyhow::{Result, anyhow};
use async_trait::async_trait;
use reqwest::{Client, cookie::Jar};
use serde::{Deserialize, Serialize};
use std::sync::Arc;
use tokio::sync::RwLock;
use url::Url;

const TWITTER_API_URL: &str = "https://api.twitter.com";
const TWITTER_LOGIN_URL: &str = "https://twitter.com/i/flow/login";

#[derive(Debug, Clone)]
pub struct TwitterClient {
    client: Arc<Client>,
    session: Arc<RwLock<Option<TwitterSession>>>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct TwitterSession {
    auth_token: String,
    csrf_token: String,
    cookies: Vec<(String, String)>,
}

#[async_trait]
pub trait SocialMediaClient: Send + Sync {
    async fn post(&self, content: &str) -> Result<String>;
    async fn reply(&self, parent_id: &str, content: &str) -> Result<String>;
    async fn delete(&self, post_id: &str) -> Result<()>;
}

impl TwitterClient {
    pub fn new() -> Self {
        let cookie_store = Arc::new(Jar::default());
        let client = Client::builder()
            .cookie_provider(cookie_store.clone())
            .build()
            .unwrap();

        Self {
            client: Arc::new(client),
            session: Arc::new(RwLock::new(None)),
        }
    }

    pub async fn login(&self, email: &str, username: &str, password: &str) -> Result<()> {
        // First, get the guest token and initial cookies
        let guest_token = self.get_guest_token().await?;
        
        // Start login flow
        let flow_token = self.start_login_flow(&guest_token).await?;
        
        // Submit username/email
        let account_flow_token = self.submit_username(&flow_token, username, email).await?;
        
        // Submit password
        let auth_token = self.submit_password(&account_flow_token, password).await?;
        
        // Store session
        let session = TwitterSession {
            auth_token,
            csrf_token: self.get_csrf_token().await?,
            cookies: self.extract_cookies(),
        };

        *self.session.write().await = Some(session);
        Ok(())
    }

    async fn get_guest_token(&self) -> Result<String> {
        let response = self.client
            .post(&format!("{}/1.1/guest/activate.json", TWITTER_API_URL))
            .send()
            .await?;

        #[derive(Deserialize)]
        struct GuestToken {
            guest_token: String,
        }

        let token: GuestToken = response.json().await?;
        Ok(token.guest_token)
    }

    async fn start_login_flow(&self, guest_token: &str) -> Result<String> {
        let response = self.client
            .get(TWITTER_LOGIN_URL)
            .header("x-guest-token", guest_token)
            .send()
            .await?;

        // Extract flow_token from response
        // This is a placeholder - actual implementation would need to parse the HTML/JS
        Ok("flow_token".to_string())
    }

    async fn submit_username(&self, flow_token: &str, username: &str, email: &str) -> Result<String> {
        // Submit username/email to the login flow
        // This is a placeholder - actual implementation would need to handle the specific endpoints
        Ok("account_flow_token".to_string())
    }

    async fn submit_password(&self, flow_token: &str, password: &str) -> Result<String> {
        // Submit password and get auth token
        // This is a placeholder - actual implementation would need to handle the specific endpoints
        Ok("auth_token".to_string())
    }

    async fn get_csrf_token(&self) -> Result<String> {
        // Get CSRF token from cookies or make a request to get it
        Ok("csrf_token".to_string())
    }

    fn extract_cookies(&self) -> Vec<(String, String)> {
        // Extract relevant cookies from the cookie store
        vec![]
    }

    async fn ensure_authenticated(&self) -> Result<()> {
        if self.session.read().await.is_none() {
            return Err(anyhow!("Not authenticated"));
        }
        Ok(())
    }
}

#[async_trait]
impl SocialMediaClient for TwitterClient {
    async fn post(&self, content: &str) -> Result<String> {
        self.ensure_authenticated().await?;
        
        let session = self.session.read().await;
        let session = session.as_ref().unwrap();

        let response = self.client
            .post(&format!("{}/2/tweets", TWITTER_API_URL))
            .header("authorization", &format!("Bearer {}", session.auth_token))
            .header("x-csrf-token", &session.csrf_token)
            .json(&serde_json::json!({
                "text": content
            }))
            .send()
            .await?;

        #[derive(Deserialize)]
        struct TweetResponse {
            data: TweetData,
        }

        #[derive(Deserialize)]
        struct TweetData {
            id: String,
        }

        let tweet: TweetResponse = response.json().await?;
        Ok(tweet.data.id)
    }

    async fn reply(&self, parent_id: &str, content: &str) -> Result<String> {
        self.ensure_authenticated().await?;
        
        let session = self.session.read().await;
        let session = session.as_ref().unwrap();

        let response = self.client
            .post(&format!("{}/2/tweets", TWITTER_API_URL))
            .header("authorization", &format!("Bearer {}", session.auth_token))
            .header("x-csrf-token", &session.csrf_token)
            .json(&serde_json::json!({
                "text": content,
                "reply": {
                    "in_reply_to_tweet_id": parent_id
                }
            }))
            .send()
            .await?;

        #[derive(Deserialize)]
        struct TweetResponse {
            data: TweetData,
        }

        #[derive(Deserialize)]
        struct TweetData {
            id: String,
        }

        let tweet: TweetResponse = response.json().await?;
        Ok(tweet.data.id)
    }

    async fn delete(&self, post_id: &str) -> Result<()> {
        self.ensure_authenticated().await?;
        
        let session = self.session.read().await;
        let session = session.as_ref().unwrap();

        self.client
            .delete(&format!("{}/2/tweets/{}", TWITTER_API_URL, post_id))
            .header("authorization", &format!("Bearer {}", session.auth_token))
            .header("x-csrf-token", &session.csrf_token)
            .send()
            .await?;

        Ok(())
    }
} 

================================================
File: src/config/agent_config.rs
================================================
use crate::error::{AgentError, AgentResult};
use serde::{Deserialize, Serialize};
use std::env;
use std::time::Duration;
use super::birdeye_config::BirdeyeConfig;

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct AgentConfig {
    pub openai_api_key: String,
    pub birdeye_api_key: String,
    pub twitter_bearer_token: String,
    pub analysis_interval: Duration,
    pub trade_min_confidence: f64,
    pub trade_max_amount: f64,
    pub trade_max_slippage: f64,
    pub birdeye: BirdeyeConfig,
}

impl AgentConfig {
    /// Creates a new AgentConfig from environment variables with validation
    pub fn new_from_env() -> AgentResult<Self> {
        // Load Birdeye config
        let birdeye = BirdeyeConfig::new_from_env()
            .map_err(|e| AgentError::Config(format!("Failed to load Birdeye config: {}", e)))?;

        let config = Self {
            openai_api_key: get_env_var("OPENAI_API_KEY")?,
            birdeye_api_key: get_env_var("BIRDEYE_API_KEY")?,
            twitter_bearer_token: env::var("TWITTER_BEARER_TOKEN")
                .unwrap_or_else(|_| "AAAA".to_string()),
            analysis_interval: parse_duration_secs("ANALYSIS_INTERVAL", 300)?,
            trade_min_confidence: parse_f64("TRADE_MIN_CONFIDENCE", 0.8)?,
            trade_max_amount: parse_f64("TRADE_MAX_AMOUNT", 100.0)?,
            trade_max_slippage: parse_f64("TRADE_MAX_SLIPPAGE", 0.05)?,
            birdeye,
        };

        config.validate()?;
        Ok(config)
    }

    /// Validates the configuration values
    fn validate(&self) -> AgentResult<()> {
        // Validate API keys are not empty
        if self.openai_api_key.is_empty() {
            return Err(AgentError::Config("OpenAI API key cannot be empty".into()));
        }
        if self.birdeye_api_key.is_empty() {
            return Err(AgentError::Config("Birdeye API key cannot be empty".into()));
        }

        // Validate trading parameters
        if !(0.0..=1.0).contains(&self.trade_min_confidence) {
            return Err(AgentError::InvalidConfig(
                "trade_min_confidence".into(),
                "must be between 0.0 and 1.0".into(),
            ));
        }
        if self.trade_max_amount <= 0.0 {
            return Err(AgentError::InvalidConfig(
                "trade_max_amount".into(),
                "must be greater than 0".into(),
            ));
        }
        if !(0.0..=1.0).contains(&self.trade_max_slippage) {
            return Err(AgentError::InvalidConfig(
                "trade_max_slippage".into(),
                "must be between 0.0 and 1.0".into(),
            ));
        }

        Ok(())
    }
}

/// Helper function to get an environment variable
fn get_env_var(key: &str) -> AgentResult<String> {
    env::var(key).map_err(|_| AgentError::MissingEnvVar(key.to_string()))
}

/// Helper function to parse a duration from seconds
fn parse_duration_secs(key: &str, default: u64) -> AgentResult<Duration> {
    let secs = env::var(key)
        .map(|v| v.parse::<u64>())
        .unwrap_or(Ok(default))
        .map_err(|_| {
            AgentError::InvalidConfig(
                key.to_string(),
                "must be a valid number of seconds".to_string(),
            )
        })?;

    Ok(Duration::from_secs(secs))
}

/// Helper function to parse an f64 value
fn parse_f64(key: &str, default: f64) -> AgentResult<f64> {
    let value = env::var(key)
        .map(|v| v.parse::<f64>())
        .unwrap_or(Ok(default))
        .map_err(|_| {
            AgentError::InvalidConfig(key.to_string(), "must be a valid number".to_string())
        })?;

    Ok(value)
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::env;

    #[test]
    fn test_config_validation() {
        // Set required environment variables
        env::set_var("OPENAI_API_KEY", "test_key");
        env::set_var("BIRDEYE_API_KEY", "test_key");
        env::set_var("TWITTER_BEARER_TOKEN", "test_token");
        env::set_var("TWITTER_EMAIL", "test@example.com");
        env::set_var("TWITTER_USERNAME", "test_user");
        env::set_var("TWITTER_PASSWORD", "test_pass");

        let config = AgentConfig::new_from_env().unwrap();
        assert_eq!(config.trade_min_confidence, 0.8); // Default value
        assert_eq!(config.trade_max_amount, 100.0); // Default value
        assert_eq!(config.trade_max_slippage, 0.05); // Default value

        // Test invalid confidence
        env::set_var("TRADE_MIN_CONFIDENCE", "2.0");
        assert!(AgentConfig::new_from_env().is_err());

        // Test invalid amount
        env::set_var("TRADE_MAX_AMOUNT", "-100");
        assert!(AgentConfig::new_from_env().is_err());

        // Test invalid slippage
        env::set_var("TRADE_MAX_SLIPPAGE", "2.0");
        assert!(AgentConfig::new_from_env().is_err());

        // Test invalid email
        env::set_var("TWITTER_EMAIL", "invalid_email");
        assert!(AgentConfig::new_from_env().is_err());
    }
}


================================================
File: src/config/birdeye_config.rs
================================================
use anyhow::Result;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct BirdeyeConfig {
    pub api_key: String,
    pub api_url: String,
}

impl BirdeyeConfig {
    pub fn new_from_env() -> Result<Self> {
        Ok(Self {
            api_key: std::env::var("BIRDEYE_API_KEY")?,
            api_url: std::env::var("BIRDEYE_API_URL")
                .unwrap_or_else(|_| "https://public-api.birdeye.so".to_string()),
        })
    }
} 

================================================
File: src/config/logging_config.rs
================================================
use tracing::Level;

pub fn get_log_level() -> Level {
    match std::env::var("RUST_LOG") {
        Ok(val) => match val.to_lowercase().as_str() {
            "trace" => Level::TRACE,
            "debug" => Level::DEBUG,
            "info" => Level::INFO,
            "warn" => Level::WARN,
            "error" => Level::ERROR,
            _ => Level::INFO,
        },
        Err(_) => Level::INFO,
    }
} 

================================================
File: src/config/market_config.rs
================================================
use crate::error::{AgentError, AgentResult};
use crate::utils::f64_to_decimal;
use bigdecimal::BigDecimal;
use std::env;

#[derive(Debug, Clone)]
pub struct MarketConfig {
    pub price_change_threshold: BigDecimal,
    pub volume_surge_threshold: BigDecimal,
    pub base_confidence: BigDecimal,
    pub price_weight: BigDecimal,
    pub volume_weight: BigDecimal,
}

impl MarketConfig {
    pub fn new_from_env() -> AgentResult<Self> {
        Ok(Self {
            price_change_threshold: parse_decimal_env("PRICE_CHANGE_THRESHOLD", 0.05)?,
            volume_surge_threshold: parse_decimal_env("VOLUME_SURGE_THRESHOLD", 1.0)?,
            base_confidence: parse_decimal_env("BASE_CONFIDENCE", 0.5)?,
            price_weight: parse_decimal_env("PRICE_WEIGHT", 0.3)?,
            volume_weight: parse_decimal_env("VOLUME_WEIGHT", 0.2)?,
        })
    }

    pub fn validate(&self) -> AgentResult<()> {
        // Validate thresholds are positive
        if self.price_change_threshold <= BigDecimal::from(0) {
            return Err(AgentError::InvalidConfig(
                "price_change_threshold".into(),
                "must be greater than 0".into(),
            ));
        }
        if self.volume_surge_threshold <= BigDecimal::from(0) {
            return Err(AgentError::InvalidConfig(
                "volume_surge_threshold".into(),
                "must be greater than 0".into(),
            ));
        }

        // Validate weights sum to less than or equal to 1
        let total_weight = &self.price_weight + &self.volume_weight;
        if total_weight > BigDecimal::from(1) {
            return Err(AgentError::InvalidConfig(
                "weights".into(),
                "sum of weights must not exceed 1.0".into(),
            ));
        }

        Ok(())
    }
}

impl Default for MarketConfig {
    fn default() -> Self {
        Self {
            price_change_threshold: f64_to_decimal(0.05),
            volume_surge_threshold: f64_to_decimal(1.0),
            base_confidence: f64_to_decimal(0.5),
            price_weight: f64_to_decimal(0.3),
            volume_weight: f64_to_decimal(0.2),
        }
    }
}

fn parse_decimal_env(key: &str, default: f64) -> AgentResult<BigDecimal> {
    match env::var(key) {
        Ok(val) => val
            .parse::<f64>()
            .map_err(|_| {
                AgentError::InvalidConfig(
                    key.to_string(),
                    "must be a valid decimal number".to_string(),
                )
            })
            .map(f64_to_decimal),
        Err(_) => Ok(f64_to_decimal(default)),
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_market_config_defaults() {
        let config = MarketConfig::default();
        assert_eq!(config.price_change_threshold, f64_to_decimal(0.05));
        assert_eq!(config.volume_surge_threshold, f64_to_decimal(1.0));
        assert_eq!(config.base_confidence, f64_to_decimal(0.5));
    }

    #[test]
    fn test_market_config_validation() {
        // Valid config
        let config = MarketConfig::default();
        assert!(config.validate().is_ok());

        // Invalid: negative threshold
        let mut invalid_config = MarketConfig::default();
        invalid_config.price_change_threshold = f64_to_decimal(-0.1);
        assert!(invalid_config.validate().is_err());

        // Invalid: weights sum > 1
        let mut invalid_weights = MarketConfig::default();
        invalid_weights.price_weight = f64_to_decimal(0.6);
        invalid_weights.volume_weight = f64_to_decimal(0.5);
        assert!(invalid_weights.validate().is_err());
    }
}


================================================
File: src/config/mod.rs
================================================
pub mod agent_config;
pub mod birdeye_config;
pub mod logging_config;
pub mod market_config;
pub mod mongodb;

pub use self::agent_config::AgentConfig;
pub use self::birdeye_config::BirdeyeConfig;
pub use self::logging_config::get_log_level;
pub use self::market_config::MarketConfig;
use rig::providers::openai::{GPT_4O, GPT_4O_MINI, O1_MINI, O1_PREVIEW};

pub const DEFAULT_MODEL: &str = GPT_4O_MINI;

pub fn get_openai_model() -> &'static str {
    match std::env::var("OPENAI_MODEL").as_deref() {
        Ok("gpt-4o") => GPT_4O,
        Ok("gpt-4o-mini") => GPT_4O_MINI,
        Ok("o3-mini") => O1_MINI,
        Ok("o1-preview") => O1_PREVIEW,
        _ => DEFAULT_MODEL,
    }
}


================================================
File: src/config/mongodb.rs
================================================
use anyhow::{anyhow, Result};
use async_trait::async_trait;
use futures::TryStreamExt;
use mongodb::{
    bson::{self, doc, Document},
    options::ClientOptions,
    Client, Database,
};
use serde::{Deserialize, Deserializer, Serialize};
use serde_json::Value;
use std::{env, sync::Arc, time::Duration};

#[derive(Debug, Clone)]
pub struct MongoPoolConfig {
    pub min_pool_size: u32,
    pub max_pool_size: u32,
    pub connect_timeout: Duration,
}

impl Default for MongoPoolConfig {
    fn default() -> Self {
        Self {
            min_pool_size: 5,
            max_pool_size: 10,
            connect_timeout: Duration::from_secs(20),
        }
    }
}

impl MongoPoolConfig {
    pub fn from_env() -> Self {
        Self {
            min_pool_size: std::env::var("MONGODB_MIN_POOL_SIZE")
                .ok()
                .and_then(|s| s.parse().ok())
                .unwrap_or(5),
            max_pool_size: std::env::var("MONGODB_MAX_POOL_SIZE")
                .ok()
                .and_then(|s| s.parse().ok())
                .unwrap_or(10),
            connect_timeout: Duration::from_millis(
                std::env::var("MONGODB_CONNECT_TIMEOUT_MS")
                    .ok()
                    .and_then(|s| s.parse().ok())
                    .unwrap_or(20000),
            ),
        }
    }

    pub fn apply_to_options(&self, options: &mut ClientOptions) {
        options.min_pool_size = Some(self.min_pool_size);
        options.max_pool_size = Some(self.max_pool_size);
        options.connect_timeout = Some(self.connect_timeout);
    }
}

#[derive(Debug, Clone)]
pub struct MongoConfig {
    pub uri: String,
    pub database: String,
    pub app_name: Option<String>,
    pub pool_config: MongoPoolConfig,
}

impl Default for MongoConfig {
    fn default() -> Self {
        Self {
            uri: "mongodb://localhost:32770".to_string(),
            database: "cainam".to_string(),
            app_name: Some("cainam-core".to_string()),
            pool_config: MongoPoolConfig::default(),
        }
    }
}

impl MongoConfig {
    pub fn from_env() -> Self {
        let uri = env::var("MONGODB_URI").expect("MONGODB_URI must be set");
        let database = env::var("MONGODB_DATABASE").expect("MONGODB_DATABASE must be set");

        Self {
            uri,
            database,
            app_name: None,
            pool_config: MongoPoolConfig::default(),
        }
    }
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct TokenAnalyticsData {
    #[serde(rename = "_id", deserialize_with = "deserialize_object_id")]
    pub id: String,
    pub token_address: String,
    pub token_name: String,
    pub token_symbol: String,
    pub price: f64,
    pub volume_24h: Option<f64>,
    pub market_cap: Option<f64>,
    pub total_supply: Option<f64>,
    pub timestamp: bson::DateTime,
    pub created_at: Option<bson::DateTime>,
}

fn deserialize_object_id<'de, D>(deserializer: D) -> Result<String, D::Error>
where
    D: Deserializer<'de>,
{
    let value = Value::deserialize(deserializer)?;
    match value {
        Value::String(s) => Ok(s),
        Value::Object(map) => {
            if let Some(Value::String(oid)) = map.get("$oid") {
                Ok(oid.to_string())
            } else {
                Err(serde::de::Error::custom(
                    "Expected $oid field with string value",
                ))
            }
        }
        _ => Err(serde::de::Error::custom(
            "Expected string or object with $oid field",
        )),
    }
}

#[derive(Clone)]
pub struct MongoDbPool {
    client: Client,
    config: MongoConfig,
    db: Database,
}

impl MongoDbPool {
    pub async fn create_pool(config: MongoConfig) -> Result<Arc<MongoDbPool>> {
        let mut client_options = ClientOptions::parse(&config.uri).await?;

        if let Some(app_name) = &config.app_name {
            client_options.app_name = Some(app_name.clone());
        }

        // Set server API version to ensure compatibility
        client_options.server_api = Some(
            mongodb::options::ServerApi::builder()
                .version(mongodb::options::ServerApiVersion::V1)
                .build(),
        );

        // Apply pool configuration
        config.pool_config.apply_to_options(&mut client_options);

        let client = Client::with_options(client_options)?;
        let db = client.database(&config.database);

        // Test the connection
        client
            .database("admin")
            .run_command(doc! {"ping": 1})
            .await?;

        Ok(Arc::new(MongoDbPool { client, config, db }))
    }

    pub fn database(&self, name: &str) -> mongodb::Database {
        self.db.clone()
    }

    pub fn get_config(&self) -> &MongoConfig {
        &self.config
    }

    pub fn client(&self) -> &Client {
        &self.client
    }
}

#[async_trait]
pub trait TokenAnalyticsDataExt {
    async fn insert_token_analytics_documents<T>(
        &self,
        collection_name: &str,
        documents: Vec<T>,
    ) -> Result<()>
    where
        T: Serialize + Send + Sync;

    async fn find_tokens(
        &self,
        collection_name: &str,
        filter: Option<Document>,
        limit: i64,
    ) -> Result<Vec<Document>>;
}

#[async_trait]
impl TokenAnalyticsDataExt for MongoDbPool {
    async fn insert_token_analytics_documents<T>(
        &self,
        collection_name: &str,
        documents: Vec<T>,
    ) -> Result<()>
    where
        T: Serialize + Send + Sync,
    {
        let collection = self.db.collection::<Document>(collection_name);

        for doc in documents {
            let token_data_doc =
                bson::to_document(&doc).map_err(|e| anyhow!("Serialization error: {}", e))?;
            collection.insert_one(token_data_doc).await?;
        }

        Ok(())
    }

    async fn find_tokens(
        &self,
        collection_name: &str,
        filter: Option<Document>,
        limit: i64,
    ) -> Result<Vec<Document>> {
        let collection = self.db.collection::<Document>(collection_name);

        let filter = filter.unwrap_or_else(|| doc! {});
        let cursor = collection.find(filter).await?;

        let documents: Vec<Document> = cursor.try_collect().await?;
        Ok(documents)
    }
}


================================================
File: src/core/agent.rs
================================================
use rig::agent::Agent as RigAgent;
use rig::providers::openai::{Client as OpenAIClient, CompletionModel, GPT_4_TURBO};
use rig::{completion::Prompt, providers};
use anyhow::Result;

pub struct Agent {
    agent: RigAgent<CompletionModel>,
}

impl Agent {
    pub fn new(openai_api_key: &str, prompt: &str) -> Self {
        let openai_client = OpenAIClient::new(openai_api_key);
        let agent = openai_client
            .agent(GPT_4_TURBO)
            .preamble(prompt)
            .temperature(1.0)
            .build();

        Agent { agent }
    }

    pub async fn prompt(&self, input: &str) -> Result<String> {
        let response = self.agent.prompt(input).await?;
        Ok(response)
    }
}


================================================
File: src/core/characteristics.rs
================================================
use std::io;

use crate::characteristics::{
    adjectives::Adjectives, bio::Bio, lore::Lore, post_examples::PostExamples,
    previous_messages::PreviousMessages, styles::Styles, topics::Topics,
};

// Trait to simulate each characteristic module
pub trait Characteristic {
    fn get_header(&self) -> String;
    fn get_traits(&self, character_name: &str) -> io::Result<String>;
}

pub struct Characteristics;

impl Characteristics {
    // Simulate getCharacteristics
    pub fn get_characteristics() -> Vec<Box<dyn Characteristic>> {
        vec![
            Box::new(Bio),
            Box::new(Lore),
            Box::new(PreviousMessages),
            Box::new(PostExamples),
            Box::new(Adjectives),
            Box::new(Topics),
            Box::new(Styles),
        ]
    }

    // Simulate buildCharacteristicsInstructions
    pub fn build_characteristics_instructions(character_name: &str) -> String {
        let mut chars_instruction = String::new();
        let characteristics = Self::get_characteristics();

        for characteristic in characteristics {
            chars_instruction += &characteristic.get_header();
            chars_instruction += "\n";
            chars_instruction += &characteristic.get_traits(character_name).unwrap();
            chars_instruction += "\n";
        }

        chars_instruction
    }

    // Simulate getCharacterInstructions
    pub fn get_character_instructions(chars_instruction: &String) -> &String {
        chars_instruction
    }
}


================================================
File: src/core/instruction_builder.rs
================================================
use std::fs;
use std::io::{self};

use super::characteristics::Characteristics;

pub struct InstructionBuilder {
    instructions: String,
}

impl InstructionBuilder {
    pub fn new() -> Self {
        Self {
            instructions: String::new(),
        }
    }

    // Read base instructions from a file
    pub fn get_base(character_name: &str) -> io::Result<String> {
        let path = format!("./characters/{}/instructions/base.txt", character_name);
        fs::read_to_string(&path)
    }

    // Read suffix instructions from a file
    pub fn get_suffix(character_name: &str) -> io::Result<String> {
        let path = format!("./characters/{}/instructions/suffix.txt", character_name);
        fs::read_to_string(&path)
    }

    // Add instruction to the internal buffer
    pub fn add_instruction(&mut self, instruction: &str) {
        self.instructions.push_str(instruction);
    }

    // Add multiple instructions (array equivalent)
    pub fn add_instructions(&mut self, instructions: Vec<String>) {
        for instruction in instructions {
            self.add_instruction(&instruction);
        }
    }

    // Build the complete instructions
    pub fn build_instructions(&mut self, character_name: &str) -> io::Result<()> {
        self.instructions.clear();

        let characteristics = Characteristics::build_characteristics_instructions(character_name);

        // Add base instructions
        if let Ok(base) = Self::get_base(character_name) {
            self.add_instruction(&base);
        }

        // Add characteristics instructions
        self.add_instruction(&characteristics);

        // Add suffix instructions
        if let Ok(suffix) = Self::get_suffix(character_name) {
            self.add_instruction(&suffix);
        }

        Ok(())
    }

    // Get the complete instructions
    pub fn get_instructions(&self) -> &str {
        &self.instructions
    }
}


================================================
File: src/core/mod.rs
================================================
pub mod agent;
pub mod characteristics;
pub mod instruction_builder;
pub mod runtime;


================================================
File: src/core/runtime.rs
================================================
use rand::Rng;
use tokio::time::{sleep, Duration};

use crate::{
    core::agent::Agent,
    memory::MemoryStore,
    providers::{ai16z_twitter::Ai16zTwitter, discord::Discord, twitter::Twitter},
};

pub enum TwitterType {
    ApiKeys(Twitter),
    Ai16zTwitter(Ai16zTwitter),
}

impl TwitterType {
    pub async fn tweet(&self, text: &str) -> Result<(), anyhow::Error> {
        match self {
            TwitterType::ApiKeys(twitter) => {
                // Call the tweet method for Twitter API
                twitter.tweet(text.to_string()).await
            }
            TwitterType::Ai16zTwitter(ai6z_twitter) => {
                // Call the tweet method for Ai6zTwitter
                ai6z_twitter.tweet(text.to_string()).await
            }
        }
    }
}

pub struct Runtime {
    openai_api_key: String,
    twitter: TwitterType,
    discord: Discord,
    agents: Vec<Agent>,
    memory: Vec<String>,
}

impl Runtime {
    pub fn new(
        openai_api_key: &str,
        discord_webhook_url: &str,
        twitter_consumer_key: Option<&str>,
        twitter_consumer_secret: Option<&str>,
        twitter_access_token: Option<&str>,
        twitter_access_token_secret: Option<&str>,
        twitter_username: Option<&str>,
        twitter_password: Option<&str>,
    ) -> Self {
        let twitter = match (twitter_username, twitter_password) {
            (Some(username), Some(password)) => {
                // If both username and password are provided, prioritize Ai6zTwitter
                TwitterType::Ai16zTwitter(Ai16zTwitter::new(username, password))
            }
            (_, _) => {
                // Otherwise, fall back to Twitter API keys if available
                match (
                    twitter_consumer_key,
                    twitter_consumer_secret,
                    twitter_access_token,
                    twitter_access_token_secret,
                ) {
                    (
                        Some(consumer_key),
                        Some(consumer_secret),
                        Some(access_token),
                        Some(access_token_secret),
                    ) => TwitterType::ApiKeys(Twitter::new(
                        consumer_key,
                        consumer_secret,
                        access_token,
                        access_token_secret,
                    )),
                    _ => panic!("You must provide either Twitter username/password or API keys."),
                }
            }
        };
        let discord = Discord::new(discord_webhook_url);

        let agents = Vec::new();
        let memory: Vec<String> = MemoryStore::load_memory().unwrap_or_else(|_| Vec::new());

        Runtime {
            discord,
            memory,
            openai_api_key: openai_api_key.to_string(),
            agents,
            twitter,
        }
    }

    pub fn add_agent(&mut self, prompt: &str) {
        let agent = Agent::new(&self.openai_api_key, prompt);
        self.agents.push(agent);
    }

    pub async fn run(&mut self) -> Result<(), anyhow::Error> {
        if self.agents.is_empty() {
            return Err(anyhow::anyhow!("No agents available")).map_err(Into::into);
        }

        let mut rng = rand::thread_rng();
        let selected_agent = &self.agents[rng.gen_range(0..self.agents.len())];
        let response = selected_agent.prompt("tweet").await?;

        match MemoryStore::add_to_memory(&mut self.memory, &response) {
            Ok(_) => println!("Response saved to memory."),
            Err(e) => eprintln!("Failed to save response to memory: {}", e),
        }

        println!("AI Response: {}", response);
        self.discord.send_channel_message(&response.clone()).await;
        self.twitter.tweet(&response).await?;
        Ok(())
    }

    pub async fn run_periodically(&mut self) -> Result<(), anyhow::Error> {
        let mut rng = rand::thread_rng();

        loop {
            let random_sleep_duration = rng.gen_range(300..=1800);

            sleep(Duration::from_secs(random_sleep_duration)).await;

            if let Err(e) = self.run().await {
                eprintln!("Error running process: {}", e);
            }
        }
    }
}


================================================
File: src/database/mod.rs
================================================
use std::sync::Arc;

use async_trait::async_trait;
pub use mongodb::{
    Collection,
    options::{FindOptions, FindOneOptions},
    bson::{self, doc, Document, DateTime},
};
use crate::config::mongodb::{MongoConfig, MongoDbPool};
use anyhow::Result;
use serde::{de::DeserializeOwned, Serialize};
// pub mod sync;

#[derive(Clone)]
pub struct DatabaseManager {
    pool: Arc<MongoDbPool>,
}

impl DatabaseManager {
    pub async fn new(config: MongoConfig) -> Result<Self> {
        let pool = MongoDbPool::create_pool(config).await?;
        Ok(Self { pool })
    }

    pub fn get_pool(&self) -> &MongoDbPool {
        &self.pool
    }

    pub fn get_database(&self, name: &str) -> mongodb::Database {
        self.pool.database(name)
    }
}

#[async_trait]
pub trait MongoDbExtensions {
    fn get_collection<T>(&self, name: &str) -> Collection<T> 
    where 
    T: Serialize + DeserializeOwned + Unpin + Send + Sync + 'static;

    async fn find_one_by_id<T>(&self, collection: &str, id: bson::oid::ObjectId) -> Result<Option<T>> 
    where 
    T: Serialize + DeserializeOwned + Unpin + Send + Sync + 'static;

    async fn find_one_by_filter<T>(&self, collection: &str, filter: bson::Document) -> Result<Option<T>>
    where 
    T: Serialize + DeserializeOwned + Unpin + Send + Sync + 'static;

    async fn find_with_sort<T>(&self, collection: &str, filter: bson::Document, sort: bson::Document, limit: Option<i64>) -> Result<Vec<T>>
    where 
    T: Serialize + DeserializeOwned + Unpin + Send + Sync + 'static;
}

// impl MongoDbExtensions for mongodb::Database {
//     fn get_collection<T>(&self, name: &str) -> Collection<T> 
//     where 
//     T: Serialize + DeserializeOwned + Unpin + Send + Sync + 'static
//     {
//         self.collection(name)
//     }

//     async fn find_one_by_id<T>(&self, collection: &str, id: bson::oid::ObjectId) -> Result<Option<T>>
//     where
//         T: Serialize + DeserializeOwned + Unpin + Send + Sync + 'static, // Crucial change
//     {
//         let filter = doc! { "_id": id };
//         let collection: Collection<T> = self.collection(collection); // Type hint for clarity
//         Ok(collection.find_one(filter).await?)
//     }

//     async fn find_one_by_filter<T>(&self, collection: &str, filter: bson::Document) -> Result<Option<T>>
//     where 
//     T: Serialize + DeserializeOwned + Unpin + Send + Sync + 'static, // Crucial change
//     {
//         Ok(self.collection(collection).find_one(filter).await?)
//     }

//     async fn find_with_sort<T>(&self, collection: &str, filter: bson::Document, sort: bson::Document, limit: Option<i64>) -> Result<Vec<T>>
//     where 
//     T: Serialize + DeserializeOwned + Unpin + Send + Sync + 'static, // Crucial change
//     {
//         let options = FindOptions::builder()
//             .sort(sort)
//             .limit(limit)
//             .build();

//         let mut cursor = self.collection(collection).find(filter).await?;
//         let mut results = Vec::new();
        
//         while let Some(doc) = cursor.try_next().await? {
//             results.push(doc);
//         }
        
//         Ok(results)
//     }
// }

// Vector store configuration helper
// pub fn create_vector_search_params() -> SearchParams {
//     SearchParams::new()
//         .with_distance_metric("cosine")
//         .with_embedding_field("vector")
//         .with_index_type("hnsw")
// }

// #[cfg(test)]
// mod tests {
//     use super::*;
//     use crate::test_utils::setup_test_db;

//     #[tokio::test]
//     async fn test_database_extensions() {
//         let (pool, db_name) = setup_test_db().await.unwrap();
//         let db = pool.database(&db_name);

//         // Test find_one_by_filter
//         let filter = doc! { "test_field": "test_value" };
//         let result = db.find_one_by_filter::<Document>("test_collection", filter).await;
//         assert!(result.is_ok());
//     }
// }

================================================
File: src/database/sync.rs
================================================
use anyhow::Result;
use bson::doc;
use chrono::{DateTime, Utc};
use mongodb::Database;
use serde::{Serialize, Deserialize};
use std::sync::Arc;
use tracing::{info, warn};
use rig::completion::CompletionModel;
use solana_sdk::signature::Keypair;
use crate::error::Error;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenState {
    pub address: String,
    pub symbol: String,
    pub name: String,
    pub price_usd: f64,
    pub price_sol: f64,
    pub volume_24h: f64,
    pub market_cap: f64,
    pub price_change_24h: f64,
    pub volume_change_24h: f64,
    pub timestamp: DateTime<Utc>,
}

pub struct DataSyncService<M: CompletionModel> {
    db: Arc<Database>,
    data_provider: Arc<dyn DataProvider>,
    twitter: Arc<TwitterClient>,
    trading_strategy: Arc<TradingStrategy<M>>,
    dex: JupiterDex,
    personality: StoicPersonality,
    wallet: Arc<Keypair>,
    sync_interval: u64,
}

impl<M: CompletionModel> DataSyncService<M> {
    pub fn new(
        db: Arc<Database>,
        data_provider: Arc<dyn DataProvider>,
        twitter: Arc<TwitterClient>,
        trading_strategy: Arc<TradingStrategy<M>>,
        dex: JupiterDex,
        wallet: Arc<Keypair>,
        sync_interval: u64,
    ) -> Self {
        Self {
            db,
            data_provider,
            twitter,
            trading_strategy,
            dex,
            personality: StoicPersonality::new(),
            wallet,
            sync_interval,
        }
    }

    pub async fn sync_market_data(&self) -> Result<()> {
        info!("Starting market data sync cycle");
        
        // Fetch trending tokens
        info!("Fetching trending tokens from BirdEye");
        let trends = self.data_provider.get_trending_tokens(20).await?;
        info!("Found {} trending tokens", trends.len());

        // Insert token states and analyze trading opportunities
        for trend in trends {
            info!(
                "Processing token {} ({}) - Price: ${:.4}, 24h Change: {:.2}%, Volume: ${:.2}M",
                trend.metadata.name,
                trend.metadata.symbol,
                trend.metadata.price_usd,
                trend.price_change_24h,
                trend.metadata.volume_24h / 1_000_000.0
            );

            let state = self.market_trend_to_token_state(trend.clone());
            info!("Inserting token state into MongoDB");
            self.db.insert_one("token_states", &state).await?;

            // Format market data for LLM analysis
            let prompt = format!(
                "Analyze trading opportunity for {} ({}). Price: ${:.4}, 24h Change: {:.2}%, Volume: ${:.2}M",
                trend.metadata.name,
                trend.metadata.symbol,
                trend.metadata.price_usd,
                trend.price_change_24h,
                trend.metadata.volume_24h / 1_000_000.0
            );

            // Analyze trading opportunity
            info!("Analyzing trading opportunity with LLM");
            if let Ok(analysis) = self.trading_strategy.analyze_trading_opportunity(prompt, 1.0).await {
                // Parse the analysis into a trade recommendation
                if let Ok(trade) = serde_json::from_str::<TradeRecommendation>(&analysis) {
                    info!(
                        "Received trade recommendation: Action={:?}, Amount={} SOL, Confidence={:.2}, Risk={}",
                        trade.action, trade.amount_in_sol, trade.confidence, trade.risk_assessment
                    );
                    
                    // Execute trade if confidence is high enough
                    if trade.confidence >= 0.8 {
                        match trade.action {
                            TradeAction::Buy => {
                                info!("Executing BUY order for {} SOL worth of {}", 
                                    trade.amount_in_sol, trend.metadata.symbol);
                                
                                if let Ok(signature) = self.dex.execute_swap(
                                    "So11111111111111111111111111111111111111112", // SOL
                                    &trade.token_address,
                                    trade.amount_in_sol as u64,
                                    &self.wallet,
                                ).await {
                                    info!("Trade executed successfully. Signature: {}", signature);

                                    // Generate and post tweet about the trade
                                    info!("Generating tweet for successful buy");
                                    let tweet = self.personality.generate_trade_tweet(
                                        &self.trading_strategy.agent,
                                        &format!(
                                            "Action: Buy\nAmount: {} SOL\nToken: {}\nPrice: ${:.4}\nMarket Cap: ${:.2}M\n24h Volume: ${:.2}M\n24h Change: {:.2}%\nContract: {}\nTransaction: {}\nAnalysis: {}\nRisk Assessment: {}\nMarket Analysis:\n- Volume: {}\n- Price Trend: {}\n- Liquidity: {}\n- Momentum: {}",
                                            trade.amount_in_sol,
                                            trend.metadata.symbol,
                                            trend.metadata.price_usd,
                                            trend.metadata.market_cap / 1_000_000.0,
                                            trend.metadata.volume_24h / 1_000_000.0,
                                            trend.price_change_24h,
                                            trend.token_address,
                                            signature,
                                            trade.reasoning,
                                            trade.risk_assessment,
                                            trade.market_analysis.volume_analysis,
                                            trade.market_analysis.price_trend,
                                            trade.market_analysis.liquidity_assessment,
                                            trade.market_analysis.momentum_indicators
                                        ),
                                    ).await?;
                                    
                                    info!("Posting tweet: {}", tweet);
                                    if let Err(e) = self.twitter.post_tweet(&tweet).await {
                                        warn!("Failed to post trade tweet: {}", e);
                                    }
                                } else {
                                    warn!("Failed to execute buy order");
                                }
                            },
                            TradeAction::Sell => {
                                info!("Skipping SELL action - not implemented yet");
                            },
                            TradeAction::Hold => {
                                info!("Decision: HOLD {} - {}", 
                                    trend.metadata.symbol, trade.reasoning);
                            }
                        }
                    } else {
                        info!("Skipping trade due to low confidence: {:.2}", trade.confidence);
                    }
                } else {
                    warn!("Failed to parse trade recommendation");
                }
            } else {
                warn!("Failed to get trading analysis from LLM");
            }
        }

        info!("Market data sync cycle complete");
        Ok(())
    }

    pub async fn get_token_state(&self, token_address: &str) -> Result<Option<TokenState>> {
        let collection = self.db
            .database()
            .collection("token_states");
            
        let filter = doc! {
            "address": token_address
        };
        
        let options = rig_mongodb::options::FindOneOptions::builder()
            .sort(doc! { "timestamp": -1 })
            .build();
            
        collection.find_one(filter, options)
            .await
            .map_err(anyhow::Error::from)
    }

    pub async fn get_token_history(
        &self,
        token_address: &str,
        start_time: DateTime<Utc>,
        end_time: DateTime<Utc>,
    ) -> Result<Vec<TokenState>> {
        let collection = self.db
            .database()
            .collection("token_states");
            
        let filter = doc! {
            "address": token_address,
            "timestamp": {
                "$gte": start_time,
                "$lte": end_time
            }
        };
        
        let options = rig_mongodb::options::FindOptions::builder()
            .sort(doc! { "timestamp": -1 })
            .build();
            
        let cursor = collection.find(filter, options).await?;
        cursor.try_collect().await.map_err(anyhow::Error::from)
    }
}

pub fn sync_databases(source: &Database, target: &Database) -> Result<(), Error> {
    // ...existing code...
}

================================================
File: src/logging/mod.rs
================================================
use crate::services::token_analytics::{MarketMetrics, MarketSignalLog};
use anyhow::Result;
use chrono::{DateTime, Utc};
use serde::Serialize;
use std::time::Instant;
use tracing::{error, info, warn};
use tracing_subscriber::{fmt, EnvFilter};

#[derive(Debug, Serialize)]
pub struct PerformanceMetrics {
    pub operation: String,
    pub duration_ms: u64,
    pub success: bool,
    pub timestamp: DateTime<Utc>,
}

#[derive(Debug, Serialize)]
pub struct RequestLog {
    pub request_id: String,
    pub service: String,
    pub operation: String,
    pub start_time: DateTime<Utc>,
    pub duration_ms: u64,
    pub status: String,
    pub error: Option<String>,
}

pub struct RequestLogger {
    module: String,
    action: String,

    start_time: Instant,
    request_id: String,
}

impl RequestLogger {
    pub fn new(module: &str, action: &str) -> Self {
        Self {
            module: module.to_string(),
            action: action.to_string(),

            start_time: Instant::now(),
            request_id: uuid::Uuid::new_v4().to_string(),
        }
    }

    pub fn info(&self, message: &str) {
        info!(module = %self.module, action = %self.action, "{}", message);
    }

    pub fn warn(&self, message: &str) {
        warn!(module = %self.module, action = %self.action, "{}", message);
    }

    pub fn error(&self, message: &str) {
        error!(module = %self.module, action = %self.action, "{}", message);
    }

    pub fn success(self) {
        let duration = self.start_time.elapsed();
        let log = RequestLog {
            request_id: self.request_id,
            service: self.module,
            operation: self.action,
            start_time: Utc::now() - chrono::Duration::from_std(duration).unwrap(),
            duration_ms: duration.as_millis() as u64,
            status: "success".to_string(),
            error: None,
        };
        info!(target: "request", "{}", serde_json::to_string(&log).unwrap());
    }
}

pub fn log_market_metrics(metrics: &MarketMetrics) {
    info!(
        symbol = %metrics.symbol,
        price = %metrics.price,
        volume_24h = ?metrics.volume_24h,
        signal_type = ?metrics.signal_type,
        confidence = ?metrics.confidence,
        "Market metrics recorded"
    );
}

pub fn log_market_signal(signal: &MarketSignalLog) {
    info!(
        token = %signal.token_symbol,
        signal_type = %signal.signal_type,
        price_change = ?signal.price_change_24h,
        volume_change = ?signal.volume_change_24h,
        confidence = %signal.confidence,
        risk_score = %signal.risk_score,
        "Market signal generated"
    );
}

pub fn log_performance(metrics: PerformanceMetrics) {
    if metrics.success {
        info!(
            target = "performance",
            "{}",
            serde_json::to_string(&metrics).unwrap()
        );
    } else {
        warn!(
            target = "performance",
            "{}",
            serde_json::to_string(&metrics).unwrap()
        );
    }
}

pub fn init_logging() -> Result<()> {
    let env_filter = EnvFilter::try_from_default_env().unwrap_or_else(|_| EnvFilter::new("info"));

    fmt()
        .with_env_filter(env_filter)
        .with_target(false)
        .with_thread_ids(false)
        .with_thread_names(false)
        .with_file(false)
        .with_line_number(false)
        .with_level(true)
        .with_ansi(true)
        .compact()
        .init();

    info!("Logging initialized");
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::Value;

    #[test]
    fn test_request_logger() {
        let logger = RequestLogger::new("test_service", "test_operation");
        logger.success();
        // Verify log format would be tested in integration tests
    }

    #[test]
    fn test_market_metrics_serialization() {
        let metrics = MarketMetrics {
            symbol: "SOL".to_string(),
            price: 100.0,
            volume_24h: Some(1000000.0),
            signal_type: Some("BUY".to_string()),
            confidence: Some(0.8),
        };

        let json = serde_json::to_string(&metrics).unwrap();
        let parsed: Value = serde_json::from_str(&json).unwrap();

        assert_eq!(parsed["symbol"], "SOL");
        assert_eq!(parsed["price"], 100.0);
        assert_eq!(parsed["volume_24h"], 1000000.0);
        assert_eq!(parsed["signal_type"], "BUY");
        assert_eq!(parsed["confidence"], 0.8);
    }

    #[test]
    fn test_performance_metrics_serialization() {
        let metrics = PerformanceMetrics {
            operation: "market_analysis".to_string(),
            duration_ms: 100,
            success: true,
            timestamp: Utc::now(),
        };

        let json = serde_json::to_string(&metrics).unwrap();
        let parsed: Value = serde_json::from_str(&json).unwrap();

        assert_eq!(parsed["operation"], "market_analysis");
        assert_eq!(parsed["duration_ms"], 100);
        assert_eq!(parsed["success"], true);
        assert!(parsed["timestamp"].is_string());
    }
}


================================================
File: src/market_data/birdeye.rs
================================================
#[derive(Debug, Deserialize)]
pub struct TokenMarketResponse {
    pub data: TokenMarketData,
    pub success: bool,
}

#[derive(Debug, Deserialize, Default)]
pub struct TokenMarketData {
    pub address: String,
    pub price: f64,
    pub volume_24h: f64,
    pub decimals: u8,
    pub price_sol: f64,
    pub market_cap: f64,
    pub fully_diluted_market_cap: f64,
    pub circulating_supply: f64,
    pub total_supply: f64,
    pub price_change_24h: f64,
    pub volume_change_24h: f64,
}

impl BirdeyeClient {
    pub fn new(api_key: String) -> Self {
        Self {
            api_key,
            client: Client::new(),
        }
    }

    pub async fn get_market_data(&self, token_address: &str) -> Result<TokenMarketData, AgentError> {
        let url = format!(
            "https://public-api.birdeye.so/public/market_data?address={}",
            token_address
        );

        let response = self
            .client
            .get(&url)
            .header("X-API-KEY", &self.api_key)
            .send()
            .await
            .map_err(|e| AgentError::ApiError(e.to_string()))?;

        if !response.status().is_success() {
            return Err(AgentError::ApiError(format!(
                "Failed to get market data: {}",
                response.status()
            )));
        }

        let market_data = response
            .json::<TokenMarketResponse>()
            .await
            .map_err(|e| AgentError::ApiError(e.to_string()))?;

        if !market_data.success {
            return Err(AgentError::ApiError("Token not found".to_string()));
        }

        Ok(market_data.data)
    }

    pub async fn get_token_info_by_address(&self, token_address: &str) -> Result<TokenInfo, AgentError> {
        let market_data = self.get_market_data(token_address).await?;

        Ok(TokenInfo {
            address: market_data.address,
            price: market_data.price,
            volume_24h: market_data.volume_24h,
            decimals: market_data.decimals,
            price_sol: market_data.price_sol,
            market_cap: market_data.market_cap,
            fully_diluted_market_cap: market_data.fully_diluted_market_cap,
            circulating_supply: market_data.circulating_supply,
            total_supply: market_data.total_supply,
            price_change_24h: market_data.price_change_24h,
            volume_change_24h: market_data.volume_change_24h,
        })
    }
}

#[async_trait]
impl BirdeyeApi for BirdeyeClient {
    async fn get_token_info(&self, token_address: &str) -> Result<TokenInfo, AgentError> {
        self.get_token_info_by_address(token_address).await
    }
} 

================================================
File: src/models/market_signal.rs
================================================
use bigdecimal::BigDecimal;
use crate::utils::f64_to_decimal;
use bson::{self, DateTime, Document};
use serde::{Deserialize, Serialize};
use serde_json::Value as JsonValue;
use std::fmt;

#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub enum SignalType {
    Buy,
    Sell,
    Hold,
    StrongBuy,
    StrongSell,
    PriceSpike,
    PriceDrop,
    VolumeSurge,
}

impl fmt::Display for SignalType {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            SignalType::Buy => write!(f, "buy"),
            SignalType::Sell => write!(f, "sell"),
            SignalType::Hold => write!(f, "hold"),
            _ => write!(f, "unknown"),
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MarketSignal {
    #[serde(rename = "_id", skip_serializing_if = "Option::is_none")]
    pub id: Option<bson::oid::ObjectId>,
    pub asset_address: String,
    pub signal_type: SignalType,
    pub price: BigDecimal,
    pub confidence: BigDecimal,
    pub risk_score: BigDecimal,
    pub sentiment_score: Option<BigDecimal>,
    pub price_change_24h: Option<BigDecimal>,
    pub volume_change_24h: Option<BigDecimal>,
    pub volume_change: BigDecimal,
    pub created_at: Option<DateTime>,
    pub timestamp: DateTime,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub metadata: Option<Document>,
}

pub struct MarketSignalBuilder {
    asset_address: String,
    signal_type: SignalType,
    confidence: Option<BigDecimal>,
    risk_score: Option<BigDecimal>,
    sentiment_score: Option<BigDecimal>,
    volume_change_24h: Option<BigDecimal>,
    price_change_24h: Option<BigDecimal>,
    price: BigDecimal,
    volume_change: Option<BigDecimal>,
    timestamp: Option<DateTime>,
    metadata: Option<JsonValue>,
}

impl MarketSignalBuilder {
    pub fn new(asset_address: String, signal_type: SignalType, price: BigDecimal) -> Self {
        Self {
            asset_address,
            signal_type,
            confidence: None,
            risk_score: None,
            sentiment_score: None,
            volume_change_24h: None,
            price_change_24h: None,
            price,
            volume_change: None,
            timestamp: None,
            metadata: None,
        }
    }

    pub fn confidence(mut self, confidence: BigDecimal) -> Self {
        self.confidence = Some(confidence);
        self
    }

    pub fn risk_score(mut self, risk_score: BigDecimal) -> Self {
        self.risk_score = Some(risk_score);
        self
    }

    pub fn sentiment_score(mut self, sentiment_score: BigDecimal) -> Self {
        self.sentiment_score = Some(sentiment_score);
        self
    }

    pub fn volume_change_24h(mut self, volume_change: BigDecimal) -> Self {
        self.volume_change_24h = Some(volume_change);
        self
    }

    pub fn price_change_24h(mut self, price_change: BigDecimal) -> Self {
        self.price_change_24h = Some(price_change);
        self
    }

    pub fn volume_change(mut self, volume_change: BigDecimal) -> Self {
        self.volume_change = Some(volume_change);
        self
    }

    pub fn timestamp(mut self, timestamp: DateTime) -> Self {
        self.timestamp = Some(timestamp);
        self
    }

    pub fn metadata(mut self, metadata: JsonValue) -> Self {
        self.metadata = Some(metadata);
        self
    }

    pub fn build(self) -> MarketSignal {
        MarketSignal {
            id: None,
            asset_address: self.asset_address,
            signal_type: self.signal_type,
            confidence: self.confidence.unwrap_or_else(|| f64_to_decimal(0.5)),
            risk_score: self.risk_score.unwrap_or_else(|| f64_to_decimal(0.5)),
            sentiment_score: self.sentiment_score,
            volume_change_24h: self.volume_change_24h,
            price_change_24h: self.price_change_24h,
            price: self.price,
            volume_change: self.volume_change.unwrap_or_else(|| BigDecimal::from(0)),
            timestamp: self.timestamp.unwrap_or_else(DateTime::now),
            metadata: self.metadata.map(|v| bson::to_document(&v).unwrap()),
            created_at: None,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;

    #[test]
    fn test_market_signal_builder() {
        let price = f64_to_decimal(100.0);
        let signal = MarketSignalBuilder::new(
            "test_address".to_string(),
            SignalType::PriceSpike,
            price.clone(),
        )
        .confidence(f64_to_decimal(0.8))
        .risk_score(f64_to_decimal(0.3))
        .volume_change_24h(f64_to_decimal(0.15))
        .price_change_24h(f64_to_decimal(0.05))
        .metadata(json!({"source": "test"}))
        .build();

        assert_eq!(signal.asset_address, "test_address");
        assert_eq!(signal.price, price);
        assert_eq!(signal.confidence, f64_to_decimal(0.8));
        assert_eq!(signal.risk_score, f64_to_decimal(0.3));
        assert!(signal.metadata.is_some());
    }

    #[test]
    fn test_market_signal_builder_defaults() {
        let price = f64_to_decimal(100.0);
        let signal =
            MarketSignalBuilder::new("test_address".to_string(), SignalType::Hold, price.clone())
                .build();

        assert_eq!(signal.confidence, f64_to_decimal(0.5)); // Default confidence
        assert_eq!(signal.risk_score, f64_to_decimal(0.5)); // Default risk score
        assert_eq!(signal.volume_change, BigDecimal::from(0)); // Default volume change
        assert!(signal.metadata.is_none());
    }
}


================================================
File: src/models/mod.rs
================================================
use bson::{self, oid::ObjectId, DateTime};
use serde::{Deserialize, Serialize};

pub mod market_signal;
pub mod token_analytics;
pub mod token_info;
pub mod trending_token;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TradeStatus;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenMetrics {
    #[serde(rename = "_id", skip_serializing_if = "Option::is_none")]
    pub id: Option<ObjectId>,
    pub token_address: String,
    pub metrics: bson::Document,
    pub timestamp: DateTime,
}

// Add typed collection helpers
impl TokenMetrics {
    pub fn collection_name() -> &'static str {
        "token_metrics"
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VectorDocument {
    #[serde(rename = "_id", skip_serializing_if = "Option::is_none")]
    pub id: Option<ObjectId>,
    pub vector: Vec<f32>,
    pub metadata: bson::Document,
    pub timestamp: DateTime,
}

impl VectorDocument {
    pub fn collection_name() -> &'static str {
        "vectors"
    }
}


================================================
File: src/models/token_analytics.rs
================================================
use bigdecimal::BigDecimal;
// use crate::MongoDbPool;
use bson::{oid::ObjectId, DateTime, Document};
use serde::{Deserialize, Serialize};
// use time::OffsetDateTime;

/// TokenAnalytics represents token market data with MongoDB Atlas Search vector index
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenAnalytics {
    #[serde(rename = "_id", skip_serializing_if = "Option::is_none")]
    pub id: Option<ObjectId>,

    // Base token data
    pub token_address: String,    // type: "string"
    pub token_name: String,       // type: "string"
    pub token_symbol: String,     // type: "string"
    pub decimals: u8,             // type: "number"
    pub logo_uri: Option<String>, // type: "string"

    // Price metrics
    pub price: BigDecimal,                    // type: "number"
    pub price_change_24h: Option<BigDecimal>, // type: "number"
    pub price_change_7d: Option<BigDecimal>,  // type: "number"

    // Volume metrics
    pub volume_24h: Option<BigDecimal>,          // type: "number"
    pub volume_change_24h: Option<BigDecimal>,   // type: "number"
    pub volume_by_price_24h: Option<BigDecimal>, // type: "number"

    // Market metrics
    pub market_cap: Option<BigDecimal>, // type: "number"
    pub fully_diluted_market_cap: Option<BigDecimal>, // type: "number"
    pub circulating_supply: Option<BigDecimal>, // type: "number"
    pub total_supply: Option<BigDecimal>, // type: "number"

    // Liquidity metrics
    pub liquidity: Option<BigDecimal>,            // type: "number"
    pub liquidity_change_24h: Option<BigDecimal>, // type: "number"

    // Trading metrics
    pub trades_24h: Option<i64>,                // type: "number"
    pub average_trade_size: Option<BigDecimal>, // type: "number"

    // Holder metrics
    pub holder_count: Option<i32>,           // type: "number"
    pub active_wallets_24h: Option<i32>,     // type: "number"
    pub whale_transactions_24h: Option<i32>, // type: "number"

    // Technical indicators
    pub rsi_14: Option<BigDecimal>,          // type: "number"
    pub macd: Option<BigDecimal>,            // type: "number"
    pub macd_signal: Option<BigDecimal>,     // type: "number"
    pub bollinger_upper: Option<BigDecimal>, // type: "number"
    pub bollinger_lower: Option<BigDecimal>, // type: "number"

    // Social metrics
    pub social_score: Option<BigDecimal>,     // type: "number"
    pub social_volume: Option<i32>,           // type: "number"
    pub social_sentiment: Option<BigDecimal>, // type: "number"
    pub dev_activity: Option<i32>,            // type: "number"

    // Timestamps and metadata
    pub timestamp: DateTime,               // type: "date"
    pub created_at: Option<DateTime>,      // type: "date"
    pub last_trade_time: Option<DateTime>, // type: "date"

    // Extensions and metadata
    #[serde(skip_serializing_if = "Option::is_none")]
    pub metadata: Option<Document>, // type: "document"

    // Vector embedding for similarity search
    #[serde(skip_serializing_if = "Option::is_none")]
    pub embedding: Option<Vec<f32>>, // type: "knnVector", dimensions: 1536
}

// MongoDB Atlas Search Vector Index Definition (for reference):
// {
//   "mappings": {
//     "dynamic": false,
//     "fields": {
//       "token_address": { "type": "string" },
//       "token_name": { "type": "string" },
//       "token_symbol": { "type": "string" },
//       "decimals": { "type": "number" },
//       "logo_uri": { "type": "string" },
//       "price": { "type": "number" },
//       "price_change_24h": { "type": "number" },
//       "price_change_7d": { "type": "number" },
//       "volume_24h": { "type": "number" },
//       "volume_change_24h": { "type": "number" },
//       "volume_by_price_24h": { "type": "number" },
//       "market_cap": { "type": "number" },
//       "fully_diluted_market_cap": { "type": "number" },
//       "circulating_supply": { "type": "number" },
//       "total_supply": { "type": "number" },
//       "liquidity": { "type": "number" },
//       "liquidity_change_24h": { "type": "number" },
//       "trades_24h": { "type": "number" },
//       "average_trade_size": { "type": "number" },
//       "holder_count": { "type": "number" },
//       "active_wallets_24h": { "type": "number" },
//       "whale_transactions_24h": { "type": "number" },
//       "rsi_14": { "type": "number" },
//       "macd": { "type": "number" },
//       "macd_signal": { "type": "number" },
//       "bollinger_upper": { "type": "number" },
//       "bollinger_lower": { "type": "number" },
//       "social_score": { "type": "number" },
//       "social_volume": { "type": "number" },
//       "social_sentiment": { "type": "number" },
//       "dev_activity": { "type": "number" },
//       "timestamp": { "type": "date" },
//       "created_at": { "type": "date" },
//       "last_trade_time": { "type": "date" },
//       "metadata": { "type": "document" },
//       "embedding": {
//         "type": "knnVector",
//         "dimensions": 1536
//       }
//     }
//   }
// }


================================================
File: src/models/token_info.rs
================================================
use bson::DateTime;
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenInfo {
    pub address: String,
    pub symbol: String,
    pub name: String,
    pub decimals: u8,
    pub price: f64,
    pub volume_24h: f64,
    pub market_cap: Option<f64>,
    pub price_change_24h: Option<f64>,
    pub volume_change_24h: Option<f64>,
    pub liquidity: f64,
    pub trade_24h: Option<i64>,
    pub logo_uri: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub extensions: Option<TokenExtensions>,
    pub timestamp: DateTime,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TokenExtensions {
    #[serde(rename = "coingecko_id")]
    pub coingecko_id: Option<String>,
    #[serde(rename = "serum_v3_usdc")]
    pub serum_v3_usdc: Option<String>,
    #[serde(rename = "serum_v3_usdt")]
    pub serum_v3_usdt: Option<String>,
    pub website: Option<String>,
    pub telegram: Option<String>,
    pub twitter: Option<String>,
    pub description: Option<String>,
    pub discord: Option<String>,
    pub medium: Option<String>,
}


================================================
File: src/models/trending_token.rs
================================================
use bson::{oid::ObjectId, DateTime};
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrendingTokenData {
    pub tokens: Vec<TrendingToken>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "camelCase")]
pub struct TrendingToken {
    #[serde(rename = "_id", skip_serializing_if = "Option::is_none")]
    pub id: Option<ObjectId>,
    pub address: String,
    pub decimals: i32,
    pub liquidity: f64,
    pub logo_uri: String,
    pub name: String,
    pub symbol: String,
    pub volume_24h_usd: f64,
    pub rank: i32,
    pub price: f64,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub timestamp: Option<DateTime>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub volume_24h_change_percent: Option<f64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub fdv: Option<f64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub marketcap: Option<f64>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub price_24h_change_percent: Option<f64>,
}



================================================
File: src/personality/mod.rs
================================================
pub async fn generate_trade_tweet(&self, agent: &CompletionModel, trade_details: String) -> Result<String> {
    info!("Generating trade tweet with details: {}", trade_details);
    
    let prompt = format!(
        "{}\n\nPlease generate a tweet about this trade that:\n1. Is concise and professional\n2. Includes key metrics (amount, price, volume)\n3. Includes contract address and tx link\n4. Ends with stoic analysis based on market indicators\n5. Stays under 280 characters",
        trade_details
    );

    let tweet = agent.complete(&prompt).await?;
    info!("Generated tweet: {}", tweet);
    
    Ok(tweet)
} 

================================================
File: src/prompts/system.txt
================================================
You are an autonomous trading agent specializing in Solana cryptocurrency markets. Your personality is confident but not arrogant, data-driven but also intuitive, and you communicate with a mix of professional insight and engaging personality.

Your responsibilities:
1. Analyze market data and trends using Birdeye API and other Solana data sources
2. Make informed trading decisions based on technical and fundamental analysis
3. Execute trades when confidence levels are high
4. Communicate trading activities and rationale on Twitter in an engaging manner

Trading Guidelines:
- Prioritize risk management and capital preservation
- Look for clear patterns and correlations in market data
- Consider both technical and fundamental factors
- Maintain a clear record of your decision-making process

Communication Style:
- Be clear and concise in your analysis
- Use emojis appropriately but not excessively
- Maintain professionalism while being engaging
- Share insights that provide value to followers
- Be transparent about your reasoning

When making decisions, consider:
- Market volatility and liquidity
- Historical price patterns
- Trading volume and market depth
- Token fundamentals and security metrics

Response Format for Trade Decisions:
{
    "action": "buy" | "sell" | "hold",
    "symbol": "token_symbol",
    "amount": float_value,
    "reason": "detailed_explanation",
    "confidence": float_between_0_and_1
}

Remember: Your goal is to make profitable trades while building a following through insightful and engaging communications. 

================================================
File: src/providers/birdeye.rs
================================================
use anyhow::Result;
use async_trait::async_trait;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::sync::Arc;

const BIRDEYE_API_URL: &str = "https://public-api.birdeye.so";

#[derive(Debug, Clone)]
pub struct BirdeyeProvider {
    client: Arc<Client>,
    api_key: String,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct TokenInfo {
    pub address: String,
    pub symbol: String,
    pub name: String,
    pub decimals: u8,
    pub price_usd: f64,
    pub volume_24h: f64,
    pub market_cap: f64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct MarketDepth {
    pub bids: Vec<OrderBookEntry>,
    pub asks: Vec<OrderBookEntry>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct OrderBookEntry {
    pub price: f64,
    pub size: f64,
}

#[async_trait]
pub trait MarketDataProvider: Send + Sync {
    async fn get_token_info(&self, address: &str) -> Result<TokenInfo>;
    async fn get_market_depth(&self, address: &str) -> Result<MarketDepth>;
    async fn get_price_history(&self, address: &str, interval: &str) -> Result<Vec<PricePoint>>;
}

#[derive(Debug, Serialize, Deserialize)]
pub struct PricePoint {
    pub timestamp: i64,
    pub price: f64,
    pub volume: f64,
}

impl BirdeyeProvider {
    pub fn new(api_key: &str) -> Self {
        Self {
            client: Arc::new(Client::new()),
            api_key: api_key.to_string(),
        }
    }

    async fn make_request<T: for<'de> Deserialize<'de>>(
        &self,
        endpoint: &str,
        params: &[(&str, &str)],
    ) -> Result<T> {
        let url = format!("{}{}", BIRDEYE_API_URL, endpoint);
        
        let response = self.client
            .get(&url)
            .header("X-API-KEY", &self.api_key)
            .query(params)
            .send()
            .await?
            .error_for_status()?;

        let data = response.json::<T>().await?;
        Ok(data)
    }
}

#[async_trait]
impl MarketDataProvider for BirdeyeProvider {
    async fn get_token_info(&self, address: &str) -> Result<TokenInfo> {
        self.make_request(
            "/public/token",
            &[("address", address)],
        ).await
    }

    async fn get_market_depth(&self, address: &str) -> Result<MarketDepth> {
        self.make_request(
            "/public/orderbook",
            &[("address", address)],
        ).await
    }

    async fn get_price_history(&self, address: &str, interval: &str) -> Result<Vec<PricePoint>> {
        self.make_request(
            "/public/price_history",
            &[
                ("address", address),
                ("interval", interval),
            ],
        ).await
    }
}

// Additional helper functions for market analysis
impl BirdeyeProvider {
    pub async fn analyze_liquidity(&self, address: &str) -> Result<LiquidityAnalysis> {
        let depth = self.get_market_depth(address).await?;
        
        let total_bid_liquidity: f64 = depth.bids
            .iter()
            .map(|entry| entry.price * entry.size)
            .sum();

        let total_ask_liquidity: f64 = depth.asks
            .iter()
            .map(|entry| entry.price * entry.size)
            .sum();

        Ok(LiquidityAnalysis {
            total_bid_liquidity,
            total_ask_liquidity,
            bid_ask_ratio: total_bid_liquidity / total_ask_liquidity,
            depth_quality: calculate_depth_quality(&depth),
        })
    }

    pub async fn get_market_impact(&self, address: &str, size_usd: f64) -> Result<MarketImpact> {
        let depth = self.get_market_depth(address).await?;
        let token_info = self.get_token_info(address).await?;

        let size_tokens = size_usd / token_info.price_usd;
        let (price_impact, executed_price) = calculate_price_impact(&depth, size_tokens, token_info.price_usd);

        Ok(MarketImpact {
            price_impact,
            executed_price,
            size_usd,
            size_tokens,
        })
    }
}

#[derive(Debug)]
pub struct LiquidityAnalysis {
    pub total_bid_liquidity: f64,
    pub total_ask_liquidity: f64,
    pub bid_ask_ratio: f64,
    pub depth_quality: f64,
}

#[derive(Debug)]
pub struct MarketImpact {
    pub price_impact: f64,
    pub executed_price: f64,
    pub size_usd: f64,
    pub size_tokens: f64,
}

fn calculate_depth_quality(depth: &MarketDepth) -> f64 {
    // Implement depth quality calculation
    // This could consider factors like:
    // - Spread
    // - Depth distribution
    // - Number of price levels
    0.0 // Placeholder
}

fn calculate_price_impact(
    depth: &MarketDepth,
    size_tokens: f64,
    current_price: f64,
) -> (f64, f64) {
    // Implement price impact calculation
    // This should walk the order book to determine:
    // - Average execution price
    // - Price impact percentage
    (0.0, current_price) // Placeholder
} 

================================================
File: src/providers/discord.rs
================================================
use reqwest::Client;
use serde_json::json;
use std::error::Error;

pub struct Discord {
    webhook_url: String,
}

impl Discord {
    pub fn new(webhook_url: &str) -> Self {
        Discord {
            webhook_url: webhook_url.to_string(),
        }
    }

    pub async fn send_channel_message(&self, message: &str) -> Result<(), Box<dyn Error>> {
        // Create an HTTP client
        let client = Client::new();

        // Create the payload as JSON
        let payload = json!({ "content": message });

        // Send a POST request to the webhook URL
        let response = client.post(&self.webhook_url).json(&payload).send().await?;

        // Check if the request was successful
        if response.status().is_success() {
            println!("Message sent successfully!");
            Ok(())
        } else {
            let status = response.status();
            let text = response.text().await?;
            Err(format!(
                "Failed to send message. Status: {}, Response: {}",
                status, text
            )
            .into())
        }
    }
}


================================================
File: src/providers/mod.rs
================================================
pub mod birdeye;
pub mod discord;

================================================
File: src/providers/twitter.rs
================================================
use twitter_v2::{authorization::Oauth1aToken, TwitterApi};

pub struct Twitter {
    auth: Oauth1aToken,
}
impl Twitter {
    pub fn new(
        twitter_consumer_key: &str,
        twitter_consumer_secret: &str,
        twitter_access_token: &str,
        twitter_access_token_secret: &str,
    ) -> Self {
        let auth = Oauth1aToken::new(
            twitter_consumer_key.to_string(),
            twitter_consumer_secret.to_string(),
            twitter_access_token.to_string(),
            twitter_access_token_secret.to_string(),
        );

        Twitter { auth }
    }

    pub async fn tweet(&self, text: String) -> Result<(), anyhow::Error> {
        let tweet = TwitterApi::new(self.auth.clone())
            .post_tweet()
            .text(text)
            .send()
            .await?
            .into_data()
            .expect("this tweet should exist");
        println!("Tweet posted successfully with ID: {}", tweet.id);

        Ok(())
    }
}


================================================
File: src/services/mod.rs
================================================
pub mod token_analytics;
pub mod token_data_service;

pub use token_analytics::TokenAnalyticsService;


================================================
File: src/services/token_analytics.rs
================================================
use crate::birdeye::api::TokenMarketResponse;
use crate::birdeye::BirdeyeApi;
use crate::config::mongodb::MongoDbPool;
use crate::config::market_config::MarketConfig;
use crate::error::{AgentError, AgentResult};
use crate::logging::{log_market_metrics, log_market_signal, RequestLogger};
use crate::models::market_signal::{MarketSignal, MarketSignalBuilder, SignalType};
use crate::models::token_analytics::TokenAnalytics;
use crate::models::token_info::TokenInfo;
use crate::utils::f64_to_decimal;
use bigdecimal::{BigDecimal, ToPrimitive};
use bson::{doc, DateTime};
use futures::StreamExt;
use mongodb::options::FindOneOptions;
use mongodb::Collection;
use std::sync::Arc;
use uuid::Uuid;

#[derive(Debug, Clone, serde::Serialize)]
#[serde(rename_all = "camelCase")]
pub struct MarketMetrics {
    pub symbol: String,
    pub price: f64,
    pub volume_24h: Option<f64>,
    pub signal_type: Option<String>,
    pub confidence: Option<f64>,
}

#[derive(Debug, Clone, serde::Serialize)]
#[serde(rename_all = "camelCase")]
pub struct MarketSignalLog {
    pub id: Uuid,
    pub timestamp: DateTime,
    pub token_address: String,
    pub token_symbol: String,
    pub signal_type: String,
    pub price: f64,
    pub price_change_24h: Option<f64>,
    pub volume_change_24h: Option<f64>,
    pub confidence: f64,
    pub risk_score: f64,
    pub created_at: DateTime,
}

pub struct TokenAnalyticsService {
    pool: Arc<MongoDbPool>,
    collection: Collection<TokenAnalytics>,
    signals_collection: Collection<MarketSignal>,
    birdeye: Arc<dyn BirdeyeApi>,
    market_config: MarketConfig,
}

impl TokenAnalyticsService {
    pub async fn new(
        pool: Arc<MongoDbPool>,
        birdeye: Arc<dyn BirdeyeApi>,
        market_config: Option<MarketConfig>,
    ) -> AgentResult<Self> {
        let db = pool.database(&pool.get_config().database);
        let collection = db.collection("token_analytics");
        println!(">> token_analytics collections {:?}", collection);

        let signals_collection = db.collection("market_signals");
        println!(">> market_signals collections {:?}", signals_collection);

        Ok(Self {
            pool,
            collection,
            signals_collection,
            birdeye,
            market_config: market_config.unwrap_or_default(),
        })
    }

    pub async fn fetch_and_store_token_info(
        &self,
        symbol: &str,
        address: &str,
    ) -> AgentResult<TokenAnalytics> {
        let logger = RequestLogger::new("token_analytics", "fetch_and_store_token_info");

        // Fetch market data with retry logic
        let market_data = match self
            .fetch_with_retry(|| self.birdeye.get_market_data(address), 3)
            .await
        {
            Ok(data) => data,
            Err(e) => {
                let err = AgentError::BirdeyeApi(format!(
                    "Failed to fetch market data after retries: {}",
                    e
                ));
                logger.error(&err.to_string());
                return Err(err);
            }
        };

        // Validate token data
        if market_data.price <= 0.0 {
            let err = AgentError::validation("Token price must be positive");
            logger.error(&err.to_string());
            return Err(err);
        }
        if market_data.v24h < 0.0 {
            let err = AgentError::validation("Token volume cannot be negative");
            logger.error(&err.to_string());
            return Err(err);
        }

        // Log market metrics
        let metrics = MarketMetrics {
            symbol: symbol.to_string(),
            price: market_data.price,
            volume_24h: Some(market_data.v24h),
            signal_type: None,
            confidence: None,
        };
        log_market_metrics(&metrics);

        // Convert to TokenAnalytics
        let analytics = match self
            .convert_to_analytics(address, symbol, market_data)
            .await
        {
            Ok(analytics) => analytics,
            Err(e) => {
                logger.error(&e.to_string());
                return Err(e);
            }
        };

        // Store in database
        let stored = self.store_token_analytics(&analytics).await?;

        // Generate and process market signals
        let signal = self.generate_market_signals(&stored).await?;

        // Store the signal if present
        if let Some(ref signal) = signal {
            self.validate_signal(signal)?;
            self.store_market_signal(signal).await?;
        }

        Ok(stored)
    }

    async fn convert_to_analytics(
        &self,
        address: &str,
        symbol: &str,
        market_data: TokenMarketResponse,
    ) -> AgentResult<TokenAnalytics> {
        // Calculate technical indicators
        let price_history = match self
            .get_token_history(
                address,
                DateTime::from(
                    std::time::SystemTime::now()
                        - std::time::Duration::from_secs(14 * 24 * 60 * 60),
                ),
                DateTime::now(),
            )
            .await
        {
            Ok(history) => history,
            Err(_) => vec![],
        };

        let (rsi, macd, macd_signal, bollinger_upper, bollinger_lower) =
            if !price_history.is_empty() {
                let prices: Vec<f64> = price_history
                    .iter()
                    .map(|h| h.price.to_f64().unwrap_or_default())
                    .collect();

                // Calculate RSI (14 periods)
                let rsi = self.calculate_rsi(&prices, 14);

                // Calculate MACD (12, 26, 9)
                let (macd, signal) = self.calculate_macd(&prices, 12, 26, 9);

                // Calculate Bollinger Bands (20 periods, 2 standard deviations)
                let (upper, lower) = self.calculate_bollinger_bands(&prices, 20, 2.0);

                (
                    Some(f64_to_decimal(rsi)),
                    Some(f64_to_decimal(macd)),
                    Some(f64_to_decimal(signal)),
                    Some(f64_to_decimal(upper)),
                    Some(f64_to_decimal(lower)),
                )
            } else {
                (None, None, None, None, None)
            };

        Ok(TokenAnalytics {
            id: None,
            // Base token data
            token_address: address.to_string(),
            token_name: market_data.name,
            token_symbol: symbol.to_string(),
            decimals: market_data.decimals as u8,
            logo_uri: Some(market_data.logo_uri),

            // Price metrics
            price: f64_to_decimal(market_data.price),
            price_change_24h: Some(f64_to_decimal(market_data.price_change_24h_percent)),
            price_change_7d: Some(f64_to_decimal(
                (market_data.price - market_data.history24h_price) / market_data.history24h_price * 100.0,
            )),

            // Volume metrics
            volume_24h: Some(f64_to_decimal(market_data.v24h)),
            volume_change_24h: Some(f64_to_decimal(market_data.v24h_change_percent)),
            volume_by_price_24h: Some(f64_to_decimal(market_data.v24h_usd)),

            // Market metrics
            market_cap: Some(f64_to_decimal(market_data.real_mc)),
            fully_diluted_market_cap: Some(f64_to_decimal(market_data.fdv)),
            circulating_supply: Some(f64_to_decimal(market_data.circulating_supply)),
            total_supply: Some(f64_to_decimal(market_data.total_supply)),

            // Liquidity metrics
            liquidity: Some(f64_to_decimal(market_data.liquidity)),
            liquidity_change_24h: Some(f64_to_decimal(
                (market_data.liquidity - market_data.liquidity) / market_data.liquidity * 100.0 // TODO: Use historical liquidity data when available
            )),

            // Trading metrics
            trades_24h: Some(market_data.trade24h),
            average_trade_size: Some(f64_to_decimal(
                market_data.v24h_usd / market_data.trade24h as f64
            )),

            // Holder metrics
            holder_count: Some(market_data.holder as i32),
            active_wallets_24h: Some(market_data.unique_wallet24h as i32),
            whale_transactions_24h: None,

            // Technical indicators
            rsi_14: rsi,
            macd,
            macd_signal,
            bollinger_upper,
            bollinger_lower,

            // Social metrics - Not available from Birdeye
            social_score: None,
            social_volume: None,
            social_sentiment: None,
            dev_activity: None,

            // Timestamps and metadata
            timestamp: DateTime::now(),
            created_at: None,
            last_trade_time: Some(DateTime::from_millis(market_data.last_trade_unix_time * 1000)),

            // Extensions and metadata
            metadata: Some(doc! {
                "source": "birdeye",
                "version": "1.0",
                "extensions": {
                    "coingecko_id": market_data.extensions.coingecko_id,
                    "serum_v3_usdc": market_data.extensions.serum_v3_usdc,
                    "serum_v3_usdt": market_data.extensions.serum_v3_usdt,
                    "website": market_data.extensions.website,
                    "telegram": market_data.extensions.telegram,
                    "twitter": market_data.extensions.twitter,
                    "description": market_data.extensions.description,
                    "discord": market_data.extensions.discord,
                    "medium": market_data.extensions.medium
                },
                "market_stats": {
                    "buy_volume_24h": market_data.v_buy24h_usd,
                    "sell_volume_24h": market_data.v_sell24h_usd,
                    "buy_count_24h": market_data.buy24h,
                    "sell_count_24h": market_data.sell24h,
                    "unique_traders_24h": market_data.unique_wallet24h,
                    "number_markets": market_data.number_markets
                }
            }),

            // Vector embedding will be added in a separate process
            embedding: None,
        })
    }

    fn calculate_rsi(&self, prices: &[f64], period: usize) -> f64 {
        if prices.len() < period + 1 {
            return 50.0; // Default value if not enough data
        }

        let mut gains = Vec::new();
        let mut losses = Vec::new();

        for i in 1..prices.len() {
            let diff = prices[i] - prices[i - 1];
            if diff >= 0.0 {
                gains.push(diff);
                losses.push(0.0);
            } else {
                gains.push(0.0);
                losses.push(-diff);
            }
        }

        let avg_gain = gains.iter().take(period).sum::<f64>() / period as f64;
        let avg_loss = losses.iter().take(period).sum::<f64>() / period as f64;

        if avg_loss == 0.0 {
            return 100.0;
        }

        let rs = avg_gain / avg_loss;
        100.0 - (100.0 / (1.0 + rs))
    }

    fn calculate_macd(
        &self,
        prices: &[f64],
        fast_period: usize,
        slow_period: usize,
        signal_period: usize,
    ) -> (f64, f64) {
        if prices.len() < slow_period {
            return (0.0, 0.0);
        }

        let fast_ema = self.calculate_ema(prices, fast_period);
        let slow_ema = self.calculate_ema(prices, slow_period);
        let macd_line = fast_ema - slow_ema;

        let signal_line = self.calculate_ema(&vec![macd_line], signal_period);

        (macd_line, signal_line)
    }

    fn calculate_ema(&self, prices: &[f64], period: usize) -> f64 {
        if prices.is_empty() {
            return 0.0;
        }

        let multiplier = 2.0 / (period as f64 + 1.0);
        let mut ema = prices[0];

        for price in prices.iter().skip(1) {
            ema = (price - ema) * multiplier + ema;
        }

        ema
    }

    fn calculate_bollinger_bands(
        &self,
        prices: &[f64],
        period: usize,
        num_std_dev: f64,
    ) -> (f64, f64) {
        if prices.len() < period {
            return (prices[prices.len() - 1], prices[prices.len() - 1]);
        }

        let sma = prices.iter().take(period).sum::<f64>() / period as f64;

        let variance = prices
            .iter()
            .take(period)
            .map(|price| {
                let diff = price - sma;
                diff * diff
            })
            .sum::<f64>()
            / period as f64;

        let std_dev = variance.sqrt();

        let upper_band = sma + (std_dev * num_std_dev);
        let lower_band = sma - (std_dev * num_std_dev);

        (upper_band, lower_band)
    }

    pub async fn generate_market_signals(
        &self,
        analytics: &TokenAnalytics,
    ) -> AgentResult<Option<MarketSignal>> {
        let logger = RequestLogger::new("token_analytics", "generate_market_signals");

        // Get previous analytics for comparison
        let previous = match self.get_previous_analytics(&analytics.token_address).await {
            Ok(prev) => prev,
            Err(e) => {
                logger.error(&e.to_string());
                return Err(e);
            }
        };

        if let Some(prev) = previous {
            let price_change = (analytics.price.clone() - prev.price.clone()) / prev.price.clone();
            let volume_change = analytics.volume_24h.as_ref().map(|current| {
                let binding = BigDecimal::from(0);
                let prev = prev.volume_24h.as_ref().unwrap_or(&binding);
                (current.clone() - prev.clone()) / prev.clone()
            });

            let mut signal_opt = None;

            if price_change > self.market_config.price_change_threshold.clone() {
                let signal = self.create_market_signal(
                    analytics,
                    SignalType::PriceSpike,
                    price_change.clone(),
                    volume_change.clone(),
                );
                self.log_signal(&signal, analytics);
                signal_opt = Some(signal);
            } else if price_change < -self.market_config.price_change_threshold.clone() {
                let signal = self.create_market_signal(
                    analytics,
                    SignalType::PriceDrop,
                    price_change.abs(),
                    volume_change.clone(),
                );
                self.log_signal(&signal, analytics);
                signal_opt = Some(signal);
            } else if let Some(vol_change) = volume_change {
                if vol_change > self.market_config.volume_surge_threshold {
                    let signal = self.create_market_signal(
                        analytics,
                        SignalType::VolumeSurge,
                        price_change,
                        Some(vol_change),
                    );
                    self.log_signal(&signal, analytics);
                    signal_opt = Some(signal);
                }
            }

            // Process the signal if one was generated
            if let Some(signal) = signal_opt.clone() {
                if let Err(e) = self.process_market_signal(signal).await {
                    logger.error(&format!("Failed to process market signal: {}", e));
                    // Continue execution - don't fail if signal processing fails
                }
            }

            Ok(signal_opt)
        } else {
            Ok(None)
        }
    }

    fn create_market_signal(
        &self,
        analytics: &TokenAnalytics,
        signal_type: SignalType,
        price_change: BigDecimal,
        volume_change: Option<BigDecimal>,
    ) -> MarketSignal {
        let confidence = self.calculate_confidence(
            price_change.clone(),
            volume_change.clone().unwrap_or_else(|| BigDecimal::from(0)),
        );

        MarketSignalBuilder::new(
            analytics.token_address.clone(),
            signal_type,
            analytics.price.clone(),
        )
        .confidence(confidence)
        .risk_score(f64_to_decimal(0.5))
        .sentiment_score(f64_to_decimal(0.5))
        .price_change_24h(price_change)
        .volume_change_24h(volume_change.clone().unwrap_or_else(|| BigDecimal::from(0)))
        .volume_change(volume_change.unwrap_or_else(|| BigDecimal::from(0)))
        .timestamp(analytics.timestamp)
        .build()
    }

    async fn store_market_signal(&self, signal: &MarketSignal) -> AgentResult<()> {
        self.signals_collection
            .insert_one(signal)
            .await
            .map_err(AgentError::Database)?;

        Ok(())
    }

    pub async fn get_previous_analytics(
        &self,
        address: &str,
    ) -> AgentResult<Option<TokenAnalytics>> {
        let filter = doc! {
            "token_address": address,
            "timestamp": { "$lt": DateTime::now() }
        };

        let _options = FindOneOptions::builder()
            .sort(doc! { "timestamp": -1 })
            .build();

        self.collection
            .find_one(filter)
            .await
            .map_err(AgentError::Database)
    }

    async fn store_token_analytics(
        &self,
        analytics: &TokenAnalytics,
    ) -> AgentResult<TokenAnalytics> {
        let result = self
            .collection
            .insert_one(analytics)
            .await
            .map_err(AgentError::Database)?;

        let mut stored = analytics.clone();
        stored.id = result.inserted_id.as_object_id();
        Ok(stored)
    }

    pub async fn get_token_history(
        &self,
        address: &str,
        start_time: DateTime,
        end_time: DateTime,
    ) -> AgentResult<Vec<TokenAnalytics>> {
        let filter = doc! {
            "token_address": address,
            "timestamp": {
                "$gte": start_time,
                "$lte": end_time
            }
        };

        let options = mongodb::options::FindOptions::builder()
            .sort(doc! { "timestamp": -1 })
            .build();

        let mut cursor = self
            .collection
            .find(filter)
            .with_options(options)
            .await
            .map_err(AgentError::Database)?;

        let mut results = Vec::new();
        while let Some(doc) = cursor.next().await {
            results.push(doc.map_err(AgentError::Database)?);
        }

        Ok(results)
    }

    // Helper method for retrying API calls
    async fn fetch_with_retry<T, F, Fut>(&self, f: F, retries: u32) -> Result<T, anyhow::Error>
    where
        F: Fn() -> Fut,
        Fut: std::future::Future<Output = Result<T, anyhow::Error>>,
    {
        let mut attempts = 0;
        let mut last_error = None;

        while attempts < retries {
            match f().await {
                Ok(result) => return Ok(result),
                Err(e) => {
                    attempts += 1;
                    last_error = Some(e);
                    if attempts < retries {
                        tokio::time::sleep(std::time::Duration::from_millis(
                            500 * 2u64.pow(attempts),
                        ))
                        .await;
                    }
                }
            }
        }

        Err(last_error.unwrap_or_else(|| anyhow::anyhow!("Unknown error during retry")))
    }

    // Helper method for validation
    fn validate_token_data(&self, token_info: &TokenInfo) -> AgentResult<()> {
        if token_info.price <= 0.0 {
            return Err(AgentError::validation("Token price must be positive"));
        }
        if token_info.volume_24h < 0.0 {
            return Err(AgentError::validation("Token volume cannot be negative"));
        }
        Ok(())
    }

    // Helper method for signal validation
    fn validate_signal(&self, signal: &MarketSignal) -> AgentResult<()> {
        let zero = BigDecimal::from(0);
        let one = BigDecimal::from(1);

        if signal.confidence < zero || signal.confidence > one {
            return Err(AgentError::validation(
                "Signal confidence must be between 0 and 1",
            ));
        }
        if signal.risk_score < zero || signal.risk_score > one {
            return Err(AgentError::validation("Risk score must be between 0 and 1"));
        }
        Ok(())
    }

    fn log_signal(&self, signal: &MarketSignal, analytics: &TokenAnalytics) {
        let signal_log = MarketSignalLog {
            id: Uuid::new_v4(),
            timestamp: DateTime::now(),
            token_address: signal.asset_address.clone(),
            token_symbol: analytics.token_symbol.clone(),
            signal_type: signal.signal_type.to_string(),
            price: analytics.price.to_f64().unwrap_or_default(),
            price_change_24h: Some(
                signal
                    .price_change_24h
                    .as_ref()
                    .and_then(|p| p.to_f64())
                    .unwrap_or_default(),
            ),
            volume_change_24h: signal.volume_change_24h.as_ref().and_then(|v| v.to_f64()),
            confidence: signal.confidence.to_f64().unwrap_or_default(),
            risk_score: signal.risk_score.to_f64().unwrap_or_default(),
            created_at: DateTime::now(),
        };

        log_market_signal(&signal_log);
    }

    fn calculate_confidence(
        &self,
        price_change: BigDecimal,
        volume_change: BigDecimal,
    ) -> BigDecimal {
        self.market_config.base_confidence.clone()
            + (price_change * self.market_config.price_weight.clone())
            + (volume_change * self.market_config.volume_weight.clone())
    }

    async fn process_market_signal(&self, signal: MarketSignal) -> AgentResult<()> {
        let _logger = RequestLogger::new("token_analytics", "process_market_signal");

        let signal_log = MarketSignalLog {
            id: Uuid::new_v4(),
            timestamp: DateTime::now(),
            token_address: signal.asset_address.clone(),
            token_symbol: signal
                .metadata
                .expect("Failed to get token symbol from metadata")
                .get("token_symbol")
                .and_then(|v| v.as_str())
                .unwrap_or(&signal.asset_address)
                .to_string(),
            signal_type: signal.signal_type.to_string(),
            price: signal.price.to_f64().unwrap_or_default(),
            price_change_24h: signal
                .price_change_24h
                .map(|p| p.to_f64().unwrap_or_default()),
            volume_change_24h: signal
                .volume_change_24h
                .map(|v| v.to_f64().unwrap_or_default()),
            confidence: signal.confidence.to_f64().unwrap_or_default(),
            risk_score: signal.risk_score.to_f64().unwrap_or_default(),
            created_at: signal.created_at.unwrap_or_else(DateTime::now),
        };

        log_market_signal(&signal_log);
        Ok(())
    }
}

// Move From implementation outside of TokenAnalyticsService impl block
impl From<MarketSignal> for MarketSignalLog {
    fn from(signal: MarketSignal) -> Self {
        Self {
            id: Uuid::new_v4(),
            timestamp: DateTime::now(),
            token_address: signal.asset_address.clone(),
            token_symbol: signal
                .metadata
                .expect("Failed to get token symbol from metadata")
                .get("token_symbol")
                .and_then(|v| v.as_str())
                .unwrap_or(&signal.asset_address)
                .to_string(),
            signal_type: signal.signal_type.to_string(),
            price: signal.price.to_f64().unwrap_or_default(),
            price_change_24h: Some(
                signal
                    .price_change_24h
                    .and_then(|p| p.to_f64())
                    .unwrap_or_default(),
            ),
            volume_change_24h: signal.volume_change_24h.and_then(|v| v.to_f64()),
            confidence: signal.confidence.to_f64().unwrap_or_default(),
            risk_score: signal.risk_score.to_f64().unwrap_or_default(),
            created_at: signal.created_at.unwrap_or_else(DateTime::now),
        }
    }
}


================================================
File: src/services/token_data.rs
================================================
use anyhow::Result;
use cainam_core::birdeye::BirdeyeClient;
// use futures::TryStreamExt; // No longer needed here (it was for the commented-out function)
use mongodb::{
    bson::{doc, Document},
    Client, Collection,
};
use serde::{Deserialize, Serialize};
use tracing::info;

// Define a struct to represent the token data we'll store.  Adapt this to your actual data.
#[derive(Debug, Serialize, Deserialize)]
pub struct TokenData {
    pub symbol: String,
    pub address: String,
    pub price: f64,
    // Add other fields as needed, e.g., volume, market_cap, etc.
    pub timestamp: mongodb::bson::DateTime,
}

pub struct TokenDataService {
    client: mongodb::Client,
    db: mongodb::Database,
    birdeye_client: BirdeyeClient,
    collection: Collection<TokenData>, // Use TokenData here
}

impl TokenDataService {
    pub async fn new(mongo_uri: String, birdeye_api_key: String) -> Result<Self> {
        let client = Client::with_uri_str(&mongo_uri).await?;
        let db = client.database("cainam");
        let collection = db.collection::<TokenData>("market_data"); // Use TokenData
        let birdeye_client = BirdeyeClient::new(birdeye_api_key);

        Ok(Self {
            client,
            db,
            birdeye_client,
            collection,
        })
    }

    pub async fn update_token_data(&self, address: &str, symbol: &str) -> Result<()> {
        let market_data = match self.birdeye_client.get_market_data(address).await {
            Ok(data) => data,
            Err(e) => {
                tracing::error!("Error fetching market data from Birdeye: {}", e);
                return Err(e);
            }
        };

        let token_data = TokenData {
            symbol: symbol.to_string(),
            address: address.to_string(),
            price: market_data.price,
            timestamp: mongodb::bson::DateTime::now(),
        };

        self.collection.insert_one(token_data, None).await?;

        info!("Updated market data for {} ({})", symbol, address);
        Ok(())
    }

    // Commenting out the unused function to fix compiler errors.
    // pub async fn get_token_analytics(
    //     &self,
    //     address: &str,
    //     start_time: chrono::DateTime<chrono::Utc>,
    //     end_time: chrono::DateTime<chrono::Utc>,
    // ) -> Result<Vec<TokenAnalyticsData>> {
    //     let filter = doc! {
    //         "address": address,
    //         "timestamp": {
    //             "$gte": bson::DateTime::now(), // Corrected usage
    //             "$lte": bson::DateTime::now()  // Corrected usage
    //         }
    //     };
    //     let find_options = mongodb::options::FindOptions::builder()
    //         .sort(doc! { "timestamp": 1 })
    //         .build();

    //     let mut cursor = self.collection.find(filter, None).await?; // Corrected: No options needed
    //     let mut analytics_data = Vec::new();
    //     while let Some(result) = cursor.try_next().await? {  // Corrected: try_next requires TryStreamExt
    //          let data: TokenAnalyticsData = bson::from_document(result)?;
    //          analytics_data.push(data);
    //     }
    //     Ok(analytics_data)
    // }
}

#[derive(Debug, Serialize, Deserialize)]
pub struct TokenAnalyticsData {
    pub symbol: String,
    pub address: String,
    pub price: f64,
    pub timestamp: mongodb::bson::DateTime,
} 

================================================
File: src/services/token_data_service.rs
================================================
use anyhow::Result;
use bson::DateTime;
use chrono::{DateTime as ChronoDateTime, Utc};
use futures::TryStreamExt;
use mongodb::options::FindOptions;
use mongodb::{
    bson::{self, doc},
    Client, Collection, Database,
};
use std::sync::Arc;
use std::time::SystemTime;

use crate::{
    birdeye::api::{BirdeyeApi, BirdeyeClient},
    config::mongodb::{MongoDbPool, TokenAnalyticsData},
    error::AgentResult,
};

const COLLECTION_NAME: &str = "token_analytics";

pub struct TokenDataService {
    database: Database,
    birdeye_client: Arc<dyn BirdeyeApi>,
    collection: Collection<TokenAnalyticsData>,
}

impl TokenDataService {
    pub async fn new(mongo_uri: String, birdeye_api_key: String) -> Result<Self> {
        let client = Client::with_uri_str(&mongo_uri).await?;
        let database = client.database("cainam");
        let collection = database.collection(COLLECTION_NAME);

        let birdeye_client = Arc::new(BirdeyeClient::new(birdeye_api_key)) as Arc<dyn BirdeyeApi>;

        Ok(Self {
            database,
            birdeye_client,
            collection,
        })
    }

    pub async fn new_with_pool(pool: Arc<MongoDbPool>, birdeye_api_key: String) -> Result<Self> {
        let database = pool.database("");
        let collection = database.collection(COLLECTION_NAME);

        let birdeye_client = Arc::new(BirdeyeClient::new(birdeye_api_key)) as Arc<dyn BirdeyeApi>;

        Ok(Self {
            database,
            birdeye_client,
            collection,
        })
    }

    pub async fn get_latest_token_data(
        &self,
        token_address: &str,
    ) -> Result<Option<TokenAnalyticsData>> {
        let filter = doc! { "token_address": token_address };
        let options = FindOptions::builder()
            .sort(doc! { "timestamp": -1 })
            .limit(1)
            .build();

        let mut cursor = self.collection.find(filter).await?;
        Ok(cursor.try_next().await?)
    }

    pub async fn get_token_history(
        &self,
        token_address: &str,
        start_time: ChronoDateTime<Utc>,
        end_time: ChronoDateTime<Utc>,
    ) -> Result<Vec<TokenAnalyticsData>> {
        let filter = doc! {
            "token_address": token_address,
            "timestamp": {
                "$gte": DateTime::from_millis(start_time.timestamp_millis()),
                "$lte": DateTime::from_millis(end_time.timestamp_millis())
            }
        };

        let cursor = self.collection.find(filter).await?;
        Ok(cursor.try_collect().await?)
    }

    pub async fn store_token_data(&self, token_data: TokenAnalyticsData) -> AgentResult<()> {
        self.collection.insert_one(token_data).await?;
        Ok(())
    }

    pub async fn get_token_data(
        &self,
        filter: bson::Document,
    ) -> AgentResult<Option<TokenAnalyticsData>> {
        let mut cursor = self.collection.find(filter).await?;
        Ok(cursor.try_next().await?)
    }

    pub async fn get_historical_data(
        &self,
        start_time: SystemTime,
        end_time: SystemTime,
    ) -> AgentResult<Vec<TokenAnalyticsData>> {
        let filter = doc! {
            "timestamp": {
                "$gte": DateTime::from_system_time(start_time),
                "$lte": DateTime::from_system_time(end_time)
            }
        };

        let mut cursor = self.collection.find(filter).await?;
        let mut results = Vec::new();
        while let Some(doc) = cursor.try_next().await? {
            results.push(doc);
        }
        Ok(results)
    }
}


================================================
File: src/strategy/llm.rs
================================================
use crate::market_data::{birdeye::BirdEyeProvider, DataProvider};
use anyhow::Result;
use std::sync::Arc;
use tracing::{debug, instrument};

pub struct LLMStrategy {
    birdeye: Arc<BirdEyeProvider>,
}

impl LLMStrategy {
    pub fn new(birdeye: Arc<BirdEyeProvider>) -> Self {
        Self { birdeye }
    }

    #[instrument(skip(self))]
    pub async fn analyze_trading_opportunity(&self, prompt: &str, sol_balance: f64) -> Result<String> {
        debug!("Analyzing trading opportunity with prompt: {}", prompt);
        
        // Format the analysis with the available SOL balance
        let analysis = format!(
            "Available SOL: {}\n{}",
            sol_balance,
            prompt
        );
        
        Ok(analysis)
    }
} 

================================================
File: src/strategy/mod.rs
================================================
#[instrument(skip(self))]
pub async fn analyze_trading_opportunity(&self, prompt: String, sol_balance: f64) -> Result<String> {
    info!("Analyzing trading opportunity with prompt: {}", prompt);
    
    // Format the prompt with market analysis requirements
    let formatted_prompt = format!(
        "{}\n\nAnalyze this trading opportunity and provide a detailed recommendation in the following JSON format:\n{{
            \"action\": \"Buy|Sell|Hold\",
            \"token_address\": \"string\",
            \"amount_in_sol\": number,
            \"reasoning\": \"string\",
            \"confidence\": number (0.0-1.0),
            \"risk_assessment\": \"string\",
            \"market_analysis\": {{
                \"volume_analysis\": {{
                    \"current_volume_usd\": number,
                    \"volume_change_24h\": number,
                    \"is_volume_bullish\": boolean,
                    \"analysis\": \"string\"
                }},
                \"price_trend\": {{
                    \"current_trend\": \"string\",
                    \"support_levels\": [number],
                    \"resistance_levels\": [number],
                    \"trend_strength\": number (0.0-1.0)
                }},
                \"liquidity_assessment\": {{
                    \"liquidity_score\": number (0.0-1.0),
                    \"slippage_estimate\": number,
                    \"is_liquid_enough\": boolean
                }},
                \"momentum_indicators\": {{
                    \"rsi_14\": number,
                    \"macd\": {{
                        \"value\": number,
                        \"signal\": \"bullish|bearish|neutral\"
                    }},
                    \"overall_momentum\": \"strong_buy|buy|neutral|sell|strong_sell\"
                }},
                \"on_chain_metrics\": {{
                    \"unique_holders\": number,
                    \"holder_concentration\": number (0.0-1.0),
                    \"smart_money_flow\": \"inflow|outflow|neutral\"
                }}
            }},
            \"execution_strategy\": {{
                \"entry_type\": \"market|limit\",
                \"position_size_sol\": number,
                \"stop_loss_pct\": number,
                \"take_profit_levels\": [{{
                    \"price_target\": number,
                    \"size_pct\": number
                }}],
                \"time_horizon\": \"short|medium|long\",
                \"dca_strategy\": {{
                    \"should_dca\": boolean,
                    \"interval_hours\": number,
                    \"num_entries\": number
                }}
            }}
        }}\n\nAvailable SOL balance: {} SOL\n\nConsider the following criteria for the analysis:\n1. Volume should show significant increase (>50% 24h change) with sustainable growth\n2. Price action should show clear trend with identifiable support/resistance levels\n3. Liquidity should be sufficient to enter/exit position with <2% slippage\n4. Momentum indicators should align with the overall trend\n5. Smart money flow should indicate institutional interest\n6. Risk:reward ratio should be at least 1:3 for any trade", 
        prompt,
        sol_balance
    );

    // Get analysis from LLM
    let analysis = self.agent.complete(&formatted_prompt).await?;
    
    info!("Received analysis from LLM");
    Ok(analysis)
}

================================================
File: src/trading/mod.rs
================================================
pub mod trading_engine;

use anyhow::Result;
use solana_client::rpc_client::RpcClient;

pub struct SolanaAgentKit {
    rpc_client: RpcClient,
    wallet_keypair: solana_sdk::signer::keypair::Keypair,
}

impl SolanaAgentKit {
    pub fn new(rpc_url: &str, wallet_keypair: solana_sdk::signer::keypair::Keypair) -> Self {
        Self {
            rpc_client: RpcClient::new(rpc_url.to_string()),
            wallet_keypair,
        }
    }

    pub fn new_from_env() -> Result<Self> {
        let rpc_url = std::env::var("SOLANA_RPC_URL")?;
        let wallet_key = std::env::var("SOLANA_PRIVATE_KEY")?;

        // Parse the base58 private key
        let wallet_keypair = solana_sdk::signer::keypair::Keypair::from_base58_string(&wallet_key);

        Ok(Self::new(&rpc_url, wallet_keypair))
    }

    pub fn get_rpc_client(&self) -> &RpcClient {
        &self.rpc_client
    }

    pub fn get_wallet_keypair(&self) -> &solana_sdk::signer::keypair::Keypair {
        &self.wallet_keypair
    }
}


================================================
File: src/trading/trading_engine.rs
================================================
use super::SolanaAgentKit;
use crate::models::market_signal::{MarketSignal, SignalType};
use crate::utils::{decimal_to_f64, f64_to_decimal};
use anyhow::Result;
use tracing::{info, warn};

pub struct TradingEngine {
    min_confidence: f64,
    max_trade_size: f64,
    agent: SolanaAgentKit,
}

#[derive(Debug)]
pub struct TradeDecision {
    pub action: String,
    pub symbol: String,
    pub amount: f64,
    pub reason: String,
    pub confidence: f64,
    pub mint_address: Option<String>,
}

impl TradingEngine {
    pub fn new(min_confidence: f64, max_trade_size: f64, agent: SolanaAgentKit) -> Self {
        Self {
            min_confidence,
            max_trade_size,
            agent,
        }
    }

    pub async fn execute_trade(&self, signal: &MarketSignal) -> Result<String> {
        let min_conf = f64_to_decimal(self.min_confidence);

        if signal.confidence < min_conf {
            warn!("Signal confidence too low for trading");
            return Ok("Signal confidence too low".to_string());
        }

        let max_size = f64_to_decimal(self.max_trade_size);
        let _amount = decimal_to_f64(&(max_size.clone() * signal.confidence.clone()).min(max_size));

        let action = match signal.signal_type {
            SignalType::Buy
            | SignalType::StrongBuy
            | SignalType::PriceSpike
            | SignalType::VolumeSurge => "BUY",
            SignalType::Sell | SignalType::StrongSell | SignalType::PriceDrop => "SELL",
            SignalType::Hold => "HOLD",
        };

        info!(
            "Executing {} trade for {} with confidence {:.2}",
            action,
            signal.asset_address,
            decimal_to_f64(&signal.confidence)
        );

        // TODO: Implement actual Solana transaction execution
        // For now, just return a mock signature
        Ok(format!(
            "mock_tx_{}_{}",
            action.to_lowercase(),
            signal.asset_address
        ))
    }

    pub fn get_min_confidence(&self) -> f64 {
        self.min_confidence
    }

    pub fn get_max_trade_size(&self) -> f64 {
        self.max_trade_size
    }
}


================================================
File: src/twitter/mod.rs
================================================
use anyhow::{anyhow, Result};
use reqwest::{
    header::{HeaderMap, HeaderValue, CONTENT_TYPE},
    Client,
};
use serde_json::json;
use tracing::{error, info};

// Remove trait definition since we're not using trait objects
pub struct TwitterClient {
    client: Client,
    email: String,
    username: String,
    password: String,
    auth_token: Option<String>,
}

impl TwitterClient {
    pub fn new(email: String, username: String, password: String) -> Self {
        Self {
            client: Client::new(),
            email,
            username,
            password,
            auth_token: None,
        }
    }

    pub async fn login(&mut self) -> Result<()> {
        let mut headers = HeaderMap::new();
        headers.insert(CONTENT_TYPE, HeaderValue::from_static("application/json"));

        // Direct auth endpoint
        let payload = json!({
            "email": self.email,
            "username": self.username,
            "password": self.password
        });

        let response = self
            .client
            .post("https://x.com/i/flow/login")
            .headers(headers)
            .json(&payload)
            .send()
            .await?;

        if response.status().is_success() {
            // Extract auth token from cookies
            if let Some(cookies) = response.headers().get("set-cookie") {
                if let Ok(cookie_str) = cookies.to_str() {
                    if let Some(auth_token) = extract_auth_token(cookie_str) {
                        info!("Successfully logged in to Twitter");
                        self.auth_token = Some(auth_token);
                        return Ok(());
                    }
                }
            }
            Err(anyhow!("No auth token found in response"))
        } else {
            let error_message = response.text().await.unwrap_or_default();
            error!("Failed to login to Twitter: {}", error_message);
            Err(anyhow!("Failed to login to Twitter: {}", error_message))
        }
    }

    pub async fn post_tweet(&self, text: &str) -> Result<()> {
        if self.auth_token.is_none() {
            return Err(anyhow!("Not authenticated"));
        }

        let mut headers = HeaderMap::new();
        headers.insert(CONTENT_TYPE, HeaderValue::from_static("application/json"));

        // Add auth token cookie
        headers.insert(
            "cookie",
            HeaderValue::from_str(&format!("auth_token={}", self.auth_token.as_ref().unwrap()))?,
        );

        let payload = json!({
            "text": text,
            "queryId": "PvJGyyJKzm2-aIsTo6tLSg"  // Twitter's internal query ID for posting tweets
        });

        let response = self
            .client
            .post("https://x.com/i/api/graphql/PvJGyyJKzm2-aIsTo6tLSg/CreateTweet")
            .headers(headers)
            .json(&payload)
            .send()
            .await?;

        if response.status().is_success() {
            info!("Successfully posted tweet");
            Ok(())
        } else {
            let error_message = response.text().await.unwrap_or_default();
            error!("Failed to post tweet: {}", error_message);
            Err(anyhow!("Failed to post tweet: {}", error_message))
        }
    }

    pub async fn delete_tweet(&self, tweet_id: &str) -> Result<()> {
        if self.auth_token.is_none() {
            return Err(anyhow!("Not authenticated"));
        }

        let mut headers = HeaderMap::new();
        headers.insert(CONTENT_TYPE, HeaderValue::from_static("application/json"));

        // Add auth token cookie
        headers.insert(
            "cookie",
            HeaderValue::from_str(&format!("auth_token={}", self.auth_token.as_ref().unwrap()))?,
        );

        let payload = json!({
            "tweet_id": tweet_id,
            "queryId": "VaenaVgh5q5ih7kvyVjgtg"  // Twitter's internal query ID for deleting tweets
        });

        let response = self
            .client
            .post("https://x.com/i/api/graphql/VaenaVgh5q5ih7kvyVjgtg/DeleteTweet")
            .headers(headers)
            .json(&payload)
            .send()
            .await?;

        if response.status().is_success() {
            info!("Successfully deleted tweet {}", tweet_id);
            Ok(())
        } else {
            let error_message = response.text().await.unwrap_or_default();
            error!("Failed to delete tweet {}: {}", tweet_id, error_message);
            Err(anyhow!("Failed to delete tweet: {}", error_message))
        }
    }
}

// Helper function to extract auth token from cookies
fn extract_auth_token(cookie_str: &str) -> Option<String> {
    cookie_str
        .split(';')
        .find(|s| s.trim().starts_with("auth_token="))
        .and_then(|s| s.trim().strip_prefix("auth_token="))
        .map(|s| s.to_string())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_extract_auth_token() {
        let cookie_str = "auth_token=abc123; Path=/; Domain=.x.com; Secure; HttpOnly";
        assert_eq!(extract_auth_token(cookie_str), Some("abc123".to_string()));
    }

    #[tokio::test]
    async fn test_auth_token_none() {
        let client = TwitterClient::new(
            "test@example.com".to_string(),
            "testuser".to_string(),
            "password".to_string(),
        );

        // Test that unauthorized operations fail
        let tweet_result = client.post_tweet("Test tweet").await;
        assert!(tweet_result.is_err());

        let delete_result = client.delete_tweet("123").await;
        assert!(delete_result.is_err());
    }
}


================================================
File: src/utils/mod.rs
================================================
use bigdecimal::FromPrimitive;
use bigdecimal::{BigDecimal, ToPrimitive};

/// Converts an f64 value to a BigDecimal. Returns 0 if the conversion fails.
pub fn f64_to_decimal(value: f64) -> BigDecimal {
    BigDecimal::from_f64(value).unwrap_or_else(|| BigDecimal::from(0))
}

/// Converts a reference to a BigDecimal to an f64. Returns 0.0 if the conversion fails.
pub fn decimal_to_f64(value: &BigDecimal) -> f64 {
    value.to_f64().unwrap_or(0.0)
}

#[cfg(test)]
mod tests {
    use super::*;
    use bigdecimal::BigDecimal;

    #[test]
    fn test_f64_to_decimal() {
        assert_eq!(f64_to_decimal(1.0), BigDecimal::from(1));
        assert_eq!(f64_to_decimal(0.0), BigDecimal::from(0));
        assert_eq!(f64_to_decimal(3.14), BigDecimal::from_f64(3.14).unwrap());
    }

    #[test]
    fn test_decimal_to_f64() {
        let big_decimal_one = BigDecimal::from(1);
        let big_decimal_zero = BigDecimal::from(0);
        let big_decimal_pi = BigDecimal::from_f64(3.14).unwrap();

        assert_eq!(decimal_to_f64(&big_decimal_one), 1.0);
        assert_eq!(decimal_to_f64(&big_decimal_zero), 0.0);
        assert_eq!(decimal_to_f64(&big_decimal_pi), 3.14);
    }
}


================================================
File: src/vector_store/mod.rs
================================================
use anyhow::{Context, Result};
use rig_core::vector_store::{Document, Store};
use rig_mongodb::MongoStore;
use std::sync::Arc;
use tracing::{info, warn};
use crate::config::mongodb::{MongoConfig, MongoDbPool};
use serde_json;

pub struct VectorStore {
    store: Arc<MongoStore>,
}

impl VectorStore {
    pub async fn new() -> Result<Self> {
        // Use centralized MongoDB configuration
        let config = MongoConfig::from_env();
        info!("Initializing vector store connection");
        
        let pool = MongoDbPool::create_pool(config.clone())
            .await
            .context("Failed to create MongoDB pool")?;
            
        // Configure vector store with optimized search parameters and fields
        let fields = serde_json::json!({
            "fields": [{
                "path": "embedding",
                "numDimensions": 1536,
                "similarity": "cosine"
            }]
        });
            
        let store = MongoStore::new(
            pool.client(), 
            &config.database, 
            "token_analytics",
            fields
        ).await
            .context("Failed to create vector store")?;

        Ok(Self {
            store: Arc::new(store),
        })
    }

    pub async fn insert_documents<T>(&self, documents: Vec<T>) -> Result<()> 
    where
        T: Send + Sync + 'static + serde::Serialize + Document,
    {
        info!("Inserting documents into vector store");
        self.store.insert_documents(&documents)
            .await
            .context("Failed to insert documents into vector store")?;
        Ok(())
    }

    pub async fn top_n<T>(&self, query: &str, limit: usize) -> Result<Vec<(f32, T)>>
    where
        T: Send + Sync + for<'de> serde::de::Deserialize<'de> + 'static,
    {
        if limit == 0 {
            warn!("top_n called with limit=0, defaulting to 1");
            let limit = 1;
        }
        
        info!("Performing vector similarity search with limit {}", limit);
        let results = self.store.search::<T>(query, limit)
            .await
            .context("Failed to perform vector similarity search")?;
            
        info!("Found {} matching documents", results.len());
        Ok(results)
    }

    #[cfg(test)]
    pub async fn cleanup_test_data(&self) -> Result<()> {
        // Implement cleanup logic for MongoDB if necessary
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde::{Deserialize, Serialize};
    use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};

    #[derive(Serialize, Deserialize, Clone, Debug, Eq, PartialEq)]
    struct TestDocument {
        id: String,
        content: String,
    }

    impl Document for TestDocument {
        fn text(&self) -> &str {
            &self.content
        }
    }

    fn init_test_logging() {
        let _ = tracing_subscriber::registry()
            .with(tracing_subscriber::EnvFilter::try_from_default_env()
                .unwrap_or_else(|_| "info".into()))
            .with(tracing_subscriber::fmt::layer())
            .try_init();
    }

    #[tokio::test]
    async fn test_vector_store() -> Result<()> {
        init_test_logging();
        dotenvy::dotenv().ok();
        
        let store = VectorStore::new()
            .await
            .context("Failed to create vector store")?;
            
        // Clean up any existing test data
        store.cleanup_test_data()
            .await
            .context("Failed to cleanup existing test data")?;
        
        let docs = vec![
            TestDocument {
                id: "1".to_string(),
                content: "Test document one".to_string(),
            },
            TestDocument {
                id: "2".to_string(), 
                content: "Test document two".to_string(),
            },
        ];

        store.insert_documents(docs)
            .await
            .context("Failed to insert test documents")?;

        let results = store.top_n::<TestDocument>("test document", 2)
            .await
            .context("Failed to perform similarity search")?;
            
        assert!(!results.is_empty(), "Expected non-empty search results");
        assert_eq!(results.len(), 2, "Expected exactly 2 search results");

        // Clean up test data
        store.cleanup_test_data()
            .await
            .context("Failed to cleanup test data")?;

        Ok(())
    }
}


